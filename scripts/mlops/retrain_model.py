"""
ìë™ ëª¨ë¸ ì¬í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

- ìƒˆë¡œìš´ í•™ìŠµ ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµ
- ë²„ì „ ê´€ë¦¬ ë° ì²´í¬í¬ì¸íŠ¸ ì €ì¥
- ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê¹…
- ê¸°ì¡´ ëª¨ë¸ê³¼ ì„±ëŠ¥ ë¹„êµ
"""

import os
import sys
import json
import pickle
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import (
    accuracy_score,
    precision_recall_fscore_support,
    mean_squared_error,
    confusion_matrix,
    classification_report
)
import matplotlib
matplotlib.use('Agg')  # GUI ì—†ëŠ” í™˜ê²½ìš©
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from datetime import datetime


# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


# ==================== ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ====================
class HairstyleDataset(Dataset):
    """í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ ë°ì´í„°ì…‹"""

    def __init__(self, csv_path, face_encoder=None, skin_encoder=None,
                 style_encoder=None, is_train=True):
        self.df = pd.read_csv(csv_path)
        self.is_train = is_train

        if is_train:
            self.face_encoder = LabelEncoder()
            self.skin_encoder = LabelEncoder()
            self.style_encoder = LabelEncoder()

            self.face_encoded = self.face_encoder.fit_transform(self.df['face_shape'])
            self.skin_encoded = self.skin_encoder.fit_transform(self.df['skin_tone'])
            self.style_encoded = self.style_encoder.fit_transform(self.df['hairstyle'])
        else:
            self.face_encoder = face_encoder
            self.skin_encoder = skin_encoder
            self.style_encoder = style_encoder

            self.face_encoded = self.face_encoder.transform(self.df['face_shape'])
            self.skin_encoded = self.skin_encoder.transform(self.df['skin_tone'])
            self.style_encoded = self.style_encoder.transform(self.df['hairstyle'])

        self.scores = self.df['score'].values
        self.feedbacks = (self.df['feedback'] == 'like').astype(int).values

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        return {
            'face': torch.tensor(self.face_encoded[idx], dtype=torch.long),
            'skin': torch.tensor(self.skin_encoded[idx], dtype=torch.long),
            'style': torch.tensor(self.style_encoded[idx], dtype=torch.long),
            'score': torch.tensor(self.scores[idx], dtype=torch.float32),
            'feedback': torch.tensor(self.feedbacks[idx], dtype=torch.long)
        }


# ==================== ëª¨ë¸ ì •ì˜ ====================
class HairstyleRecommender(nn.Module):
    """í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ ëª¨ë¸"""

    def __init__(self, n_faces=5, n_skins=3, n_styles=6,
                 emb_dim=16, hidden_dim=64):
        super().__init__()

        self.face_emb = nn.Embedding(n_faces, emb_dim)
        self.skin_emb = nn.Embedding(n_skins, emb_dim)
        self.style_emb = nn.Embedding(n_styles, emb_dim)

        self.shared_layers = nn.Sequential(
            nn.Linear(emb_dim * 3, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3)
        )

        self.score_head = nn.Sequential(
            nn.Linear(hidden_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )

        self.feedback_head = nn.Sequential(
            nn.Linear(hidden_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 2)
        )

    def forward(self, face, skin, style):
        face_emb = self.face_emb(face)
        skin_emb = self.skin_emb(skin)
        style_emb = self.style_emb(style)

        x = torch.cat([face_emb, skin_emb, style_emb], dim=1)
        shared = self.shared_layers(x)

        score = self.score_head(shared).squeeze()
        feedback_logits = self.feedback_head(shared)

        return score, feedback_logits


# ==================== íŠ¸ë ˆì´ë„ˆ í´ë˜ìŠ¤ ====================
class ModelTrainer:
    """ëª¨ë¸ í•™ìŠµ í´ë˜ìŠ¤"""

    def __init__(
        self,
        train_data_path="data_source/train_data.csv",
        val_data_path="data_source/val_data.csv",
        test_data_path="data_source/test_data.csv",
        output_dir="models/checkpoints",
        device="cpu"
    ):
        self.project_root = project_root
        self.train_path = self.project_root / train_data_path
        self.val_path = self.project_root / val_data_path
        self.test_path = self.project_root / test_data_path
        self.output_dir = self.project_root / output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.device = torch.device(device)
        self.model = None
        self.train_dataset = None
        self.val_dataset = None
        self.test_dataset = None

        # í•™ìŠµ íˆìŠ¤í† ë¦¬
        self.history = {
            'train_loss': [],
            'val_loss': [],
            'val_accuracy': [],
            'val_f1': []
        }

        # ë²„ì „ ì •ë³´
        self.version = datetime.now().strftime("%Y%m%d_%H%M%S")

    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print("=" * 60)
        print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
        print("=" * 60)

        # í•™ìŠµ ë°ì´í„° ë¡œë“œ (ì¸ì½”ë” ìƒì„±)
        self.train_dataset = HairstyleDataset(
            self.train_path,
            is_train=True
        )
        print(f"âœ… í•™ìŠµ ë°ì´í„°: {len(self.train_dataset)}ê±´")

        # ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ (ì¸ì½”ë” ì¬ì‚¬ìš©)
        self.val_dataset = HairstyleDataset(
            self.val_path,
            face_encoder=self.train_dataset.face_encoder,
            skin_encoder=self.train_dataset.skin_encoder,
            style_encoder=self.train_dataset.style_encoder,
            is_train=False
        )
        print(f"âœ… ê²€ì¦ ë°ì´í„°: {len(self.val_dataset)}ê±´")

        self.test_dataset = HairstyleDataset(
            self.test_path,
            face_encoder=self.train_dataset.face_encoder,
            skin_encoder=self.train_dataset.skin_encoder,
            style_encoder=self.train_dataset.style_encoder,
            is_train=False
        )
        print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(self.test_dataset)}ê±´")

        # ì¸ì½”ë” ì €ì¥
        self._save_encoders()

    def _save_encoders(self):
        """ì¸ì½”ë” ì €ì¥"""
        encoders = {
            'face': self.train_dataset.face_encoder,
            'skin': self.train_dataset.skin_encoder,
            'style': self.train_dataset.style_encoder
        }

        encoder_path = self.output_dir / f"encoders_{self.version}.pkl"
        with open(encoder_path, 'wb') as f:
            pickle.dump(encoders, f)

        # ìµœì‹  ë²„ì „ë„ ì €ì¥
        encoder_latest = self.output_dir / "encoders_latest.pkl"
        with open(encoder_latest, 'wb') as f:
            pickle.dump(encoders, f)

        print(f"âœ… ì¸ì½”ë” ì €ì¥: {encoder_path}")

    def build_model(self):
        """ëª¨ë¸ ìƒì„±"""
        print("\n" + "=" * 60)
        print("ğŸ—ï¸ ëª¨ë¸ ìƒì„± ì¤‘...")
        print("=" * 60)

        n_faces = len(self.train_dataset.face_encoder.classes_)
        n_skins = len(self.train_dataset.skin_encoder.classes_)
        n_styles = len(self.train_dataset.style_encoder.classes_)

        self.model = HairstyleRecommender(
            n_faces=n_faces,
            n_skins=n_skins,
            n_styles=n_styles,
            emb_dim=16,
            hidden_dim=64
        ).to(self.device)

        print(f"âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        print(f"   ì–¼êµ´í˜•: {n_faces}ê°œ")
        print(f"   í”¼ë¶€í†¤: {n_skins}ê°œ")
        print(f"   í—¤ì–´ìŠ¤íƒ€ì¼: {n_styles}ê°œ")

    def calculate_class_weights(self):
        """í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (ë¶ˆê· í˜• í•´ê²°)"""
        feedbacks = self.train_dataset.feedbacks
        n_total = len(feedbacks)
        n_like = np.sum(feedbacks == 1)
        n_dislike = np.sum(feedbacks == 0)

        weight_like = n_total / (2 * n_like) if n_like > 0 else 1.0
        weight_dislike = n_total / (2 * n_dislike) if n_dislike > 0 else 1.0

        class_weights = torch.tensor([weight_dislike, weight_like], dtype=torch.float32)

        print(f"\nğŸ“Š í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬:")
        print(f"   Like: {n_like}ê±´ (ê°€ì¤‘ì¹˜: {weight_like:.3f})")
        print(f"   Dislike: {n_dislike}ê±´ (ê°€ì¤‘ì¹˜: {weight_dislike:.3f})")

        return class_weights

    def train(self, batch_size=64, max_epochs=50, learning_rate=0.001, patience=7):
        """ëª¨ë¸ í•™ìŠµ"""
        print("\n" + "=" * 60)
        print("ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        print("=" * 60)

        # ë°ì´í„° ë¡œë”
        train_loader = DataLoader(self.train_dataset, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(self.val_dataset, batch_size=batch_size)

        # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
        class_weights = self.calculate_class_weights().to(self.device)

        # ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €
        mse_loss = nn.MSELoss()
        ce_loss = nn.CrossEntropyLoss(weight=class_weights)
        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)

        # Early stopping
        best_val_loss = float('inf')
        patience_counter = 0
        best_model_state = None

        for epoch in range(max_epochs):
            # í•™ìŠµ
            self.model.train()
            train_loss = 0.0

            for batch in train_loader:
                face = batch['face'].to(self.device)
                skin = batch['skin'].to(self.device)
                style = batch['style'].to(self.device)
                score_target = batch['score'].to(self.device)
                feedback_target = batch['feedback'].to(self.device)

                optimizer.zero_grad()

                score_pred, feedback_logits = self.model(face, skin, style)

                loss_score = mse_loss(score_pred, score_target)
                loss_feedback = ce_loss(feedback_logits, feedback_target)
                loss = loss_score + 2.0 * loss_feedback

                loss.backward()
                optimizer.step()

                train_loss += loss.item()

            train_loss /= len(train_loader)

            # ê²€ì¦
            val_loss, val_metrics = self.evaluate(val_loader, mse_loss, ce_loss)

            # íˆìŠ¤í† ë¦¬ ì €ì¥
            self.history['train_loss'].append(train_loss)
            self.history['val_loss'].append(val_loss)
            self.history['val_accuracy'].append(val_metrics['accuracy'])
            self.history['val_f1'].append(val_metrics['f1'])

            print(f"Epoch {epoch+1}/{max_epochs} | "
                  f"Train Loss: {train_loss:.4f} | "
                  f"Val Loss: {val_loss:.4f} | "
                  f"Val Acc: {val_metrics['accuracy']:.4f} | "
                  f"Val F1: {val_metrics['f1']:.4f}")

            # Early stopping
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                best_model_state = self.model.state_dict().copy()
                print("   âœ… ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸!")
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    print(f"\nâ¹ï¸ Early stopping (patience={patience})")
                    break

        # ìµœê³  ëª¨ë¸ ë³µì›
        if best_model_state:
            self.model.load_state_dict(best_model_state)

        print("\nâœ… í•™ìŠµ ì™„ë£Œ!")

    def evaluate(self, data_loader, mse_loss, ce_loss):
        """ëª¨ë¸ í‰ê°€"""
        self.model.eval()
        total_loss = 0.0

        all_feedback_preds = []
        all_feedback_targets = []

        with torch.no_grad():
            for batch in data_loader:
                face = batch['face'].to(self.device)
                skin = batch['skin'].to(self.device)
                style = batch['style'].to(self.device)
                score_target = batch['score'].to(self.device)
                feedback_target = batch['feedback'].to(self.device)

                score_pred, feedback_logits = self.model(face, skin, style)

                loss_score = mse_loss(score_pred, score_target)
                loss_feedback = ce_loss(feedback_logits, feedback_target)
                loss = loss_score + 2.0 * loss_feedback

                total_loss += loss.item()

                feedback_pred = torch.argmax(feedback_logits, dim=1)
                all_feedback_preds.extend(feedback_pred.cpu().numpy())
                all_feedback_targets.extend(feedback_target.cpu().numpy())

        total_loss /= len(data_loader)

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        accuracy = accuracy_score(all_feedback_targets, all_feedback_preds)
        precision, recall, f1, _ = precision_recall_fscore_support(
            all_feedback_targets,
            all_feedback_preds,
            average='weighted',
            zero_division=0
        )

        metrics = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1
        }

        return total_loss, metrics

    def test(self):
        """í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€"""
        print("\n" + "=" * 60)
        print("ğŸ§ª í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€")
        print("=" * 60)

        test_loader = DataLoader(self.test_dataset, batch_size=64)

        mse_loss = nn.MSELoss()
        ce_loss = nn.CrossEntropyLoss()

        test_loss, test_metrics = self.evaluate(test_loader, mse_loss, ce_loss)

        print(f"âœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        print(f"   Loss: {test_loss:.4f}")
        print(f"   Accuracy: {test_metrics['accuracy']:.4f}")
        print(f"   Precision: {test_metrics['precision']:.4f}")
        print(f"   Recall: {test_metrics['recall']:.4f}")
        print(f"   F1-Score: {test_metrics['f1']:.4f}")

        return test_metrics

    def save_model(self):
        """ëª¨ë¸ ì €ì¥"""
        print("\n" + "=" * 60)
        print("ğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")
        print("=" * 60)

        # ë²„ì „ë³„ ì €ì¥
        model_path = self.output_dir / f"model_{self.version}.pth"
        torch.save(self.model.state_dict(), model_path)
        print(f"âœ… ëª¨ë¸ ì €ì¥: {model_path}")

        # ìµœì‹  ë²„ì „ ì €ì¥
        model_latest = self.output_dir / "model_latest.pth"
        torch.save(self.model.state_dict(), model_latest)
        print(f"âœ… ìµœì‹  ëª¨ë¸ ì €ì¥: {model_latest}")

        # ë©”íŠ¸ë¦­ ì €ì¥
        metrics_path = self.output_dir / f"metrics_{self.version}.json"
        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(self.history, f, indent=2, ensure_ascii=False)
        print(f"âœ… ë©”íŠ¸ë¦­ ì €ì¥: {metrics_path}")

    def plot_training_curves(self):
        """í•™ìŠµ ê³¡ì„  í”Œë¡¯"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))

        # Loss
        axes[0, 0].plot(self.history['train_loss'], label='Train Loss')
        axes[0, 0].plot(self.history['val_loss'], label='Val Loss')
        axes[0, 0].set_title('Loss Curves')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].legend()
        axes[0, 0].grid(True)

        # Accuracy
        axes[0, 1].plot(self.history['val_accuracy'], label='Val Accuracy', color='green')
        axes[0, 1].set_title('Validation Accuracy')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy')
        axes[0, 1].legend()
        axes[0, 1].grid(True)

        # F1-Score
        axes[1, 0].plot(self.history['val_f1'], label='Val F1-Score', color='orange')
        axes[1, 0].set_title('Validation F1-Score')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('F1-Score')
        axes[1, 0].legend()
        axes[1, 0].grid(True)

        # Summary
        axes[1, 1].axis('off')
        summary_text = f"""
        Training Summary

        Final Train Loss: {self.history['train_loss'][-1]:.4f}
        Final Val Loss: {self.history['val_loss'][-1]:.4f}
        Best Val Accuracy: {max(self.history['val_accuracy']):.4f}
        Best Val F1: {max(self.history['val_f1']):.4f}
        Total Epochs: {len(self.history['train_loss'])}
        """
        axes[1, 1].text(0.1, 0.5, summary_text, fontsize=12, verticalalignment='center')

        plt.tight_layout()

        # ì €ì¥
        plot_path = self.output_dir / f"training_curves_{self.version}.png"
        plt.savefig(plot_path, dpi=150)
        print(f"âœ… í•™ìŠµ ê³¡ì„  ì €ì¥: {plot_path}")

        plt.close()

    def run(self):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("\n" + "ğŸš€" * 30)
        print("ëª¨ë¸ ì¬í•™ìŠµ ì‹œì‘")
        print("ğŸš€" * 30 + "\n")

        # 1. ë°ì´í„° ë¡œë“œ
        self.load_data()

        # 2. ëª¨ë¸ ìƒì„±
        self.build_model()

        # 3. í•™ìŠµ
        self.train()

        # 4. í…ŒìŠ¤íŠ¸
        test_metrics = self.test()

        # 5. ì €ì¥
        self.save_model()
        self.plot_training_curves()

        print("\n" + "=" * 60)
        print("âœ… ëª¨ë¸ ì¬í•™ìŠµ ì™„ë£Œ!")
        print("=" * 60)

        return {
            'version': self.version,
            'test_metrics': test_metrics,
            'model_path': self.output_dir / f"model_{self.version}.pth"
        }


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description="ëª¨ë¸ ì¬í•™ìŠµ")
    parser.add_argument("--batch-size", type=int, default=64, help="ë°°ì¹˜ í¬ê¸°")
    parser.add_argument("--epochs", type=int, default=50, help="ìµœëŒ€ ì—í­ ìˆ˜")
    parser.add_argument("--lr", type=float, default=0.001, help="í•™ìŠµë¥ ")
    parser.add_argument("--patience", type=int, default=7, help="Early stopping patience")

    args = parser.parse_args()

    try:
        trainer = ModelTrainer()
        result = trainer.run()

        print(f"\nâœ… ìƒì„±ëœ ëª¨ë¸:")
        print(f"   ë²„ì „: {result['version']}")
        print(f"   ê²½ë¡œ: {result['model_path']}")
        print(f"   í…ŒìŠ¤íŠ¸ F1: {result['test_metrics']['f1']:.4f}")

        return 0

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
