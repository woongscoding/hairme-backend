#!/usr/bin/env python3
"""
ì—¬ëŸ¬ NPZ íŒŒì¼ì„ í•˜ë‚˜ë¡œ ë³‘í•©

ì‚¬ìš© ì˜ˆì‹œ:
  python merge_npz_files.py batch1.npz batch2.npz -o combined.npz
  python merge_npz_files.py data_source/ai_face_batch*.npz -o data_source/combined.npz

Author: HairMe ML Team
Date: 2025-11-15
"""

import argparse
import numpy as np
from pathlib import Path
import logging
import glob

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def merge_npz_files(input_files, output_file):
    """
    ì—¬ëŸ¬ NPZ íŒŒì¼ì„ ë³‘í•©

    Args:
        input_files: ìž…ë ¥ NPZ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        output_file: ì¶œë ¥ NPZ íŒŒì¼ ê²½ë¡œ
    """
    logger.info(f"ðŸ”„ {len(input_files)}ê°œ íŒŒì¼ ë³‘í•© ì‹œìž‘...")

    all_face_features = []
    all_skin_features = []
    all_hairstyles = []
    all_scores = []
    all_metadata = []

    total_samples = 0

    for i, file_path in enumerate(input_files, 1):
        logger.info(f"[{i}/{len(input_files)}] ë¡œë”©: {file_path}")

        try:
            data = np.load(file_path, allow_pickle=False)

            # ë°ì´í„° ì¶”ì¶œ
            face_features = data['face_features']
            skin_features = data['skin_features']
            hairstyles = data['hairstyles']
            scores = data['scores']
            metadata = data['metadata']

            # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            all_face_features.append(face_features)
            all_skin_features.append(skin_features)
            all_hairstyles.append(hairstyles)
            all_scores.append(scores)
            all_metadata.append(metadata)

            sample_count = len(scores)
            total_samples += sample_count

            logger.info(f"  âœ… {sample_count}ê°œ ìƒ˜í”Œ ì¶”ê°€ (ëˆ„ì : {total_samples}ê°œ)")

        except Exception as e:
            logger.error(f"  âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            continue

    if not all_scores:
        logger.error("âŒ ë³‘í•©í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return

    # NumPy ë°°ì—´ë¡œ ë³‘í•©
    logger.info("ðŸ“Š ë°ì´í„° ë³‘í•© ì¤‘...")

    merged_data = {
        'face_features': np.concatenate(all_face_features, axis=0),
        'skin_features': np.concatenate(all_skin_features, axis=0),
        'hairstyles': np.concatenate(all_hairstyles, axis=0),
        'scores': np.concatenate(all_scores, axis=0),
        'metadata': np.concatenate(all_metadata, axis=0)
    }

    # ì €ìž¥
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    np.savez_compressed(output_file, **merged_data)

    logger.info(f"\n{'='*60}")
    logger.info("âœ… ë³‘í•© ì™„ë£Œ!")
    logger.info(f"{'='*60}")
    logger.info(f"  ì¶œë ¥ íŒŒì¼: {output_file}")
    logger.info(f"  ì´ ìƒ˜í”Œ: {len(merged_data['scores'])}ê°œ")
    logger.info(f"  Face features: {merged_data['face_features'].shape}")
    logger.info(f"  Skin features: {merged_data['skin_features'].shape}")
    logger.info(f"  Hairstyles: {len(merged_data['hairstyles'])}")
    logger.info(f"  Scores: {merged_data['scores'].shape}")
    logger.info(f"{'='*60}")

    # í†µê³„ ì¶œë ¥
    scores = merged_data['scores']
    logger.info("\nðŸ“Š ì ìˆ˜ í†µê³„:")
    logger.info(f"  - ì¶”ì²œ (â‰¥70): {(scores >= 70).sum()}ê°œ")
    logger.info(f"  - ë¹„ì¶”ì²œ (<70): {(scores < 70).sum()}ê°œ")
    logger.info(f"  - í‰ê· : {scores.mean():.1f}")
    logger.info(f"  - í‘œì¤€íŽ¸ì°¨: {scores.std():.1f}")

    # ì–¼êµ´í˜• ë¶„í¬
    from collections import Counter
    metadata = merged_data['metadata']
    face_shapes = [m['face_shape'] for m in metadata]

    logger.info("\nðŸ“Š ì–¼êµ´í˜• ë¶„í¬:")
    for shape, count in Counter(face_shapes).most_common():
        logger.info(f"  - {shape}: {count}ê°œ ({count/len(face_shapes)*100:.1f}%)")

    # í”¼ë¶€í†¤ ë¶„í¬
    skin_tones = [m['skin_tone'] for m in metadata]
    logger.info("\nðŸ“Š í”¼ë¶€í†¤ ë¶„í¬:")
    for tone, count in Counter(skin_tones).most_common():
        logger.info(f"  - {tone}: {count}ê°œ ({count/len(skin_tones)*100:.1f}%)")


def main():
    parser = argparse.ArgumentParser(description="NPZ íŒŒì¼ ë³‘í•©")
    parser.add_argument(
        'input_files',
        nargs='+',
        help='ìž…ë ¥ NPZ íŒŒì¼ë“¤ (glob íŒ¨í„´ ì‚¬ìš© ê°€ëŠ¥)'
    )
    parser.add_argument(
        '-o', '--output',
        required=True,
        help='ì¶œë ¥ NPZ íŒŒì¼ ê²½ë¡œ'
    )

    args = parser.parse_args()

    # Glob íŒ¨í„´ í™•ìž¥
    input_files = []
    for pattern in args.input_files:
        # Glob íŒ¨í„´ì¸ì§€ í™•ì¸
        if '*' in pattern or '?' in pattern:
            matched = glob.glob(pattern)
            input_files.extend(matched)
        else:
            input_files.append(pattern)

    # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    input_files = sorted(set(input_files))

    if not input_files:
        logger.error("âŒ ìž…ë ¥ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        return

    logger.info(f"ðŸ“‚ ìž…ë ¥ íŒŒì¼ {len(input_files)}ê°œ:")
    for f in input_files:
        logger.info(f"  - {f}")
    logger.info("")

    # ë³‘í•© ì‹¤í–‰
    merge_npz_files(input_files, args.output)


if __name__ == "__main__":
    main()
