#!/usr/bin/env python3
"""
ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ëª¨ë¸ ì¬í•™ìŠµ

DBì— ì €ì¥ëœ ì‹¤ì œ ì‚¬ìš©ì í”¼ë“œë°±ìœ¼ë¡œ ML ëª¨ë¸ì„ ì¬í•™ìŠµí•©ë‹ˆë‹¤.

MLOps ì›Œí¬í”Œë¡œìš°:
1. DBì—ì„œ í”¼ë“œë°± ë°ì´í„° ë¡œë“œ
2. ê¸°ì¡´ í•©ì„± ë°ì´í„°ì™€ ë³‘í•©
3. ëª¨ë¸ ì¬í•™ìŠµ
4. ì„±ëŠ¥ í‰ê°€
5. ëª¨ë¸ ë°°í¬

Author: HairMe ML Team
Date: 2025-11-08
Version: 1.0.0
"""

import argparse
import sys
import time
from pathlib import Path
from typing import List, Dict, Tuple
import numpy as np
import json

# Windows ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# SQLAlchemy imports
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split


# ==================== ì„¤ì • ====================
class Config:
    """ì¬í•™ìŠµ ì„¤ì •"""

    # DB ì—°ê²° (í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
    DB_URL = "sqlite:///./hairstyle.db"  # ê¸°ë³¸ê°’

    # ëª¨ë¸ ê²½ë¡œ
    MODEL_PATH = "models/hairstyle_recommender.pt"
    EMBEDDINGS_PATH = "data_source/style_embeddings.npz"
    BACKUP_DIR = "models/backups"

    # í•™ìŠµ ì„¤ì •
    BATCH_SIZE = 32
    LEARNING_RATE = 0.0005  # ì¬í•™ìŠµì€ ë‚®ì€ learning rate
    NUM_EPOCHS = 50
    EARLY_STOPPING_PATIENCE = 10

    # ë°ì´í„° ë¹„ìœ¨
    MIN_FEEDBACK_COUNT = 10  # ìµœì†Œ í”¼ë“œë°± ê°œìˆ˜
    SYNTHETIC_WEIGHT = 0.7   # í•©ì„± ë°ì´í„° ê°€ì¤‘ì¹˜
    FEEDBACK_WEIGHT = 0.3    # í”¼ë“œë°± ë°ì´í„° ê°€ì¤‘ì¹˜


# ==================== DB ëª¨ë¸ (ê°„ì†Œí™”) ====================
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy import Column, Integer, String, Float, DateTime

Base = declarative_base()


class UserFeedback(Base):
    """ì‚¬ìš©ì í”¼ë“œë°± í…Œì´ë¸”"""
    __tablename__ = "user_feedback"

    id = Column(Integer, primary_key=True)
    face_shape = Column(String(20))
    skin_tone = Column(String(20))
    hairstyle = Column(String(100))
    reaction = Column(Integer)  # 1: ì¢‹ì•„ìš”, 0: ì‹«ì–´ìš”
    ml_score = Column(Float)
    created_at = Column(DateTime)


# ==================== ë°ì´í„° ë¡œë” ====================
class FeedbackLoader:
    """DBì—ì„œ í”¼ë“œë°± ë°ì´í„° ë¡œë“œ"""

    def __init__(self, db_url: str):
        """ì´ˆê¸°í™”"""
        self.engine = create_engine(db_url)
        Session = sessionmaker(bind=self.engine)
        self.session = Session()

    def load_feedbacks(self) -> List[Dict]:
        """
        DBì—ì„œ í”¼ë“œë°± ë¡œë“œ

        Returns:
            í”¼ë“œë°± ë¦¬ìŠ¤íŠ¸
        """
        print(f"\nğŸ“‚ DBì—ì„œ í”¼ë“œë°± ë¡œë”©...")

        feedbacks = self.session.query(UserFeedback).all()

        results = []
        for fb in feedbacks:
            results.append({
                "face_shape": fb.face_shape,
                "skin_tone": fb.skin_tone,
                "hairstyle": fb.hairstyle,
                "reaction": fb.reaction,  # 1 or 0
                "ml_score": fb.ml_score
            })

        print(f"  âœ… {len(results)}ê°œ í”¼ë“œë°± ë¡œë“œ")

        # í†µê³„
        likes = sum(1 for r in results if r["reaction"] == 1)
        dislikes = len(results) - likes

        print(f"  ğŸ“Š ì¢‹ì•„ìš”: {likes}ê°œ, ì‹«ì–´ìš”: {dislikes}ê°œ")

        return results

    def close(self):
        """ì„¸ì…˜ ì¢…ë£Œ"""
        self.session.close()


class DataMerger:
    """í•©ì„± ë°ì´í„°ì™€ í”¼ë“œë°± ë°ì´í„° ë³‘í•©"""

    FACE_SHAPES = ["ê°ì§„í˜•", "ë‘¥ê·¼í˜•", "ê¸´í˜•", "ê³„ë€í˜•"]
    SKIN_TONES = ["ê²¨ìš¸ì¿¨", "ê°€ì„ì›œ", "ë´„ì›œ", "ì—¬ë¦„ì¿¨"]

    def __init__(self, embeddings_path: str):
        """ì´ˆê¸°í™”"""
        # ì„ë² ë”© ë¡œë“œ
        data = np.load(embeddings_path, allow_pickle=True)
        self.styles = data['styles'].tolist()
        self.embeddings = data['embeddings']
        self.style_to_idx = {style: idx for idx, style in enumerate(self.styles)}

    @staticmethod
    def get_adjustment_factors(feedback_count: int) -> Tuple[float, float]:
        """
        í”¼ë“œë°± ê°œìˆ˜ì— ë”°ë¼ ì¡°ì • ë¹„ìœ¨ ê²°ì •

        Args:
            feedback_count: ì´ í”¼ë“œë°± ê°œìˆ˜

        Returns:
            (boost_factor, penalty_factor) - ì¢‹ì•„ìš”/ì‹«ì–´ìš” ì¡°ì • ë¹„ìœ¨
        """
        if feedback_count < 100:
            # Phase 1: ì´ˆê¸° - ê³µê²©ì  í•™ìŠµ (ë¹ ë¥¸ ë‹¤ì–‘ì„± í™•ë³´)
            return 1.2, 0.8  # 20% ë³€í™”
        elif feedback_count < 500:
            # Phase 2: ì„±ì¥ - í‘œì¤€ í•™ìŠµ (ê· í˜•)
            return 1.15, 0.85  # 15% ë³€í™”
        else:
            # Phase 3: ì•ˆì • - ë³´ìˆ˜ì  í•™ìŠµ (Fine-tuning)
            return 1.1, 0.9  # 10% ë³€í™”

    def convert_feedback_to_training_data(
        self,
        feedbacks: List[Dict]
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        í”¼ë“œë°±ì„ í•™ìŠµ ë°ì´í„°ë¡œ ë³€í™˜

        Args:
            feedbacks: í”¼ë“œë°± ë¦¬ìŠ¤íŠ¸

        Returns:
            (X, y) - íŠ¹ì§• í–‰ë ¬, íƒ€ê²Ÿ ë²¡í„°
        """
        print(f"\nğŸ”„ í”¼ë“œë°± ë°ì´í„° ë³€í™˜ ì¤‘...")

        # í”¼ë“œë°± ê°œìˆ˜ì— ë”°ë¼ ì¡°ì • ë¹„ìœ¨ ê²°ì •
        feedback_count = len(feedbacks)
        boost_factor, penalty_factor = self.get_adjustment_factors(feedback_count)

        if feedback_count < 100:
            phase = "Phase 1: ì´ˆê¸° (ê³µê²©ì )"
        elif feedback_count < 500:
            phase = "Phase 2: ì„±ì¥ (í‘œì¤€)"
        else:
            phase = "Phase 3: ì•ˆì • (ë³´ìˆ˜ì )"

        print(f"  ğŸ“Š {phase}")
        print(f"  ğŸ“ˆ ì¡°ì • ë¹„ìœ¨: ì¢‹ì•„ìš” {boost_factor}ë°°, ì‹«ì–´ìš” {penalty_factor}ë°°")

        X_list = []
        y_list = []

        for fb in feedbacks:
            # ì–¼êµ´í˜• one-hot
            face_vec = np.zeros(4, dtype=np.float32)
            if fb["face_shape"] in self.FACE_SHAPES:
                idx = self.FACE_SHAPES.index(fb["face_shape"])
                face_vec[idx] = 1.0

            # í”¼ë¶€í†¤ one-hot
            tone_vec = np.zeros(4, dtype=np.float32)
            if fb["skin_tone"] in self.SKIN_TONES:
                idx = self.SKIN_TONES.index(fb["skin_tone"])
                tone_vec[idx] = 1.0

            # í—¤ì–´ìŠ¤íƒ€ì¼ ì„ë² ë”©
            hairstyle = fb["hairstyle"]
            if hairstyle not in self.style_to_idx:
                continue  # ë¯¸ë“±ë¡ ìŠ¤íƒ€ì¼ ìŠ¤í‚µ

            style_idx = self.style_to_idx[hairstyle]
            style_vec = self.embeddings[style_idx]

            # íŠ¹ì§• ë²¡í„° ìƒì„±
            feature = np.concatenate([face_vec, tone_vec, style_vec])
            X_list.append(feature)

            # íƒ€ê²Ÿ ì ìˆ˜ ìƒì„± (ë™ì  ë¹„ë¡€ ì¡°ì •)
            # í”¼ë“œë°± ê°œìˆ˜ì— ë”°ë¼ ì¡°ì • ê°•ë„ ìë™ ë³€í™”
            ml_score = fb["ml_score"]
            if fb["reaction"] == 1:
                score = ml_score * boost_factor  # ì¢‹ì•„ìš”
            else:
                score = ml_score * penalty_factor  # ì‹«ì–´ìš”

            # 0-100 ë²”ìœ„ ì œí•œ
            score = max(0.0, min(100.0, score))

            y_list.append(score)

        X = np.array(X_list, dtype=np.float32)
        y = np.array(y_list, dtype=np.float32)

        print(f"  âœ… ë³€í™˜ ì™„ë£Œ: {len(X)}ê°œ ìƒ˜í”Œ")
        print(f"  ğŸ“Š ì ìˆ˜ ë²”ìœ„: {y.min():.1f} ~ {y.max():.1f}")

        return X, y

    def merge_with_synthetic(
        self,
        feedback_X: np.ndarray,
        feedback_y: np.ndarray,
        synthetic_path: str,
        synthetic_weight: float = 0.7,
        feedback_weight: float = 0.3
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        í”¼ë“œë°± ë°ì´í„°ì™€ í•©ì„± ë°ì´í„° ë³‘í•©

        Args:
            feedback_X, feedback_y: í”¼ë“œë°± ë°ì´í„°
            synthetic_path: í•©ì„± ë°ì´í„° ê²½ë¡œ
            synthetic_weight: í•©ì„± ë°ì´í„° ê°€ì¤‘ì¹˜
            feedback_weight: í”¼ë“œë°± ë°ì´í„° ê°€ì¤‘ì¹˜

        Returns:
            (X_merged, y_merged)
        """
        print(f"\nğŸ”— í•©ì„± ë°ì´í„°ì™€ ë³‘í•© ì¤‘...")

        # í•©ì„± ë°ì´í„° ë¡œë“œ
        synthetic_data = np.load(synthetic_path)
        synthetic_X_train = synthetic_data['X_train']
        synthetic_y_train = synthetic_data['y_train']

        print(f"  í•©ì„± ë°ì´í„°: {len(synthetic_X_train)}ê°œ")
        print(f"  í”¼ë“œë°± ë°ì´í„°: {len(feedback_X)}ê°œ")

        # ìƒ˜í”Œ ìˆ˜ ì¡°ì • (ê°€ì¤‘ì¹˜ ì ìš©)
        synthetic_count = int(len(synthetic_X_train) * synthetic_weight / (synthetic_weight + feedback_weight))
        feedback_count = int(len(feedback_X) * feedback_weight / (synthetic_weight + feedback_weight))

        # ìƒ˜í”Œë§
        synthetic_indices = np.random.choice(len(synthetic_X_train), synthetic_count, replace=False)
        feedback_indices = np.random.choice(len(feedback_X), min(feedback_count, len(feedback_X)), replace=True)

        X_merged = np.vstack([
            synthetic_X_train[synthetic_indices],
            feedback_X[feedback_indices]
        ])

        y_merged = np.concatenate([
            synthetic_y_train[synthetic_indices],
            feedback_y[feedback_indices]
        ])

        print(f"  âœ… ë³‘í•© ì™„ë£Œ: {len(X_merged)}ê°œ (í•©ì„± {synthetic_count} + í”¼ë“œë°± {len(feedback_indices)})")

        return X_merged, y_merged


# ==================== ëª¨ë¸ ë° í•™ìŠµ (ê¸°ì¡´ ì½”ë“œ ì¬ì‚¬ìš©) ====================
class RecommendationModel(nn.Module):
    """PyTorch ì¶”ì²œ ëª¨ë¸"""

    def __init__(self, input_dim: int = 392):
        super(RecommendationModel, self).__init__()

        hidden_dims = [256, 128, 64]
        dropout_rates = [0.3, 0.2, 0.0]

        layers = []
        prev_dim = input_dim

        for hidden_dim, dropout_rate in zip(hidden_dims, dropout_rates):
            layers.append(nn.Linear(prev_dim, hidden_dim))
            layers.append(nn.ReLU())

            if dropout_rate > 0:
                layers.append(nn.Dropout(dropout_rate))

            prev_dim = hidden_dim

        layers.append(nn.Linear(prev_dim, 1))

        self.network = nn.Sequential(*layers)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.network(x)


class HairstyleDataset(Dataset):
    """PyTorch Dataset"""

    def __init__(self, X: np.ndarray, y: np.ndarray):
        self.X = torch.FloatTensor(X)
        self.y = torch.FloatTensor(y).unsqueeze(1)

    def __len__(self) -> int:
        return len(self.X)

    def __getitem__(self, idx: int):
        return self.X[idx], self.y[idx]


def retrain_model(
    X_train: np.ndarray,
    y_train: np.ndarray,
    X_val: np.ndarray,
    y_val: np.ndarray,
    model_path: str,
    num_epochs: int = 50
):
    """ëª¨ë¸ ì¬í•™ìŠµ"""

    print(f"\nğŸš€ ëª¨ë¸ ì¬í•™ìŠµ ì‹œì‘...")

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ
    model = RecommendationModel()
    model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))
    model.to(device)

    # ë°ì´í„°ì…‹
    train_dataset = HairstyleDataset(X_train, y_train)
    val_dataset = HairstyleDataset(X_val, y_val)

    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)

    # ì˜µí‹°ë§ˆì´ì €
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=Config.LEARNING_RATE)

    best_val_loss = float('inf')
    patience_counter = 0

    for epoch in range(num_epochs):
        # Train
        model.train()
        train_loss = 0.0
        for X_batch, y_batch in train_loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)

            optimizer.zero_grad()
            predictions = model(X_batch)
            loss = criterion(predictions, y_batch)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

        train_loss /= len(train_loader)

        # Validate
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for X_batch, y_batch in val_loader:
                X_batch, y_batch = X_batch.to(device), y_batch.to(device)
                predictions = model(X_batch)
                loss = criterion(predictions, y_batch)
                val_loss += loss.item()

        val_loss /= len(val_loader)

        if (epoch + 1) % 10 == 0:
            print(f"  Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")

        # Early Stopping
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
        else:
            patience_counter += 1

        if patience_counter >= Config.EARLY_STOPPING_PATIENCE:
            print(f"\n  âš ï¸  Early Stopping at epoch {epoch+1}")
            break

    print(f"\n  âœ… ì¬í•™ìŠµ ì™„ë£Œ! ìµœì¢… Val Loss: {val_loss:.4f}")

    return model


# ==================== ë©”ì¸ í•¨ìˆ˜ ====================
def main():
    """ë©”ì¸ ì‹¤í–‰"""

    parser = argparse.ArgumentParser(description="ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ëª¨ë¸ ì¬í•™ìŠµ")
    parser.add_argument('--db-url', type=str, default=Config.DB_URL, help='DB URL')
    parser.add_argument('--min-feedbacks', type=int, default=Config.MIN_FEEDBACK_COUNT, help='ìµœì†Œ í”¼ë“œë°± ê°œìˆ˜')

    args = parser.parse_args()

    print("=" * 60)
    print("ğŸ”„ MLOps ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸ v1.0.0")
    print("=" * 60)

    try:
        # 1. í”¼ë“œë°± ë¡œë“œ
        loader = FeedbackLoader(args.db_url)
        feedbacks = loader.load_feedbacks()
        loader.close()

        if len(feedbacks) < args.min_feedbacks:
            print(f"\nâš ï¸  í”¼ë“œë°±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤ ({len(feedbacks)}ê°œ < {args.min_feedbacks}ê°œ)")
            print("   ë” ë§ì€ í”¼ë“œë°±ì„ ìˆ˜ì§‘í•œ í›„ ì¬í•™ìŠµí•˜ì„¸ìš”.")
            return 1

        # 2. í”¼ë“œë°± ë°ì´í„° ë³€í™˜
        merger = DataMerger(Config.EMBEDDINGS_PATH)
        feedback_X, feedback_y = merger.convert_feedback_to_training_data(feedbacks)

        # 3. í•©ì„± ë°ì´í„°ì™€ ë³‘í•©
        X_merged, y_merged = merger.merge_with_synthetic(
            feedback_X, feedback_y,
            "data_source/ml_training_dataset.npz",
            Config.SYNTHETIC_WEIGHT,
            Config.FEEDBACK_WEIGHT
        )

        # 4. Train/Val split
        X_train, X_val, y_train, y_val = train_test_split(
            X_merged, y_merged,
            test_size=0.2,
            random_state=42
        )

        print(f"\nğŸ“Š ìµœì¢… ë°ì´í„°:")
        print(f"  - Train: {len(X_train)}ê°œ")
        print(f"  - Val: {len(X_val)}ê°œ")

        # 5. ê¸°ì¡´ ëª¨ë¸ ë°±ì—…
        backup_dir = Path(Config.BACKUP_DIR)
        backup_dir.mkdir(parents=True, exist_ok=True)

        timestamp = time.strftime("%Y%m%d_%H%M%S")
        backup_path = backup_dir / f"model_backup_{timestamp}.pt"

        import shutil
        shutil.copy(Config.MODEL_PATH, backup_path)
        print(f"\nğŸ’¾ ê¸°ì¡´ ëª¨ë¸ ë°±ì—…: {backup_path}")

        # 6. ì¬í•™ìŠµ
        new_model = retrain_model(X_train, y_train, X_val, y_val, Config.MODEL_PATH, Config.NUM_EPOCHS)

        # 7. ìƒˆ ëª¨ë¸ ì €ì¥
        torch.save(new_model.state_dict(), Config.MODEL_PATH)
        print(f"âœ… ìƒˆ ëª¨ë¸ ì €ì¥: {Config.MODEL_PATH}")

        print("\n" + "=" * 60)
        print("ğŸ‰ ì¬í•™ìŠµ ì™„ë£Œ!")
        print("=" * 60)
        print(f"ğŸ“Š ê²°ê³¼:")
        print(f"  - í”¼ë“œë°± ë°ì´í„°: {len(feedbacks)}ê°œ")
        print(f"  - ìµœì¢… í•™ìŠµ ë°ì´í„°: {len(X_train)}ê°œ")
        print(f"  - ë°±ì—… íŒŒì¼: {backup_path.name}")
        print("=" * 60)

        return 0

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
