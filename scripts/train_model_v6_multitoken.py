#!/usr/bin/env python3
"""
v6 ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ - Multi-Token Attention ë²„ì „

**í•µì‹¬ ê°œì„  (v5 ëŒ€ë¹„):**
- ê¸°ì¡´: ë‹¨ì¼ í† í°(480ì°¨ì›)ì— self-attention â†’ ì‚¬ì‹¤ìƒ identity (ë¬´ì˜ë¯¸)
- ê°œì„ : face/skin/style 3ê°œ í† í° ê°„ cross-attention â†’ ì˜ë¯¸ ìˆëŠ” ìƒí˜¸ì‘ìš© í•™ìŠµ

**êµ¬ì¡°:**
1. Input Projection: face(6â†’64), skin(2â†’32)
2. Multi-Token Attention: 3ê°œ í† í°ì„ 128ì°¨ì›ìœ¼ë¡œ í†µì¼ í›„ self-attention
3. Feature Fusion: attention ì¶œë ¥(384) â†’ MLP â†’ score

**ë¼ë²¨ ì •ê·œí™” (v5 ë™ì¼):**
- ì›ë³¸ ì ìˆ˜ ë²”ìœ„: 10~95ì 
- normalized_label = (label - 10) / 85
- ì—­ë³€í™˜: final_score = model_output * 85 + 10

Author: HairMe ML Team
Date: 2025-12-02
"""

import os
import sys
import argparse
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, Subset
from pathlib import Path
import logging
from typing import Dict, Tuple, List
from datetime import datetime
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from sentence_transformers import SentenceTransformer

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)
logger = logging.getLogger(__name__)

# ========== ë¼ë²¨ ì •ê·œí™” ìƒìˆ˜ ==========
LABEL_MIN = 10.0   # ì›ë³¸ ì ìˆ˜ ìµœì†Œê°’
LABEL_MAX = 95.0   # ì›ë³¸ ì ìˆ˜ ìµœëŒ€ê°’
LABEL_RANGE = LABEL_MAX - LABEL_MIN  # 85


def normalize_score(score: np.ndarray) -> np.ndarray:
    """ì›ë³¸ ì ìˆ˜ë¥¼ 0~1ë¡œ ì •ê·œí™”"""
    return (score - LABEL_MIN) / LABEL_RANGE


def denormalize_score(normalized: np.ndarray) -> np.ndarray:
    """0~1 ì ìˆ˜ë¥¼ ì›ë³¸ ìŠ¤ì¼€ì¼ë¡œ ì—­ë³€í™˜"""
    return normalized * LABEL_RANGE + LABEL_MIN


# ========== Multi-Token Attention Layer ==========
class MultiTokenAttentionLayer(nn.Module):
    """
    3-Token Cross-Attention Layer

    face_proj, skin_proj, style_embë¥¼ 3ê°œì˜ ê°œë³„ í† í°ìœ¼ë¡œ êµ¬ì„±í•˜ì—¬
    í† í° ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ í•™ìŠµí•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        face_dim: int = 64,
        skin_dim: int = 32,
        style_dim: int = 384,
        token_dim: int = 128,
        num_heads: int = 4,
        dropout: float = 0.1
    ):
        super().__init__()
        self.token_dim = token_dim

        # ê° ì…ë ¥ì„ ë™ì¼í•œ token_dimìœ¼ë¡œ projection
        self.face_to_token = nn.Linear(face_dim, token_dim)
        self.skin_to_token = nn.Linear(skin_dim, token_dim)
        self.style_to_token = nn.Linear(style_dim, token_dim)

        # Multi-head self-attention (3 tokens)
        self.attention = nn.MultiheadAttention(
            embed_dim=token_dim,
            num_heads=num_heads,
            dropout=dropout,
            batch_first=True
        )
        self.norm1 = nn.LayerNorm(token_dim)

        # Feed-forward network
        self.ffn = nn.Sequential(
            nn.Linear(token_dim, token_dim * 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(token_dim * 2, token_dim)
        )
        self.norm2 = nn.LayerNorm(token_dim)
        self.dropout = nn.Dropout(dropout)

    def forward(
        self,
        face_proj: torch.Tensor,  # (batch, 64)
        skin_proj: torch.Tensor,  # (batch, 32)
        style_emb: torch.Tensor   # (batch, 384)
    ) -> torch.Tensor:
        """
        Returns:
            (batch, token_dim * 3) - 3ê°œ í† í°ì˜ concat ê²°ê³¼
        """
        batch_size = face_proj.size(0)

        # ê° íŠ¹ì§•ì„ token_dimìœ¼ë¡œ projection
        face_token = self.face_to_token(face_proj)   # (batch, token_dim)
        skin_token = self.skin_to_token(skin_proj)   # (batch, token_dim)
        style_token = self.style_to_token(style_emb) # (batch, token_dim)

        # 3ê°œ í† í°ìœ¼ë¡œ ì‹œí€€ìŠ¤ êµ¬ì„±: (batch, 3, token_dim)
        tokens = torch.stack([face_token, skin_token, style_token], dim=1)

        # Self-attention across 3 tokens
        attn_out, _ = self.attention(tokens, tokens, tokens)
        tokens = self.norm1(tokens + self.dropout(attn_out))

        # Feed-forward network
        ffn_out = self.ffn(tokens)
        tokens = self.norm2(tokens + self.dropout(ffn_out))

        # 3ê°œ í† í°ì„ flattení•˜ì—¬ ë°˜í™˜: (batch, token_dim * 3)
        output = tokens.reshape(batch_size, -1)

        return output


# ========== ëª¨ë¸ ì •ì˜ (V6) ==========
class RecommendationModelV6(nn.Module):
    """
    Multi-Token Attention ê¸°ë°˜ ì¶”ì²œ ëª¨ë¸ v6

    í•µì‹¬ íŠ¹ì§•:
    - 3ê°œ í† í°(face, skin, style) ê°„ cross-attention
    - ì¶œë ¥ì¸µì— Sigmoid í™œì„±í™” í•¨ìˆ˜ ì‚¬ìš© (0~1 ì¶œë ¥ ë³´ì¥)
    - ì¶”ë¡  ì‹œ ì—­ë³€í™˜ í•„ìš” (0~1 â†’ 10~95)
    """

    def __init__(
        self,
        face_feat_dim: int = 6,
        skin_feat_dim: int = 2,
        style_embed_dim: int = 384,
        token_dim: int = 128,
        num_heads: int = 4,
        dropout_rate: float = 0.3
    ):
        super().__init__()

        self.face_feat_dim = face_feat_dim
        self.skin_feat_dim = skin_feat_dim
        self.style_embed_dim = style_embed_dim

        # Input projection layers (attention ì´ì „)
        self.face_projection = nn.Sequential(
            nn.Linear(face_feat_dim, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(dropout_rate * 0.5)
        )

        self.skin_projection = nn.Sequential(
            nn.Linear(skin_feat_dim, 32),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.Dropout(dropout_rate * 0.5)
        )

        # Multi-Token Attention Layer (3ê°œ í† í° ê°„ ìƒí˜¸ì‘ìš©)
        self.multi_token_attention = MultiTokenAttentionLayer(
            face_dim=64,
            skin_dim=32,
            style_dim=style_embed_dim,
            token_dim=token_dim,
            num_heads=num_heads,
            dropout=dropout_rate * 0.3
        )

        # Attention ì¶œë ¥ ì°¨ì›: token_dim * 3 = 384
        attention_out_dim = token_dim * 3

        # Feature fusion network
        self.fc1 = nn.Linear(attention_out_dim, 256)
        self.bn1 = nn.BatchNorm1d(256)
        self.dropout1 = nn.Dropout(dropout_rate)

        self.fc2 = nn.Linear(256, 128)
        self.bn2 = nn.BatchNorm1d(128)
        self.dropout2 = nn.Dropout(dropout_rate * 0.7)

        # Residual connection
        self.residual_proj = nn.Linear(attention_out_dim, 128)

        self.fc3 = nn.Linear(128, 64)
        self.bn3 = nn.BatchNorm1d(64)
        self.dropout3 = nn.Dropout(dropout_rate * 0.5)

        self.fc4 = nn.Linear(64, 32)
        self.fc_out = nn.Linear(32, 1)

        # Sigmoid í™œì„±í™” í•¨ìˆ˜ - ì¶œë ¥ì„ 0~1ë¡œ ì œí•œ
        self.sigmoid = nn.Sigmoid()

    def forward(
        self,
        face_features: torch.Tensor,
        skin_features: torch.Tensor,
        style_emb: torch.Tensor
    ) -> torch.Tensor:
        """Forward pass - ì¶œë ¥ ë²”ìœ„: 0~1 (Sigmoid)"""
        # 1. Input projection
        face_proj = self.face_projection(face_features)  # (batch, 64)
        skin_proj = self.skin_projection(skin_features)  # (batch, 32)

        # 2. Multi-Token Attention (3ê°œ í† í° ê°„ ìƒí˜¸ì‘ìš©)
        x = self.multi_token_attention(face_proj, skin_proj, style_emb)  # (batch, 384)

        # Store for residual
        residual = self.residual_proj(x)

        # 3. Feature fusion MLP
        x = self.fc1(x)
        x = self.bn1(x)
        x = torch.relu(x)
        x = self.dropout1(x)

        x = self.fc2(x)
        x = self.bn2(x)
        x = torch.relu(x)
        x = self.dropout2(x)

        # Add residual connection
        x = x + residual

        x = self.fc3(x)
        x = self.bn3(x)
        x = torch.relu(x)
        x = self.dropout3(x)

        x = self.fc4(x)
        x = torch.relu(x)

        x = self.fc_out(x)

        # Sigmoidë¡œ 0~1 ì¶œë ¥ ë³´ì¥
        x = self.sigmoid(x)

        return x.squeeze(-1)


# ========== ë°ì´í„°ì…‹ ==========
class HairstyleDatasetV6(Dataset):
    """ì •ê·œí™”ëœ ë¼ë²¨ ê¸°ë°˜ í—¤ì–´ìŠ¤íƒ€ì¼ ë°ì´í„°ì…‹"""

    def __init__(
        self,
        face_features: np.ndarray,
        skin_features: np.ndarray,
        style_embeddings: np.ndarray,
        scores: np.ndarray,
        normalize_labels: bool = True
    ):
        self.face_features = torch.tensor(face_features, dtype=torch.float32)
        self.skin_features = torch.tensor(skin_features, dtype=torch.float32)
        self.style_embeddings = torch.tensor(style_embeddings, dtype=torch.float32)

        if normalize_labels:
            normalized_scores = normalize_score(scores)
            self.scores = torch.tensor(normalized_scores, dtype=torch.float32).unsqueeze(1)
            logger.info(f"  ë¼ë²¨ ì •ê·œí™” ì ìš©: {scores.min():.1f}~{scores.max():.1f} â†’ {normalized_scores.min():.3f}~{normalized_scores.max():.3f}")
        else:
            self.scores = torch.tensor(scores, dtype=torch.float32).unsqueeze(1)

    def __len__(self):
        return len(self.scores)

    def __getitem__(self, idx):
        return (
            self.face_features[idx],
            self.skin_features[idx],
            self.style_embeddings[idx],
            self.scores[idx]
        )


def load_training_data(data_path: str) -> Dict:
    """NPZ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    logger.info(f"ğŸ“‚ ë°ì´í„° ë¡œë”©: {data_path}")

    data = np.load(data_path, allow_pickle=True)

    face_features = data['face_features']
    skin_features = data['skin_features']
    hairstyles = data['hairstyles']
    scores = data['scores']

    logger.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ:")
    logger.info(f"  - ìƒ˜í”Œ ìˆ˜: {len(scores):,}")
    logger.info(f"  - Face features: {face_features.shape}")
    logger.info(f"  - Skin features: {skin_features.shape}")
    logger.info(f"  - Hairstyles: {len(hairstyles)}")

    # í—¤ì–´ìŠ¤íƒ€ì¼ ì„ë² ë”© ìƒì„±
    logger.info("ğŸ”„ í—¤ì–´ìŠ¤íƒ€ì¼ ì„ë² ë”© ìƒì„± ì¤‘...")
    sentence_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    style_embeddings = sentence_model.encode(
        hairstyles.tolist(),
        show_progress_bar=True,
        convert_to_numpy=True
    )

    logger.info(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ: {style_embeddings.shape}")

    # í†µê³„
    logger.info(f"\nğŸ“Š ì›ë³¸ ë°ì´í„° í†µê³„:")
    logger.info(f"  - ì ìˆ˜ ë²”ìœ„: {scores.min():.1f} ~ {scores.max():.1f}")
    logger.info(f"  - ì ìˆ˜ í‰ê· : {scores.mean():.1f} Â± {scores.std():.1f}")
    logger.info(f"  - ê³ ì ìˆ˜ (â‰¥75): {(scores >= 75).sum():,}ê°œ ({(scores >= 75).sum()/len(scores)*100:.1f}%)")
    logger.info(f"  - ì €ì ìˆ˜ (â‰¤40): {(scores <= 40).sum():,}ê°œ ({(scores <= 40).sum()/len(scores)*100:.1f}%)")

    return {
        'face_features': face_features,
        'skin_features': skin_features,
        'style_embeddings': style_embeddings,
        'scores': scores,
        'hairstyles': hairstyles
    }


def create_dataloaders_no_leakage(
    data: Dict,
    batch_size: int = 64,
    val_ratio: float = 0.15,
    test_ratio: float = 0.15,
    samples_per_face: int = 6
) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€: ì–¼êµ´ ë‹¨ìœ„ë¡œ train/val/test ë¶„í• """

    dataset = HairstyleDatasetV6(
        face_features=data['face_features'],
        skin_features=data['skin_features'],
        style_embeddings=data['style_embeddings'],
        scores=data['scores'],
        normalize_labels=True
    )

    total_samples = len(dataset)
    num_faces = total_samples // samples_per_face

    logger.info(f"\nğŸ” ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€ ëª¨ë“œ:")
    logger.info(f"  - ì´ ìƒ˜í”Œ: {total_samples:,}ê°œ")
    logger.info(f"  - ì´ ì–¼êµ´: {num_faces:,}ê°œ")
    logger.info(f"  - ì–¼êµ´ë‹¹ ìƒ˜í”Œ: {samples_per_face}ê°œ")

    np.random.seed(42)
    face_indices = np.random.permutation(num_faces)

    num_test_faces = int(num_faces * test_ratio)
    num_val_faces = int(num_faces * val_ratio)
    num_train_faces = num_faces - num_test_faces - num_val_faces

    train_face_indices = face_indices[:num_train_faces]
    val_face_indices = face_indices[num_train_faces:num_train_faces + num_val_faces]
    test_face_indices = face_indices[num_train_faces + num_val_faces:]

    logger.info(f"\nğŸ“Š ì–¼êµ´ ë‹¨ìœ„ ë¶„í• :")
    logger.info(f"  - Train: {num_train_faces:,}ê°œ ì–¼êµ´ ({num_train_faces/num_faces*100:.1f}%)")
    logger.info(f"  - Val:   {num_val_faces:,}ê°œ ì–¼êµ´ ({num_val_faces/num_faces*100:.1f}%)")
    logger.info(f"  - Test:  {num_test_faces:,}ê°œ ì–¼êµ´ ({num_test_faces/num_faces*100:.1f}%)")

    def face_indices_to_sample_indices(face_idxs: np.ndarray) -> List[int]:
        sample_idxs = []
        for face_idx in face_idxs:
            start = face_idx * samples_per_face
            end = start + samples_per_face
            sample_idxs.extend(range(start, end))
        return sample_idxs

    train_sample_indices = face_indices_to_sample_indices(train_face_indices)
    val_sample_indices = face_indices_to_sample_indices(val_face_indices)
    test_sample_indices = face_indices_to_sample_indices(test_face_indices)

    train_dataset = Subset(dataset, train_sample_indices)
    val_dataset = Subset(dataset, val_sample_indices)
    test_dataset = Subset(dataset, test_sample_indices)

    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=0,
        pin_memory=True
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=True
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=True
    )

    return train_loader, val_loader, test_loader


def train_epoch(
    model: nn.Module,
    train_loader: DataLoader,
    optimizer: optim.Optimizer,
    criterion: nn.Module,
    device: torch.device
) -> float:
    """1 ì—í­ í•™ìŠµ"""
    model.train()
    total_loss = 0.0

    for face_feat, skin_feat, style_emb, scores in train_loader:
        face_feat = face_feat.to(device)
        skin_feat = skin_feat.to(device)
        style_emb = style_emb.to(device)
        scores = scores.to(device)

        optimizer.zero_grad()
        pred_scores = model(face_feat, skin_feat, style_emb)

        loss = criterion(pred_scores.unsqueeze(1), scores)

        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    avg_loss = total_loss / len(train_loader)
    return avg_loss


def validate(
    model: nn.Module,
    val_loader: DataLoader,
    criterion: nn.Module,
    device: torch.device
) -> Tuple[float, float, float]:
    """ê²€ì¦"""
    model.eval()
    total_loss = 0.0
    total_normalized_mae = 0.0
    total_original_mae = 0.0

    with torch.no_grad():
        for face_feat, skin_feat, style_emb, scores in val_loader:
            face_feat = face_feat.to(device)
            skin_feat = skin_feat.to(device)
            style_emb = style_emb.to(device)
            scores = scores.to(device)

            pred_scores = model(face_feat, skin_feat, style_emb)

            loss = criterion(pred_scores.unsqueeze(1), scores)
            normalized_mae = torch.abs(pred_scores.unsqueeze(1) - scores).mean()

            pred_original = pred_scores.unsqueeze(1) * LABEL_RANGE + LABEL_MIN
            scores_original = scores * LABEL_RANGE + LABEL_MIN
            original_mae = torch.abs(pred_original - scores_original).mean()

            total_loss += loss.item()
            total_normalized_mae += normalized_mae.item()
            total_original_mae += original_mae.item()

    num_batches = len(val_loader)
    return (
        total_loss / num_batches,
        total_normalized_mae / num_batches,
        total_original_mae / num_batches
    )


def count_parameters(model: nn.Module) -> int:
    """ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°"""
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


def train_model(
    data_path: str,
    output_dir: str = "models",
    epochs: int = 100,
    batch_size: int = 64,
    learning_rate: float = 0.001,
    patience: int = 15,
    token_dim: int = 128,
    num_heads: int = 4
):
    """ëª¨ë¸ í•™ìŠµ ë©”ì¸ í•¨ìˆ˜ (V6 - Multi-Token Attention)"""
    logger.info("=" * 60)
    logger.info("ğŸš€ V6 ëª¨ë¸ í•™ìŠµ ì‹œì‘ (Multi-Token Attention)")
    logger.info("=" * 60)
    logger.info(f"  - í•µì‹¬ ê°œì„ : 3ê°œ í† í° ê°„ Cross-Attention")
    logger.info(f"  - Token dimension: {token_dim}")
    logger.info(f"  - Attention heads: {num_heads}")
    logger.info(f"  - ë¼ë²¨ ì •ê·œí™”: {LABEL_MIN}~{LABEL_MAX} â†’ 0~1")

    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {device}")

    # ë°ì´í„° ë¡œë“œ
    data = load_training_data(data_path)

    # ë°ì´í„°ë¡œë” ìƒì„±
    train_loader, val_loader, test_loader = create_dataloaders_no_leakage(
        data,
        batch_size=batch_size
    )

    # V6 ëª¨ë¸ ìƒì„±
    model = RecommendationModelV6(
        face_feat_dim=6,
        skin_feat_dim=2,
        style_embed_dim=384,
        token_dim=token_dim,
        num_heads=num_heads,
        dropout_rate=0.3
    ).to(device)

    num_params = count_parameters(model)

    logger.info(f"\nğŸ—ï¸  ëª¨ë¸ êµ¬ì¡° (V6 - Multi-Token Attention):")
    logger.info(f"  - Face features: 6 â†’ 64")
    logger.info(f"  - Skin features: 2 â†’ 32")
    logger.info(f"  - Style embedding: 384")
    logger.info(f"  - Token dimension: {token_dim}")
    logger.info(f"  - Attention: 3-token cross-attention ({num_heads} heads)")
    logger.info(f"  - Attention output: {token_dim * 3}")
    logger.info(f"  - ì¶œë ¥ì¸µ: Sigmoid (0~1)")
    logger.info(f"  - ì´ íŒŒë¼ë¯¸í„°: {num_params:,}")

    # í•™ìŠµ ì„¤ì •
    criterion = nn.MSELoss()
    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer,
        mode='min',
        factor=0.5,
        patience=5
    )

    history = {
        'train_loss': [],
        'val_loss': [],
        'val_mae_normalized': [],
        'val_mae_original': [],
        'lr': []
    }

    best_val_loss = float('inf')
    patience_counter = 0

    logger.info(f"\nğŸ‹ï¸  í•™ìŠµ ì‹œì‘:")
    logger.info(f"  - Epochs: {epochs}")
    logger.info(f"  - Batch size: {batch_size}")
    logger.info(f"  - Learning rate: {learning_rate}")
    logger.info(f"  - Early stopping patience: {patience}")

    for epoch in range(epochs):
        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)
        val_loss, val_mae_norm, val_mae_orig = validate(model, val_loader, criterion, device)

        current_lr = optimizer.param_groups[0]['lr']

        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['val_mae_normalized'].append(val_mae_norm)
        history['val_mae_original'].append(val_mae_orig)
        history['lr'].append(current_lr)

        if (epoch + 1) % 5 == 0 or epoch == 0:
            logger.info(
                f"Epoch [{epoch+1:3d}/{epochs}] "
                f"Train Loss: {train_loss:.4f} | "
                f"Val Loss: {val_loss:.4f} | "
                f"MAE(orig): {val_mae_orig:.2f} | "
                f"LR: {current_lr:.6f}"
            )

        scheduler.step(val_loss)

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0

            model_path = output_dir / "hairstyle_recommender_v6_multitoken.pt"
            torch.save({
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_val_loss': best_val_loss,
                'history': history,
                'config': {
                    'version': 'v6',
                    'face_feat_dim': 6,
                    'skin_feat_dim': 2,
                    'style_embed_dim': 384,
                    'token_dim': token_dim,
                    'num_heads': num_heads,
                    'normalized': True,
                    'label_min': LABEL_MIN,
                    'label_max': LABEL_MAX,
                    'label_range': LABEL_RANGE,
                    'attention_type': 'multi_token'
                }
            }, model_path)

            logger.info(f"  âœ… Best ëª¨ë¸ ì €ì¥: {model_path}")

        else:
            patience_counter += 1

        if patience_counter >= patience:
            logger.info(f"\nâ¸ï¸  Early stopping at epoch {epoch + 1}")
            break

    # ìµœì¢… í…ŒìŠ¤íŠ¸
    logger.info(f"\nğŸ§ª ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê°€:")
    test_loss, test_mae_norm, test_mae_orig = validate(model, test_loader, criterion, device)
    logger.info(f"  - Test Loss: {test_loss:.4f}")
    logger.info(f"  - Test MAE (ì •ê·œí™”): {test_mae_norm:.4f}")
    logger.info(f"  - Test MAE (ì›ë³¸ ìŠ¤ì¼€ì¼): {test_mae_orig:.2f}ì ")

    # í•™ìŠµ ê¸°ë¡ ì €ì¥
    history_path = output_dir / "training_history_v6_multitoken.json"
    with open(history_path, 'w', encoding='utf-8') as f:
        json.dump(history, f, indent=2)

    logger.info(f"\nğŸ“Š í•™ìŠµ ê¸°ë¡ ì €ì¥: {history_path}")

    # ëª¨ë¸ ì¶œë ¥ ë²”ìœ„ ê²€ì¦
    logger.info(f"\nğŸ” ëª¨ë¸ ì¶œë ¥ ë²”ìœ„ ê²€ì¦:")
    model.eval()
    with torch.no_grad():
        all_preds = []
        all_labels = []
        for face_feat, skin_feat, style_emb, scores in test_loader:
            face_feat = face_feat.to(device)
            skin_feat = skin_feat.to(device)
            style_emb = style_emb.to(device)

            pred = model(face_feat, skin_feat, style_emb)
            all_preds.append(pred.cpu().numpy())
            all_labels.append(scores.cpu().numpy())

        all_preds = np.concatenate(all_preds)
        all_labels = np.concatenate(all_labels).flatten()

        logger.info(f"  - ì •ê·œí™”ëœ ì¶œë ¥ ë²”ìœ„: {all_preds.min():.4f} ~ {all_preds.max():.4f}")
        logger.info(f"  - ì •ê·œí™”ëœ ë¼ë²¨ ë²”ìœ„: {all_labels.min():.4f} ~ {all_labels.max():.4f}")

        preds_orig = all_preds * LABEL_RANGE + LABEL_MIN
        labels_orig = all_labels * LABEL_RANGE + LABEL_MIN

        logger.info(f"  - ì›ë³¸ ìŠ¤ì¼€ì¼ ì¶œë ¥ ë²”ìœ„: {preds_orig.min():.1f} ~ {preds_orig.max():.1f}")
        logger.info(f"  - ì›ë³¸ ìŠ¤ì¼€ì¼ ë¼ë²¨ ë²”ìœ„: {labels_orig.min():.1f} ~ {labels_orig.max():.1f}")

        # ë¶„ë¥˜ ì •í™•ë„
        high_threshold = normalize_score(np.array([75.0]))[0]
        low_threshold = normalize_score(np.array([40.0]))[0]

        high_labels = all_labels >= high_threshold
        low_labels = all_labels <= low_threshold

        if high_labels.sum() > 0:
            high_correct = (all_preds[high_labels] >= high_threshold).sum()
            logger.info(f"\nğŸ“Š ë¶„ë¥˜ ì •í™•ë„:")
            logger.info(f"  - ê³ ì ìˆ˜(â‰¥75ì ) ì˜ˆì¸¡ ì •í™•ë„: {high_correct}/{high_labels.sum()} ({high_correct/high_labels.sum()*100:.1f}%)")

        if low_labels.sum() > 0:
            low_correct = (all_preds[low_labels] <= low_threshold).sum()
            logger.info(f"  - ì €ì ìˆ˜(â‰¤40ì ) ì˜ˆì¸¡ ì •í™•ë„: {low_correct}/{low_labels.sum()} ({low_correct/low_labels.sum()*100:.1f}%)")

    logger.info("\n" + "=" * 60)
    logger.info("âœ… V6 í•™ìŠµ ì™„ë£Œ!")
    logger.info("=" * 60)
    logger.info(f"  - Best Val Loss: {best_val_loss:.4f}")
    logger.info(f"  - Test MAE: {test_mae_orig:.2f}ì  (ì›ë³¸ ìŠ¤ì¼€ì¼)")
    logger.info(f"  - ëª¨ë¸ ê²½ë¡œ: {output_dir / 'hairstyle_recommender_v6_multitoken.pt'}")


def main():
    parser = argparse.ArgumentParser(description="V6 ëª¨ë¸ í•™ìŠµ (Multi-Token Attention)")
    parser.add_argument(
        "--data",
        type=str,
        default="data_source/ai_face_1000.npz",
        help="í•™ìŠµ ë°ì´í„° NPZ ê²½ë¡œ"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="models",
        help="ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬"
    )
    parser.add_argument(
        "--epochs",
        type=int,
        default=100,
        help="í•™ìŠµ ì—í­ ìˆ˜"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=64,
        help="ë°°ì¹˜ í¬ê¸°"
    )
    parser.add_argument(
        "--lr",
        type=float,
        default=0.001,
        help="í•™ìŠµë¥ "
    )
    parser.add_argument(
        "--patience",
        type=int,
        default=15,
        help="Early stopping patience"
    )
    parser.add_argument(
        "--token-dim",
        type=int,
        default=128,
        help="Attention í† í° ì°¨ì›"
    )
    parser.add_argument(
        "--num-heads",
        type=int,
        default=4,
        help="Attention heads ìˆ˜"
    )

    args = parser.parse_args()

    train_model(
        data_path=args.data,
        output_dir=args.output_dir,
        epochs=args.epochs,
        batch_size=args.batch_size,
        learning_rate=args.lr,
        patience=args.patience,
        token_dim=args.token_dim,
        num_heads=args.num_heads
    )


if __name__ == "__main__":
    main()
