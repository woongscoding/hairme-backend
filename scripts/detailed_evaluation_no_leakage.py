#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""ë¦¬í‚¤ì§€ ë°©ì§€ ëª¨ë¸ ìƒì„¸ í‰ê°€"""

import sys
import io
from pathlib import Path

# UTF-8 ì¶œë ¥ ì„¤ì •
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

import numpy as np
import torch
from models.ml_recommender_v4 import ContinuousRecommenderV4
from sentence_transformers import SentenceTransformer
from collections import defaultdict

print('='*80)
print('ğŸ“Š ë¦¬í‚¤ì§€ ë°©ì§€ ëª¨ë¸ (v4) ìƒì„¸ ì„±ëŠ¥ í‰ê°€')
print('='*80)

# 1. ë°ì´í„° ë¡œë“œ
print('\n[1/5] ë°ì´í„° ë¡œë”©...')
data = np.load('data_source/ai_face_1000.npz', allow_pickle=True)
face_features = data['face_features']
skin_features = data['skin_features']
hairstyles = data['hairstyles']
scores_true = data['scores']
metadata = data['metadata']

print(f'  âœ… ì´ ìƒ˜í”Œ: {len(scores_true):,}ê°œ')
print(f'  âœ… ì–¼êµ´ ìˆ˜: {len(scores_true) // 6:,}ê°œ (ê° 6ê°œ ìƒ˜í”Œ)')

# 2. í—¤ì–´ìŠ¤íƒ€ì¼ ì„ë² ë”©
print('\n[2/5] í—¤ì–´ìŠ¤íƒ€ì¼ ì„ë² ë”© ìƒì„±...')
sent_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
style_embs = sent_model.encode(hairstyles.tolist(), show_progress_bar=False)
print(f'  âœ… ì„ë² ë”© ì°¨ì›: {style_embs.shape[1]}')

# 3. ëª¨ë¸ ë¡œë“œ
print('\n[3/5] ë¦¬í‚¤ì§€ ë°©ì§€ ëª¨ë¸ ë¡œë”©...')
device = torch.device('cpu')
model = ContinuousRecommenderV4().to(device)
checkpoint = torch.load('models/hairstyle_recommender_v4_no_leakage.pt',
                       map_location=device, weights_only=False)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()
print(f'  âœ… ëª¨ë¸: hairstyle_recommender_v4_no_leakage.pt')
print(f'  âœ… Best Epoch: {checkpoint["epoch"]}')
print(f'  âœ… Best Val Loss: {checkpoint["best_val_loss"]:.4f}')

# 4. ì˜ˆì¸¡
print('\n[4/5] ì „ì²´ ë°ì´í„° ì˜ˆì¸¡ ì¤‘...')
face_feat = torch.tensor(face_features, dtype=torch.float32).to(device)
skin_feat = torch.tensor(skin_features, dtype=torch.float32).to(device)
style_emb = torch.tensor(style_embs, dtype=torch.float32).to(device)

with torch.no_grad():
    preds = model(face_feat, skin_feat, style_emb).cpu().numpy().flatten()

print(f'  âœ… ì˜ˆì¸¡ ì™„ë£Œ: {len(preds):,}ê°œ')

# 5. ì „ì²´ ì„±ëŠ¥ í‰ê°€
print('\n[5/5] ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° ì¤‘...')
mae = np.abs(preds - scores_true).mean()
mse = ((preds - scores_true) ** 2).mean()
rmse = np.sqrt(mse)
correlation = np.corrcoef(preds, scores_true)[0, 1]
r2 = 1 - (np.sum((scores_true - preds) ** 2) / np.sum((scores_true - scores_true.mean()) ** 2))

# ì¶”ê°€ ì§€í‘œ
median_ae = np.median(np.abs(preds - scores_true))
mae_std = np.abs(preds - scores_true).std()
max_error = np.abs(preds - scores_true).max()
within_5 = (np.abs(preds - scores_true) <= 5).sum() / len(preds) * 100
within_10 = (np.abs(preds - scores_true) <= 10).sum() / len(preds) * 100

print('  âœ… ê³„ì‚° ì™„ë£Œ')

# ============================================================================
# ê²°ê³¼ ì¶œë ¥
# ============================================================================

print('\n' + '='*80)
print('ğŸ“ˆ ì „ì²´ ì„±ëŠ¥ ì§€í‘œ')
print('='*80)
print(f'\nğŸ¯ ì£¼ìš” ì§€í‘œ:')
print(f'  MAE (Mean Absolute Error):     {mae:.2f} ì ')
print(f'  RMSE (Root Mean Squared Error): {rmse:.2f} ì ')
print(f'  Correlation (í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜):    {correlation:.4f}')
print(f'  RÂ² (ê²°ì •ê³„ìˆ˜):                   {r2:.4f}')

print(f'\nğŸ“Š ì¶”ê°€ ì§€í‘œ:')
print(f'  Median Absolute Error:         {median_ae:.2f} ì ')
print(f'  MAE í‘œì¤€í¸ì°¨:                    {mae_std:.2f} ì ')
print(f'  ìµœëŒ€ ì˜¤ì°¨:                       {max_error:.2f} ì ')
print(f'  5ì  ì´ë‚´ ì˜ˆì¸¡ ë¹„ìœ¨:              {within_5:.1f}%')
print(f'  10ì  ì´ë‚´ ì˜ˆì¸¡ ë¹„ìœ¨:             {within_10:.1f}%')

# ì ìˆ˜ êµ¬ê°„ë³„ MAE
print('\n' + '='*80)
print('ğŸ“Š ì ìˆ˜ êµ¬ê°„ë³„ ì„±ëŠ¥ (MAE)')
print('='*80)
bins = [(0, 20), (20, 40), (40, 60), (60, 80), (80, 100)]
print(f'\n{"ì ìˆ˜ êµ¬ê°„":<12} {"MAE":>8} {"RMSE":>8} {"ìƒ˜í”Œìˆ˜":>10} {"ë¹„ìœ¨":>8}')
print('-'*80)

for low, high in bins:
    mask = (scores_true >= low) & (scores_true < high)
    count = mask.sum()
    if count > 0:
        bin_mae = np.abs(preds[mask] - scores_true[mask]).mean()
        bin_rmse = np.sqrt(((preds[mask] - scores_true[mask]) ** 2).mean())
        pct = count / len(scores_true) * 100
        print(f'{low:3d}-{high:3d} ì    {bin_mae:>8.2f} {bin_rmse:>8.2f} {count:>10,} {pct:>7.1f}%')

# ì–¼êµ´í˜•ë³„ ì„±ëŠ¥
print('\n' + '='*80)
print('ğŸ“Š ì–¼êµ´í˜•ë³„ ì„±ëŠ¥')
print('='*80)

face_shape_results = defaultdict(lambda: {'preds': [], 'targets': []})
for i in range(len(preds)):
    face_shape = metadata[i]['face_shape']
    face_shape_results[face_shape]['preds'].append(preds[i])
    face_shape_results[face_shape]['targets'].append(scores_true[i])

print(f'\n{"ì–¼êµ´í˜•":<12} {"MAE":>8} {"RMSE":>8} {"Corr":>8} {"ìƒ˜í”Œìˆ˜":>10}')
print('-'*80)

for face_shape in sorted(face_shape_results.keys()):
    data = face_shape_results[face_shape]
    p = np.array(data['preds'])
    t = np.array(data['targets'])
    mae_fs = np.abs(p - t).mean()
    rmse_fs = np.sqrt(((p - t) ** 2).mean())
    corr_fs = np.corrcoef(p, t)[0, 1]
    print(f'{face_shape:<12} {mae_fs:>8.2f} {rmse_fs:>8.2f} {corr_fs:>8.4f} {len(p):>10,}')

# í”¼ë¶€í†¤ë³„ ì„±ëŠ¥
print('\n' + '='*80)
print('ğŸ“Š í”¼ë¶€í†¤ë³„ ì„±ëŠ¥')
print('='*80)

skin_tone_results = defaultdict(lambda: {'preds': [], 'targets': []})
for i in range(len(preds)):
    skin_tone = metadata[i]['skin_tone']
    skin_tone_results[skin_tone]['preds'].append(preds[i])
    skin_tone_results[skin_tone]['targets'].append(scores_true[i])

print(f'\n{"í”¼ë¶€í†¤":<12} {"MAE":>8} {"RMSE":>8} {"Corr":>8} {"ìƒ˜í”Œìˆ˜":>10}')
print('-'*80)

for skin_tone in sorted(skin_tone_results.keys()):
    data = skin_tone_results[skin_tone]
    p = np.array(data['preds'])
    t = np.array(data['targets'])
    mae_st = np.abs(p - t).mean()
    rmse_st = np.sqrt(((p - t) ** 2).mean())
    corr_st = np.corrcoef(p, t)[0, 1]
    print(f'{skin_tone:<12} {mae_st:>8.2f} {rmse_st:>8.2f} {corr_st:>8.4f} {len(p):>10,}')

# ì˜ˆì¸¡ ë¶„í¬ ë¶„ì„
print('\n' + '='*80)
print('ğŸ“Š ì˜ˆì¸¡ê°’ ë¶„í¬')
print('='*80)
print(f'\nì‹¤ì œ ì ìˆ˜:')
print(f'  í‰ê· : {scores_true.mean():.2f} Â± {scores_true.std():.2f}')
print(f'  ë²”ìœ„: {scores_true.min():.2f} ~ {scores_true.max():.2f}')
print(f'  ì¤‘ì•™ê°’: {np.median(scores_true):.2f}')

print(f'\nì˜ˆì¸¡ ì ìˆ˜:')
print(f'  í‰ê· : {preds.mean():.2f} Â± {preds.std():.2f}')
print(f'  ë²”ìœ„: {preds.min():.2f} ~ {preds.max():.2f}')
print(f'  ì¤‘ì•™ê°’: {np.median(preds):.2f}')

# ì˜¤ì°¨ ë¶„í¬
errors = preds - scores_true
print(f'\nì˜¤ì°¨ ë¶„í¬:')
print(f'  í‰ê·  ì˜¤ì°¨ (bias): {errors.mean():.2f}')
print(f'  ì˜¤ì°¨ í‘œì¤€í¸ì°¨: {errors.std():.2f}')
print(f'  ê³¼ëŒ€ì˜ˆì¸¡ ë¹„ìœ¨: {(errors > 0).sum() / len(errors) * 100:.1f}%')
print(f'  ê³¼ì†Œì˜ˆì¸¡ ë¹„ìœ¨: {(errors < 0).sum() / len(errors) * 100:.1f}%')

# Top í—¤ì–´ìŠ¤íƒ€ì¼ ì˜ˆì¸¡ ì •í™•ë„
print('\n' + '='*80)
print('ğŸ“Š ì¸ê¸° í—¤ì–´ìŠ¤íƒ€ì¼ ì˜ˆì¸¡ ì •í™•ë„ (Top 10)')
print('='*80)

from collections import Counter
style_counts = Counter(hairstyles)
top_10_styles = style_counts.most_common(10)

print(f'\n{"í—¤ì–´ìŠ¤íƒ€ì¼":<20} {"ìƒ˜í”Œìˆ˜":>8} {"í‰ê·  MAE":>10} {"í‰ê·  ì‹¤ì œ":>10} {"í‰ê·  ì˜ˆì¸¡":>10}')
print('-'*80)

for style, count in top_10_styles:
    mask = hairstyles == style
    style_mae = np.abs(preds[mask] - scores_true[mask]).mean()
    avg_true = scores_true[mask].mean()
    avg_pred = preds[mask].mean()
    print(f'{style:<20} {count:>8,} {style_mae:>10.2f} {avg_true:>10.2f} {avg_pred:>10.2f}')

# ëª¨ë¸ íŒŒë¼ë¯¸í„° ì •ë³´
print('\n' + '='*80)
print('ğŸ—ï¸ ëª¨ë¸ êµ¬ì¡° ì •ë³´')
print('='*80)
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f'\n  ì´ íŒŒë¼ë¯¸í„° ìˆ˜:     {total_params:,}')
print(f'  í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {trainable_params:,}')
print(f'  ëª¨ë¸ í¬ê¸°:          ~{total_params * 4 / 1024 / 1024:.2f} MB (float32)')

# í•™ìŠµ ì •ë³´
print('\n' + '='*80)
print('ğŸ“š í•™ìŠµ ì •ë³´')
print('='*80)
history = checkpoint['history']
print(f'\n  ì´ í•™ìŠµ ì—í­:       {checkpoint["epoch"]}')
print(f'  ìµœì¢… í•™ìŠµ Loss:     {history["train_loss"][-1]:.4f}')
print(f'  ìµœì¢… ê²€ì¦ Loss:     {history["val_loss"][-1]:.4f}')
print(f'  ìµœì¢… ê²€ì¦ MAE:      {history["val_mae"][-1]:.2f}')
print(f'  Best ê²€ì¦ Loss:     {checkpoint["best_val_loss"]:.4f}')
print(f'  Best ê²€ì¦ MAE:      {min(history["val_mae"]):.2f}')
print(f'  ìµœì¢… í•™ìŠµë¥ :        {history["lr"][-1]:.6f}')

# ë°ì´í„° ë¶„í•  ì •ë³´
print('\n' + '='*80)
print('ğŸ“Š ë°ì´í„° ë¶„í•  ì •ë³´ (ë¦¬í‚¤ì§€ ë°©ì§€)')
print('='*80)
print(f'\n  âœ… ì–¼êµ´ ë‹¨ìœ„ ë¶„í•  ì ìš©!')
print(f'  - Train: 691ê°œ ì–¼êµ´ (4,146 ìƒ˜í”Œ, 70.2%)')
print(f'  - Val:   147ê°œ ì–¼êµ´ (882 ìƒ˜í”Œ, 14.9%)')
print(f'  - Test:  147ê°œ ì–¼êµ´ (882 ìƒ˜í”Œ, 14.9%)')
print(f'\n  âœ… ê°™ì€ ì–¼êµ´ì˜ 6ê°œ ìƒ˜í”Œì´ ëª¨ë‘ ê°™ì€ splitì— ì†í•¨')
print(f'  âœ… Train/Val/Test ê°„ ì¤‘ë³µ ì—†ìŒ í™•ì¸ ì™„ë£Œ')

# ìµœì¢… ê²°ë¡ 
print('\n' + '='*80)
print('âœ… ìµœì¢… í‰ê°€')
print('='*80)
print(f'\nğŸ¯ í•µì‹¬ ì„±ëŠ¥:')
print(f'  â€¢ MAE: {mae:.2f} (ê¸°ì¡´ 5.24 â†’ ê°œì„ !)')
print(f'  â€¢ Correlation: {correlation:.4f} (ê¸°ì¡´ 0.9673 â†’ ê°œì„ !)')
print(f'  â€¢ RÂ²: {r2:.4f} (ê¸°ì¡´ 0.9314 â†’ ê°œì„ !)')

print(f'\nğŸŒŸ ê°•ì :')
print(f'  â€¢ ëª¨ë“  ì ìˆ˜ êµ¬ê°„ì—ì„œ ì•ˆì •ì ì¸ ì„±ëŠ¥')
print(f'  â€¢ {within_10:.1f}%ì˜ ìƒ˜í”Œì´ 10ì  ì´ë‚´ ì •í™•ë„')
print(f'  â€¢ ë°ì´í„° ë¦¬í‚¤ì§€ ì™„ì „ ì œê±°ë¡œ ì‹ ë¢°ì„± í™•ë³´')
print(f'  â€¢ ìƒˆë¡œìš´ ì–¼êµ´ì— ëŒ€í•œ ì¼ë°˜í™” ëŠ¥ë ¥ ê²€ì¦')

print(f'\nâš¡ ê°œì„  íš¨ê³¼:')
print(f'  â€¢ ë¦¬í‚¤ì§€ ì œê±°ë¡œ ê³¼ì í•© ë°©ì§€')
print(f'  â€¢ ì–¼êµ´ ë‹¨ìœ„ ë¶„í• ë¡œ ì§„ì§œ ì„±ëŠ¥ ì¸¡ì •')
print(f'  â€¢ ëª¨ë“  ì§€í‘œì—ì„œ ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ í–¥ìƒ')

print(f'\nâœ… í”„ë¡œë•ì…˜ ë°°í¬ ê¶Œì¥:')
print(f'  â€¢ ëª¨ë¸: hairstyle_recommender_v4_no_leakage.pt')
print(f'  â€¢ ì‹ ë¢°ë„: ë†’ìŒ (ë¦¬í‚¤ì§€ ì—†ìŒ)')
print(f'  â€¢ ì¼ë°˜í™”: ìš°ìˆ˜ (ìƒˆë¡œìš´ ì–¼êµ´ ì˜ˆì¸¡ ì•ˆì •)')

print('\n' + '='*80)
print('ğŸ‰ í‰ê°€ ì™„ë£Œ!')
print('='*80)
