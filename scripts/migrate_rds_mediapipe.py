#!/usr/bin/env python3
"""
RDS MediaPipe ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

db_schema_mediapipe_continuous.sqlì„ RDSì— ì•ˆì „í•˜ê²Œ ì ìš©í•©ë‹ˆë‹¤.

âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸:
1. RDS ë°±ì—… í™•ì¸
2. DATABASE_URL / DB_PASSWORD í™•ì¸
3. SQL ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
4. ì»¬ëŸ¼ ì¶”ê°€ í™•ì¸
5. ì¸ë±ìŠ¤ í™•ì¸
6. í†µê³„ í™•ì¸

Author: HairMe ML Team
Date: 2025-11-15
"""

import os
import sys
import subprocess
import pymysql
import logging
from pathlib import Path
from typing import Dict, Optional
import urllib.parse

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)
logger = logging.getLogger(__name__)

PROJECT_ROOT = Path(__file__).parent.parent


class RDSMigrator:
    """RDS ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ê¸°"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.connection = None
        self.db_config = {}

    def load_credentials(self) -> Dict:
        """AWS Secrets Managerì—ì„œ DB ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        logger.info("ğŸ“‚ AWS Secrets Managerì—ì„œ DB ì •ë³´ ê°€ì ¸ì˜¤ê¸°...")

        try:
            # DATABASE_URL ê°€ì ¸ì˜¤ê¸°
            result = subprocess.run(
                [
                    "aws", "secretsmanager", "get-secret-value",
                    "--secret-id", "hairme-database-url",
                    "--query", "SecretString",
                    "--output", "text"
                ],
                capture_output=True,
                text=True,
                env={"MSYS_NO_PATHCONV": "1", **os.environ}
            )

            database_url = result.stdout.strip()

            # DB_PASSWORD ê°€ì ¸ì˜¤ê¸°
            result = subprocess.run(
                [
                    "aws", "secretsmanager", "get-secret-value",
                    "--secret-id", "hairme-db-password",
                    "--query", "SecretString",
                    "--output", "text"
                ],
                capture_output=True,
                text=True,
                env={"MSYS_NO_PATHCONV": "1", **os.environ}
            )

            db_password = result.stdout.strip()

            # URL íŒŒì‹±
            # mysql+asyncmy://admin@hairme-data-v2.cr28a6uqo2k8.ap-northeast-2.rds.amazonaws.com:3306/hairme
            parts = database_url.split('@')[1].split('/')
            host_port = parts[0]
            database = parts[1] if len(parts) > 1 else 'hairme'

            host = host_port.split(':')[0]
            port = int(host_port.split(':')[1]) if ':' in host_port else 3306

            self.db_config = {
                'host': host,
                'port': port,
                'user': 'admin',
                'password': db_password,
                'database': database
            }

            logger.info(f"âœ… DB ì •ë³´ ë¡œë“œ ì™„ë£Œ:")
            logger.info(f"   Host: {host}")
            logger.info(f"   Port: {port}")
            logger.info(f"   Database: {database}")

            return self.db_config

        except Exception as e:
            logger.error(f"âŒ DB ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise

    def connect(self) -> pymysql.Connection:
        """RDS ì ‘ì†"""
        logger.info("\nğŸ”Œ RDS ì ‘ì† ì¤‘...")

        try:
            self.connection = pymysql.connect(
                host=self.db_config['host'],
                port=self.db_config['port'],
                user=self.db_config['user'],
                password=self.db_config['password'],
                database=self.db_config['database'],
                charset='utf8mb4',
                cursorclass=pymysql.cursors.DictCursor
            )

            logger.info("âœ… RDS ì ‘ì† ì„±ê³µ")
            return self.connection

        except Exception as e:
            logger.error(f"âŒ RDS ì ‘ì† ì‹¤íŒ¨: {str(e)}")
            raise

    def check_backup(self) -> bool:
        """ë°±ì—… í…Œì´ë¸” ì¡´ì¬ í™•ì¸"""
        logger.info("\nğŸ“¦ ë°±ì—… í…Œì´ë¸” í™•ì¸ ì¤‘...")

        with self.connection.cursor() as cursor:
            cursor.execute("SHOW TABLES LIKE 'analysis_history_backup_mediapipe'")
            result = cursor.fetchone()

            if result:
                cursor.execute("SELECT COUNT(*) as count FROM analysis_history_backup_mediapipe")
                count = cursor.fetchone()['count']
                logger.info(f"âœ… ë°±ì—… í…Œì´ë¸” ì¡´ì¬: {count:,}ê°œ ë ˆì½”ë“œ")
                return True
            else:
                logger.warning("âš ï¸ ë°±ì—… í…Œì´ë¸” ì—†ìŒ")
                return False

    def execute_sql_file(self, sql_file_path: Path):
        """SQL íŒŒì¼ ì‹¤í–‰"""
        logger.info(f"\nğŸ”„ SQL ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰: {sql_file_path}")

        with open(sql_file_path, 'r', encoding='utf-8') as f:
            sql_script = f.read()

        # SQL ë¬¸ì¥ ë¶„ë¦¬ (ì„¸ë¯¸ì½œë¡  ê¸°ì¤€)
        statements = sql_script.split(';')

        with self.connection.cursor() as cursor:
            for i, statement in enumerate(statements):
                statement = statement.strip()

                if not statement or statement.startswith('--') or statement.startswith('/*'):
                    continue

                try:
                    cursor.execute(statement)
                    self.connection.commit()

                    # ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° ì¶œë ¥ (SELECT ë¬¸)
                    if statement.strip().upper().startswith('SELECT'):
                        results = cursor.fetchall()
                        if results:
                            logger.info(f"  Query {i+1}: {results[0]}")

                except Exception as e:
                    # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ì¶”ê°€ ì‹œë„ ë“±ì€ ë¬´ì‹œ
                    if "Duplicate column name" in str(e):
                        logger.info(f"  âš ï¸ ì»¬ëŸ¼ì´ ì´ë¯¸ ì¡´ì¬í•¨ (ìŠ¤í‚µ)")
                    else:
                        logger.error(f"  âŒ ì‹¤í–‰ ì‹¤íŒ¨: {statement[:100]}...")
                        logger.error(f"     ì˜¤ë¥˜: {str(e)}")

        logger.info("âœ… SQL ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì™„ë£Œ")

    def verify_columns(self) -> bool:
        """MediaPipe ì»¬ëŸ¼ ì¶”ê°€ í™•ì¸"""
        logger.info("\nğŸ” MediaPipe ì»¬ëŸ¼ í™•ì¸ ì¤‘...")

        with self.connection.cursor() as cursor:
            cursor.execute("""
                SELECT
                    COLUMN_NAME,
                    COLUMN_TYPE,
                    COLUMN_COMMENT
                FROM INFORMATION_SCHEMA.COLUMNS
                WHERE TABLE_SCHEMA = %s
                  AND TABLE_NAME = 'analysis_history'
                  AND COLUMN_NAME LIKE 'mediapipe%%'
                ORDER BY ORDINAL_POSITION
            """, (self.db_config['database'],))

            columns = cursor.fetchall()

            if columns:
                logger.info(f"âœ… MediaPipe ì»¬ëŸ¼ í™•ì¸ë¨ ({len(columns)}ê°œ):")
                for col in columns:
                    logger.info(f"   - {col['COLUMN_NAME']:30s} {col['COLUMN_TYPE']:15s} {col['COLUMN_COMMENT']}")
                return True
            else:
                logger.error("âŒ MediaPipe ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
                return False

    def verify_indexes(self) -> bool:
        """ì¸ë±ìŠ¤ í™•ì¸"""
        logger.info("\nğŸ” ì¸ë±ìŠ¤ í™•ì¸ ì¤‘...")

        with self.connection.cursor() as cursor:
            cursor.execute("""
                SHOW INDEXES FROM analysis_history
                WHERE Key_name IN ('idx_mediapipe_complete', 'idx_training_data')
            """)

            indexes = cursor.fetchall()

            if indexes:
                logger.info(f"âœ… ì¸ë±ìŠ¤ í™•ì¸ë¨ ({len(indexes)}ê°œ):")
                for idx in indexes:
                    logger.info(f"   - {idx['Key_name']}")
                return True
            else:
                logger.warning("âš ï¸ ì¸ë±ìŠ¤ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return False

    def show_statistics(self):
        """ë°ì´í„° í†µê³„ í™•ì¸"""
        logger.info("\nğŸ“Š ë°ì´í„° í†µê³„:")

        with self.connection.cursor() as cursor:
            # ì „ì²´ ë ˆì½”ë“œ ìˆ˜
            cursor.execute("SELECT COUNT(*) as total FROM analysis_history")
            total = cursor.fetchone()['total']

            # MediaPipe ë°ì´í„° ìˆ˜ì§‘ë¥ 
            cursor.execute("""
                SELECT
                    COUNT(*) as total_records,
                    SUM(CASE WHEN mediapipe_features_complete = TRUE THEN 1 ELSE 0 END) as mediapipe_complete,
                    ROUND(
                        SUM(CASE WHEN mediapipe_features_complete = TRUE THEN 1 ELSE 0 END) * 100.0 / COUNT(*),
                        2
                    ) as mediapipe_coverage_percent
                FROM analysis_history
            """)

            stats = cursor.fetchone()

            logger.info(f"   - ì „ì²´ ë ˆì½”ë“œ: {total:,}ê°œ")
            logger.info(f"   - MediaPipe ì™„ë£Œ: {stats['mediapipe_complete']:,}ê°œ ({stats['mediapipe_coverage_percent']}%)")

            # ìµœê·¼ 10ê°œ ë ˆì½”ë“œ
            cursor.execute("""
                SELECT
                    id,
                    face_shape,
                    personal_color,
                    mediapipe_face_ratio,
                    mediapipe_ITA_value,
                    mediapipe_features_complete,
                    created_at
                FROM analysis_history
                ORDER BY id DESC
                LIMIT 5
            """)

            recent = cursor.fetchall()

            logger.info(f"\n   ìµœê·¼ 5ê°œ ë ˆì½”ë“œ:")
            for row in recent:
                mp_status = "âœ“" if row['mediapipe_features_complete'] else "âœ—"
                logger.info(f"      ID {row['id']:5d}: {row['face_shape']:10s} / {row['personal_color']:10s} "
                          f"MediaPipe:{mp_status}")

    def close(self):
        """ì—°ê²° ì¢…ë£Œ"""
        if self.connection:
            self.connection.close()
            logger.info("\nğŸ”Œ RDS ì—°ê²° ì¢…ë£Œ")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("=" * 60)
    logger.info("ğŸš€ RDS MediaPipe ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
    logger.info("=" * 60)

    migrator = RDSMigrator()

    try:
        # 1. DB ì •ë³´ ë¡œë“œ
        migrator.load_credentials()

        # 2. RDS ì ‘ì†
        migrator.connect()

        # 3. ë°±ì—… í™•ì¸
        backup_exists = migrator.check_backup()
        if not backup_exists:
            logger.warning("\nâš ï¸ ë°±ì—… í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
            response = input("ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
            if response.lower() != 'y':
                logger.info("ë§ˆì´ê·¸ë ˆì´ì…˜ ì·¨ì†Œë¨")
                return

        # 4. SQL ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        sql_file = PROJECT_ROOT / "db_schema_mediapipe_continuous.sql"
        if not sql_file.exists():
            logger.error(f"âŒ SQL íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {sql_file}")
            return

        migrator.execute_sql_file(sql_file)

        # 5. ê²€ì¦
        columns_ok = migrator.verify_columns()
        indexes_ok = migrator.verify_indexes()

        # 6. í†µê³„
        migrator.show_statistics()

        # ê²°ê³¼
        logger.info("\n" + "=" * 60)
        if columns_ok:
            logger.info("âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì„±ê³µ!")
        else:
            logger.error("âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨!")

        logger.info("=" * 60)

        logger.info("\në‹¤ìŒ ë‹¨ê³„:")
        logger.info("  1. ì„œë²„ ì½”ë“œ ì—…ë°ì´íŠ¸ (MediaPipe ì—°ì†í˜• ë³€ìˆ˜ ì €ì¥)")
        logger.info("  2. ìƒˆ ë°ì´í„° ìˆ˜ì§‘ (mediapipe_features_complete = TRUE)")
        logger.info("  3. v4 ëª¨ë¸ í•™ìŠµ")
        logger.info("  4. ë°°í¬")

    except Exception as e:
        logger.error(f"\nâŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {str(e)}")
        import traceback
        traceback.print_exc()

    finally:
        migrator.close()


if __name__ == "__main__":
    main()
