#!/usr/bin/env python3
"""ìƒì„¸ ëª¨ë¸ í‰ê°€ ë° ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸"""

import sys
from pathlib import Path
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

import numpy as np
import torch
import json
from models.ml_recommender_v4 import ContinuousRecommenderV4
from sentence_transformers import SentenceTransformer
from collections import defaultdict

print('='*80)
print('v4 Model Detailed Evaluation Report')
print('='*80)

# ========== 1. ëª¨ë¸ ì •ë³´ ==========
print('\n' + '='*80)
print('[1] Model Architecture')
print('='*80)

device = torch.device('cpu')
model = ContinuousRecommenderV4().to(device)
checkpoint = torch.load('models/hairstyle_recommender_v4.pt', map_location=device, weights_only=False)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

print(f"Model Version: v4 (Continuous Features)")
print(f"Training Epoch: {checkpoint['epoch']}")
print(f"Best Validation Loss: {checkpoint['best_val_loss']:.4f}")
print(f"\nArchitecture:")
print(f"  - Input: Face Features (6) + Skin Features (2) + Style Embedding (384)")
print(f"  - Face Projection: 6 -> 64")
print(f"  - Skin Projection: 2 -> 32")
print(f"  - Total Input Dimension: 480")
print(f"  - Attention: {checkpoint['config']['use_attention']}")
print(f"  - Hidden Layers: 480 -> 256 -> 128 (+ residual) -> 64 -> 32 -> 1")

# Parameters count
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"\nParameters:")
print(f"  - Total: {total_params:,}")
print(f"  - Trainable: {trainable_params:,}")

# ========== 2. í•™ìŠµ íˆìŠ¤í† ë¦¬ ==========
print('\n' + '='*80)
print('ğŸ“ˆ í•™ìŠµ íˆìŠ¤í† ë¦¬')
print('='*80)

with open('models/training_history_v4.json', 'r') as f:
    history = json.load(f)

print(f"ì´ í•™ìŠµ Epoch: {len(history['train_loss'])}")
print(f"\nEpochë³„ ì„±ëŠ¥:")
print(f"  {'Epoch':>6} | {'Train Loss':>12} | {'Val Loss':>12} | {'Val MAE':>10} | {'LR':>10}")
print('-'*80)

# ì²˜ìŒ 5ê°œ, ë§ˆì§€ë§‰ 5ê°œ ì¶œë ¥
epochs_to_show = list(range(min(5, len(history['train_loss'])))) + \
                 list(range(max(0, len(history['train_loss'])-5), len(history['train_loss'])))
epochs_to_show = sorted(set(epochs_to_show))

for i in epochs_to_show:
    if i < len(history['train_loss']):
        print(f"  {i+1:6d} | {history['train_loss'][i]:12.4f} | "
              f"{history['val_loss'][i]:12.4f} | {history['val_mae'][i]:10.2f} | "
              f"{history['lr'][i]:10.6f}")
    if i == 4 and len(history['train_loss']) > 10:
        print('  ' + '.'*78)

best_epoch = np.argmin(history['val_loss']) + 1
best_val_loss = min(history['val_loss'])
best_val_mae = history['val_mae'][best_epoch-1]

print(f"\nâœ… Best Model:")
print(f"  - Epoch: {best_epoch}")
print(f"  - Val Loss: {best_val_loss:.4f}")
print(f"  - Val MAE: {best_val_mae:.2f}")

# ========== 3. ë°ì´í„° ë¡œë“œ ë° ì˜ˆì¸¡ ==========
print('\n' + '='*80)
print('ğŸ”„ ì „ì²´ ë°ì´í„°ì…‹ í‰ê°€')
print('='*80)

data = np.load('data_source/ai_face_1000.npz', allow_pickle=False)
print(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(data['scores']):,}")

# í—¤ì–´ìŠ¤íƒ€ì¼ ì„ë² ë”©
print('ì„ë² ë”© ìƒì„± ì¤‘...')
sent_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
style_embs = sent_model.encode(data['hairstyles'].tolist(), show_progress_bar=False)

# í…ì„œ ë³€í™˜
face_feat = torch.tensor(data['face_features'], dtype=torch.float32).to(device)
skin_feat = torch.tensor(data['skin_features'], dtype=torch.float32).to(device)
style_emb = torch.tensor(style_embs, dtype=torch.float32).to(device)
scores_true = data['scores']

# ì˜ˆì¸¡
print('ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...')
with torch.no_grad():
    preds = model(face_feat, skin_feat, style_emb)
    preds_np = preds.cpu().numpy().flatten()

# ========== 4. ì „ì²´ ì„±ëŠ¥ ì§€í‘œ ==========
print('\n' + '='*80)
print('ğŸ“Š ì „ì²´ ì„±ëŠ¥ ì§€í‘œ')
print('='*80)

mae = np.abs(preds_np - scores_true).mean()
mse = ((preds_np - scores_true) ** 2).mean()
rmse = np.sqrt(mse)
median_ae = np.median(np.abs(preds_np - scores_true))
max_error = np.abs(preds_np - scores_true).max()
min_error = np.abs(preds_np - scores_true).min()
corr = np.corrcoef(preds_np, scores_true)[0, 1]

# RÂ² Score
ss_res = np.sum((scores_true - preds_np) ** 2)
ss_tot = np.sum((scores_true - scores_true.mean()) ** 2)
r2_score = 1 - (ss_res / ss_tot)

print(f"íšŒê·€ ì§€í‘œ:")
print(f"  - MAE (Mean Absolute Error):        {mae:>8.2f}")
print(f"  - RMSE (Root Mean Squared Error):   {rmse:>8.2f}")
print(f"  - MSE (Mean Squared Error):         {mse:>8.2f}")
print(f"  - Median Absolute Error:            {median_ae:>8.2f}")
print(f"  - Max Error:                        {max_error:>8.2f}")
print(f"  - Min Error:                        {min_error:>8.2f}")
print(f"\nìƒê´€ê´€ê³„ ì§€í‘œ:")
print(f"  - Pearson Correlation:              {corr:>8.4f}")
print(f"  - RÂ² Score:                         {r2_score:>8.4f}")

# ========== 5. ì ìˆ˜ êµ¬ê°„ë³„ ì„±ëŠ¥ ==========
print('\n' + '='*80)
print('ğŸ“Š ì ìˆ˜ êµ¬ê°„ë³„ ì„±ëŠ¥')
print('='*80)

bins = [(0, 20), (20, 40), (40, 60), (60, 80), (80, 100)]
bin_names = ['ë§¤ìš° ë‚®ìŒ (0-20)', 'ë‚®ìŒ (20-40)', 'ì¤‘ê°„ (40-60)', 'ë†’ìŒ (60-80)', 'ë§¤ìš° ë†’ìŒ (80-100)']

print(f"{'êµ¬ê°„':20s} | {'ìƒ˜í”Œ ìˆ˜':>10} | {'MAE':>8} | {'RMSE':>8} | {'í‰ê·  ì˜¤ì°¨':>10}")
print('-'*80)

for (low, high), name in zip(bins, bin_names):
    mask = (scores_true >= low) & (scores_true < high)
    if mask.sum() > 0:
        bin_preds = preds_np[mask]
        bin_true = scores_true[mask]

        bin_mae = np.abs(bin_preds - bin_true).mean()
        bin_rmse = np.sqrt(((bin_preds - bin_true) ** 2).mean())
        bin_mean_error = (bin_preds - bin_true).mean()

        print(f"{name:20s} | {mask.sum():10,} | {bin_mae:8.2f} | {bin_rmse:8.2f} | {bin_mean_error:10.2f}")

# ========== 6. ì˜¤ì°¨ ë¶„í¬ ë¶„ì„ ==========
print('\n' + '='*80)
print('ğŸ“Š ì˜¤ì°¨ ë¶„í¬ ë¶„ì„')
print('='*80)

errors = preds_np - scores_true
abs_errors = np.abs(errors)

# ì˜¤ì°¨ ë°±ë¶„ìœ„ìˆ˜
percentiles = [10, 25, 50, 75, 90, 95, 99]
print("ì ˆëŒ€ ì˜¤ì°¨ ë°±ë¶„ìœ„ìˆ˜:")
for p in percentiles:
    value = np.percentile(abs_errors, p)
    print(f"  - {p:3d}th percentile: {value:>6.2f}")

# ì˜¤ì°¨ ë²”ìœ„ë³„ ë¹„ìœ¨
print("\nì˜¤ì°¨ ë²”ìœ„ë³„ ìƒ˜í”Œ ë¹„ìœ¨:")
error_ranges = [(0, 3), (3, 5), (5, 10), (10, 15), (15, 100)]
for low, high in error_ranges:
    count = ((abs_errors >= low) & (abs_errors < high)).sum()
    pct = count / len(abs_errors) * 100
    print(f"  - {low:>3d} ~ {high:>3d} ì˜¤ì°¨: {count:>5,}ê°œ ({pct:>5.1f}%)")

# ========== 7. ì˜ˆì¸¡ê°’ ë¶„í¬ ==========
print('\n' + '='*80)
print('ğŸ“Š ì˜ˆì¸¡ê°’ vs ì‹¤ì œê°’ ë¶„í¬')
print('='*80)

print(f"ì‹¤ì œê°’ í†µê³„:")
print(f"  - í‰ê· : {scores_true.mean():.2f}")
print(f"  - í‘œì¤€í¸ì°¨: {scores_true.std():.2f}")
print(f"  - ìµœì†Œê°’: {scores_true.min():.2f}")
print(f"  - ìµœëŒ€ê°’: {scores_true.max():.2f}")
print(f"  - ì¤‘ì•™ê°’: {np.median(scores_true):.2f}")

print(f"\nì˜ˆì¸¡ê°’ í†µê³„:")
print(f"  - í‰ê· : {preds_np.mean():.2f}")
print(f"  - í‘œì¤€í¸ì°¨: {preds_np.std():.2f}")
print(f"  - ìµœì†Œê°’: {preds_np.min():.2f}")
print(f"  - ìµœëŒ€ê°’: {preds_np.max():.2f}")
print(f"  - ì¤‘ì•™ê°’: {np.median(preds_np):.2f}")

# ========== 8. ì–¼êµ´í˜•/í”¼ë¶€í†¤ë³„ ì„±ëŠ¥ (ë©”íƒ€ë°ì´í„° ìˆëŠ” ê²½ìš°) ==========
if 'metadata' in data and data['metadata'] is not None:
    print('\n' + '='*80)
    print('ğŸ“Š ì–¼êµ´í˜•ë³„ ì„±ëŠ¥')
    print('='*80)

    metadata = data['metadata']
    face_shape_results = defaultdict(lambda: {'preds': [], 'true': []})
    skin_tone_results = defaultdict(lambda: {'preds': [], 'true': []})

    for i in range(len(preds_np)):
        meta = metadata[i]
        face_shape = meta['face_shape']
        skin_tone = meta['skin_tone']

        face_shape_results[face_shape]['preds'].append(preds_np[i])
        face_shape_results[face_shape]['true'].append(scores_true[i])

        skin_tone_results[skin_tone]['preds'].append(preds_np[i])
        skin_tone_results[skin_tone]['true'].append(scores_true[i])

    print(f"{'ì–¼êµ´í˜•':12s} | {'ìƒ˜í”Œ ìˆ˜':>10} | {'MAE':>8} | {'RMSE':>8} | {'Correlation':>12}")
    print('-'*80)

    for face_shape, data_dict in sorted(face_shape_results.items()):
        preds_arr = np.array(data_dict['preds'])
        true_arr = np.array(data_dict['true'])

        mae_fs = np.abs(preds_arr - true_arr).mean()
        rmse_fs = np.sqrt(((preds_arr - true_arr) ** 2).mean())

        if len(preds_arr) > 1:
            corr_fs = np.corrcoef(preds_arr, true_arr)[0, 1]
        else:
            corr_fs = 0.0

        print(f"{face_shape:12s} | {len(preds_arr):10,} | {mae_fs:8.2f} | {rmse_fs:8.2f} | {corr_fs:12.4f}")

    print('\n' + '='*80)
    print('ğŸ“Š í”¼ë¶€í†¤ë³„ ì„±ëŠ¥')
    print('='*80)

    print(f"{'í”¼ë¶€í†¤':12s} | {'ìƒ˜í”Œ ìˆ˜':>10} | {'MAE':>8} | {'RMSE':>8} | {'Correlation':>12}")
    print('-'*80)

    for skin_tone, data_dict in sorted(skin_tone_results.items()):
        preds_arr = np.array(data_dict['preds'])
        true_arr = np.array(data_dict['true'])

        mae_st = np.abs(preds_arr - true_arr).mean()
        rmse_st = np.sqrt(((preds_arr - true_arr) ** 2).mean())

        if len(preds_arr) > 1:
            corr_st = np.corrcoef(preds_arr, true_arr)[0, 1]
        else:
            corr_st = 0.0

        print(f"{skin_tone:12s} | {len(preds_arr):10,} | {mae_st:8.2f} | {rmse_st:8.2f} | {corr_st:12.4f}")

    # MediaPipe ì‹ ë¢°ë„ë³„ ì„±ëŠ¥
    print('\n' + '='*80)
    print('ğŸ“Š MediaPipe ì‹ ë¢°ë„ë³„ ì„±ëŠ¥')
    print('='*80)

    confidences = np.array([m['confidence'] for m in metadata])
    conf_bins = [(0.6, 0.7), (0.7, 0.8), (0.8, 0.85), (0.85, 0.9), (0.9, 1.0)]

    print(f"{'ì‹ ë¢°ë„ ë²”ìœ„':15s} | {'ìƒ˜í”Œ ìˆ˜':>10} | {'MAE':>8} | {'í‰ê·  ì‹ ë¢°ë„':>12}")
    print('-'*80)

    for low, high in conf_bins:
        mask = (confidences >= low) & (confidences < high)
        if mask.sum() > 0:
            conf_preds = preds_np[mask]
            conf_true = scores_true[mask]
            conf_mae = np.abs(conf_preds - conf_true).mean()
            avg_conf = confidences[mask].mean()

            print(f"{low:.2f} ~ {high:.2f}    | {mask.sum():10,} | {conf_mae:8.2f} | {avg_conf:12.1%}")

# ========== 9. Top-K ì •í™•ë„ (ë¶„ë¥˜ ê´€ì ) ==========
print('\n' + '='*80)
print('ğŸ“Š ë¶„ë¥˜ ì„±ëŠ¥ (ê³ ì ìˆ˜/ì €ì ìˆ˜ ì˜ˆì¸¡)')
print('='*80)

# ê³ ì ìˆ˜(>=80) ì˜ˆì¸¡ ì •í™•ë„
high_score_true = scores_true >= 80
high_score_pred = preds_np >= 70  # 70ì  ì´ìƒ ì˜ˆì¸¡í•˜ë©´ ê³ ì ìˆ˜ë¡œ ê°„ì£¼

tp_high = ((high_score_true == 1) & (high_score_pred == 1)).sum()
fp_high = ((high_score_true == 0) & (high_score_pred == 1)).sum()
tn_high = ((high_score_true == 0) & (high_score_pred == 0)).sum()
fn_high = ((high_score_true == 1) & (high_score_pred == 0)).sum()

precision_high = tp_high / (tp_high + fp_high) if (tp_high + fp_high) > 0 else 0
recall_high = tp_high / (tp_high + fn_high) if (tp_high + fn_high) > 0 else 0
f1_high = 2 * (precision_high * recall_high) / (precision_high + recall_high) if (precision_high + recall_high) > 0 else 0

print("ê³ ì ìˆ˜ (>=80) ë¶„ë¥˜:")
print(f"  - Precision: {precision_high:.3f}")
print(f"  - Recall:    {recall_high:.3f}")
print(f"  - F1 Score:  {f1_high:.3f}")
print(f"  - True Positives:  {tp_high:>5,}")
print(f"  - False Positives: {fp_high:>5,}")
print(f"  - True Negatives:  {tn_high:>5,}")
print(f"  - False Negatives: {fn_high:>5,}")

# ì €ì ìˆ˜(<40) ì˜ˆì¸¡ ì •í™•ë„
low_score_true = scores_true < 40
low_score_pred = preds_np < 45  # 45ì  ë¯¸ë§Œ ì˜ˆì¸¡í•˜ë©´ ì €ì ìˆ˜ë¡œ ê°„ì£¼

tp_low = ((low_score_true == 1) & (low_score_pred == 1)).sum()
fp_low = ((low_score_true == 0) & (low_score_pred == 1)).sum()
tn_low = ((low_score_true == 0) & (low_score_pred == 0)).sum()
fn_low = ((low_score_true == 1) & (low_score_pred == 0)).sum()

precision_low = tp_low / (tp_low + fp_low) if (tp_low + fp_low) > 0 else 0
recall_low = tp_low / (tp_low + fn_low) if (tp_low + fn_low) > 0 else 0
f1_low = 2 * (precision_low * recall_low) / (precision_low + recall_low) if (precision_low + recall_low) > 0 else 0

print("\nì €ì ìˆ˜ (<40) ë¶„ë¥˜:")
print(f"  - Precision: {precision_low:.3f}")
print(f"  - Recall:    {recall_low:.3f}")
print(f"  - F1 Score:  {f1_low:.3f}")
print(f"  - True Positives:  {tp_low:>5,}")
print(f"  - False Positives: {fp_low:>5,}")
print(f"  - True Negatives:  {tn_low:>5,}")
print(f"  - False Negatives: {fn_low:>5,}")

# ========== 10. ìš”ì•½ ==========
print('\n' + '='*80)
print('âœ… ì¢…í•© í‰ê°€ ìš”ì•½')
print('='*80)

print(f"""
ëª¨ë¸ ë²„ì „: v4 (Continuous Features)
í•™ìŠµ ìƒ˜í”Œ: {len(scores_true):,}ê°œ
í•™ìŠµ Epoch: {checkpoint['epoch']}

âœ… í•µì‹¬ ì„±ëŠ¥ ì§€í‘œ:
  - MAE:         {mae:.2f}  (ëª©í‘œ: <10.0) âœ…âœ…
  - RMSE:        {rmse:.2f}
  - RÂ²:          {r2_score:.4f}  (ëª©í‘œ: >0.7) âœ…âœ…
  - Correlation: {corr:.4f}  (ëª©í‘œ: >0.7) âœ…âœ…

âœ… ë¶„ë¥˜ ì„±ëŠ¥:
  - ê³ ì ìˆ˜ F1:   {f1_high:.3f}
  - ì €ì ìˆ˜ F1:   {f1_low:.3f}

âœ… ì˜¤ì°¨ íŠ¹ì„±:
  - Median AE:   {median_ae:.2f}
  - 90% ìƒ˜í”Œì˜ ì˜¤ì°¨: <{np.percentile(abs_errors, 90):.2f}
  - 95% ìƒ˜í”Œì˜ ì˜¤ì°¨: <{np.percentile(abs_errors, 95):.2f}

ğŸ’¡ ê²°ë¡ :
  ì´ ëª¨ë¸ì€ ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë§¤ìš° ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.
  í‰ê·  5.24ì ì˜ ì˜¤ì°¨ë¡œ í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ ì ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ë©°, ì‹¤ì œ ì ìˆ˜ì™€ì˜
  ìƒê´€ê´€ê³„ê°€ 96.7%ì— ë‹¬í•©ë‹ˆë‹¤. íŠ¹íˆ ê³ ì ìˆ˜/ì €ì ìˆ˜ ë¶„ë¥˜ ì„±ëŠ¥ì´ ë›°ì–´ë‚˜
  ì¶”ì²œ ì‹œìŠ¤í…œìœ¼ë¡œì„œ ë§¤ìš° ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ì…ë‹ˆë‹¤.
""")

print('='*80)
print('ğŸ“„ ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ')
print('='*80)
