import os
import time
import json
import logging
from typing import Optional
from datetime import datetime
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from enum import Enum
import google.generativeai as genai
from PIL import Image
import io
import cv2
import numpy as np
import hashlib
import redis
import urllib.parse
import torch
import torch.nn as nn
import pickle

# ========== SQLAlchemy ì¶”ê°€ ==========
from sqlalchemy import Column, Integer, String, Float, DateTime, JSON, Boolean, create_engine, Enum as SQLEnum
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

# ========== ì–¼êµ´ ë¶„ì„ ëª¨ë“ˆ ì„í¬íŠ¸ ==========
# from models.face_analyzer import extract_face_features, create_enhanced_prompt, FaceFeatures  # âŒ ì œê±°ë¨ (Haar Cascade)
from models.mediapipe_analyzer import MediaPipeFaceAnalyzer, MediaPipeFaceFeatures

# ========== ML & í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ ì„í¬íŠ¸ ==========
from services.hybrid_recommender import get_hybrid_service
from models.ml_recommender import get_ml_recommender
from services.feedback_collector import get_feedback_collector
from services.retrain_queue import get_retrain_queue

# ========== ë¼ìš°í„° ì„í¬íŠ¸ ==========
from routers.admin import router as admin_router

Base = declarative_base()

# ========== ë¡œê¹… ì„¤ì • ==========
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ========== ML ëª¨ë¸ ì •ì˜ ==========
class HairstyleRecommender(nn.Module):
    """í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ ML ëª¨ë¸"""

    def __init__(self, n_faces=5, n_skins=3, n_styles=6,
                 emb_dim=16, hidden_dim=64):
        super().__init__()

        self.face_emb = nn.Embedding(n_faces, emb_dim)
        self.skin_emb = nn.Embedding(n_skins, emb_dim)
        self.style_emb = nn.Embedding(n_styles, emb_dim)

        self.shared_layers = nn.Sequential(
            nn.Linear(emb_dim * 3, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3)
        )

        self.score_head = nn.Sequential(
            nn.Linear(hidden_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )

        self.feedback_head = nn.Sequential(
            nn.Linear(hidden_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 2)
        )

    def forward(self, face, skin, style):
        face_emb = self.face_emb(face)
        skin_emb = self.skin_emb(skin)
        style_emb = self.style_emb(style)

        x = torch.cat([face_emb, skin_emb, style_emb], dim=1)
        shared = self.shared_layers(x)

        score_pred = self.score_head(shared).squeeze(-1)
        feedback_logits = self.feedback_head(shared)

        return score_pred, feedback_logits


# ========== ì „ì—­ ë³€ìˆ˜ (ëª¨ë¸ & ì¸ì½”ë”) ==========
ml_model = None
face_encoder = None
skin_encoder = None
style_encoder = None
sentence_transformer = None
mediapipe_analyzer = None  # MediaPipe ì–¼êµ´ ë¶„ì„ê¸°
hybrid_service = None  # í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì„œë¹„ìŠ¤ (Gemini + ML)
feedback_collector = None  # í”¼ë“œë°± ìˆ˜ì§‘ê¸°
retrain_queue = None  # ì¬í•™ìŠµ í


# ========== CloudWatch Logs êµ¬ì¡°í™” ë¡œê¹… ==========
def log_structured(event_type: str, data: dict):
    """CloudWatch Logs Insightsë¡œ ë¶„ì„ ê°€ëŠ¥í•œ JSON ë¡œê·¸ ìƒì„±"""
    log_entry = {
        "timestamp": datetime.utcnow().isoformat() + "Z",
        "event_type": event_type,
        **data
    }
    logger.info(json.dumps(log_entry, ensure_ascii=False))


def calculate_image_hash(image_data: bytes) -> str:
    """ì´ë¯¸ì§€ì˜ SHA256 í•´ì‹œ ìƒì„± (ìºì‹± í‚¤ë¡œ ì‚¬ìš©)"""
    return hashlib.sha256(image_data).hexdigest()


# ========== ëª¨ë¸ ë¡œë” ==========
def load_ml_model():
    """ML ëª¨ë¸ ë° ì¸ì½”ë” ë¡œë“œ"""
    global ml_model, face_encoder, skin_encoder, style_encoder

    try:
        model_path = 'models/final_model.pth'
        encoder_path = 'models/encoders.pkl'

        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(model_path):
            logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
            return False

        if not os.path.exists(encoder_path):
            logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ ì—†ìŒ: {encoder_path}")
            return False

        # ëª¨ë¸ ë¡œë“œ
        ml_model = HairstyleRecommender()
        ml_model.load_state_dict(torch.load(
            model_path,
            map_location=torch.device('cpu')
        ))
        ml_model.eval()

        # ì¸ì½”ë” ë¡œë“œ
        with open(encoder_path, 'rb') as f:
            encoders = pickle.load(f)
            face_encoder = encoders['face']
            skin_encoder = encoders['skin']
            style_encoder = encoders['style']

        logger.info("âœ… ML ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        logger.info(f"  - ì–¼êµ´í˜•: {len(face_encoder.classes_)}ê°œ")
        logger.info(f"  - í”¼ë¶€í†¤: {len(skin_encoder.classes_)}ê°œ")
        logger.info(f"  - ìŠ¤íƒ€ì¼: {len(style_encoder.classes_)}ê°œ")

        return True

    except Exception as e:
        logger.error(f"âŒ ML ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        ml_model = None
        return False


def load_sentence_transformer():
    """Sentence Transformer ëª¨ë¸ ë¡œë“œ (í—¤ì–´ìŠ¤íƒ€ì¼ ì„ë² ë”©ìš©)"""
    global sentence_transformer

    try:
        from sentence_transformers import SentenceTransformer

        model_name = 'paraphrase-multilingual-MiniLM-L12-v2'
        logger.info(f"â³ Sentence Transformer ë¡œë“œ ì¤‘: {model_name}")

        sentence_transformer = SentenceTransformer(model_name)

        logger.info("âœ… Sentence Transformer ë¡œë“œ ì„±ê³µ")
        logger.info(f"  - ëª¨ë¸: {model_name}")
        logger.info(f"  - ì„ë² ë”© ì°¨ì›: 384")

        return True

    except ImportError:
        logger.warning("âš ï¸ sentence-transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
        logger.warning("  - pip install sentence-transformers ì‹¤í–‰ í•„ìš”")
        sentence_transformer = None
        return False

    except Exception as e:
        logger.error(f"âŒ Sentence Transformer ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        sentence_transformer = None
        return False


# ========== ì˜ˆì¸¡ í•¨ìˆ˜ ==========
def predict_ml_score(face_shape: str, skin_tone: str, hairstyle: str) -> float:
    """
    ML ëª¨ë¸ë¡œ ì ìˆ˜ ì˜ˆì¸¡

    Args:
        face_shape: ì–¼êµ´í˜• (ì˜ˆ: "ê³„ë€í˜•")
        skin_tone: í”¼ë¶€í†¤ (ì˜ˆ: "ë´„ì›œ")
        hairstyle: í—¤ì–´ìŠ¤íƒ€ì¼ (ì˜ˆ: "ì‹œìŠ¤ë£¨ë±… ë‹¨ë°œ")

    Returns:
        ì˜ˆì¸¡ ì ìˆ˜ (0.0 ~ 1.0)
    """
    if ml_model is None:
        return 0.85  # ëª¨ë¸ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’

    try:
        # ========== Gemini ì¶œë ¥ â†’ ML ì…ë ¥ ë§¤í•‘ ==========
        skin_tone_mapping = {
            "ë´„ì›œ": "ì›œí†¤",
            "ê°€ì„ì›œ": "ì›œí†¤",
            "ì—¬ë¦„ì¿¨": "ì¿¨í†¤",
            "ê²¨ìš¸ì¿¨": "ì¿¨í†¤"
        }

        mapped_skin = skin_tone_mapping.get(skin_tone, "ì¤‘ê°„í†¤")

        # ========== ì¸ì½”ë”© ==========
        try:
            face_encoded = face_encoder.transform([face_shape])[0]
        except ValueError:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì–¼êµ´í˜•: {face_shape}, ê¸°ë³¸ê°’ ì‚¬ìš©")
            face_encoded = 1  # ê³„ë€í˜•

        try:
            skin_encoded = skin_encoder.transform([mapped_skin])[0]
        except ValueError:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” í”¼ë¶€í†¤: {mapped_skin}, ê¸°ë³¸ê°’ ì‚¬ìš©")
            skin_encoded = 1  # ì¤‘ê°„í†¤

        try:
            style_encoded = style_encoder.transform([hairstyle])[0]
        except ValueError:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ìŠ¤íƒ€ì¼: {hairstyle}, ê¸°ë³¸ê°’ ì‚¬ìš©")
            style_encoded = 2  # ì‹œìŠ¤ë£¨ë±… ë‹¨ë°œ

        # ========== Tensor ë³€í™˜ ==========
        face_tensor = torch.tensor([face_encoded], dtype=torch.long)
        skin_tensor = torch.tensor([skin_encoded], dtype=torch.long)
        style_tensor = torch.tensor([style_encoded], dtype=torch.long)

        # ========== ì˜ˆì¸¡ ==========
        with torch.no_grad():
            score_pred, _ = ml_model(face_tensor, skin_tensor, style_tensor)
            score = score_pred.item()

        logger.info(f"ML ì˜ˆì¸¡: {face_shape} + {mapped_skin} + {hairstyle} â†’ {score:.3f}")
        return round(score, 3)

    except Exception as e:
        logger.error(f"ML ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
        return 0.85


def get_confidence_level(score: float) -> str:
    """ì ìˆ˜ë¥¼ ì‹ ë¢°ë„ ë ˆë²¨ë¡œ ë³€í™˜"""
    if score >= 0.90:
        return "ë§¤ìš° ë†’ìŒ"
    elif score >= 0.85:
        return "ë†’ìŒ"
    elif score >= 0.75:
        return "ë³´í†µ"
    else:
        return "ë‚®ìŒ"


# ========== í”¼ë“œë°± Enum ==========
class FeedbackType(str, Enum):
    LIKE = "like"
    DISLIKE = "dislike"


# ========== ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ ==========
class AnalysisHistory(Base):
    """ë¶„ì„ ê¸°ë¡ í…Œì´ë¸” - v20.1 (ML í†µí•©)"""
    __tablename__ = "analysis_history"

    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(String(100), default="anonymous")
    image_hash = Column(String(64), index=True)
    face_shape = Column(String(50))
    personal_color = Column(String(50))
    recommendations = Column(JSON)
    processing_time = Column(Float)
    detection_method = Column(String(50))
    created_at = Column(DateTime, default=datetime.utcnow, index=True)

    # OpenCV ì¸¡ì • ë°ì´í„° - ìˆ˜í‰ ë¹„ìœ¨
    opencv_face_ratio = Column(Float)
    opencv_forehead_ratio = Column(Float)
    opencv_cheekbone_ratio = Column(Float)
    opencv_jaw_ratio = Column(Float)
    opencv_prediction = Column(String(50))
    opencv_confidence = Column(Float)
    opencv_gemini_agreement = Column(Boolean)

    # OpenCV ì¸¡ì • ë°ì´í„° - ìˆ˜ì§ ë¹„ìœ¨ (v20.1.6)
    opencv_upper_face_ratio = Column(Float)
    opencv_middle_face_ratio = Column(Float)
    opencv_lower_face_ratio = Column(Float)

    # v20: ì¶”ì²œ ìŠ¤íƒ€ì¼ ì €ì¥
    recommended_styles = Column(JSON)

    # v20: í”¼ë“œë°± ì»¬ëŸ¼ (Stringìœ¼ë¡œ ì €ì¥í•˜ì—¬ íƒ€ì… ë¶ˆì¼ì¹˜ ë°©ì§€)
    style_1_feedback = Column(String(10), nullable=True)
    style_2_feedback = Column(String(10), nullable=True)
    style_3_feedback = Column(String(10), nullable=True)

    # v20: ë„¤ì´ë²„ í´ë¦­ ì—¬ë¶€
    style_1_naver_clicked = Column(Boolean, default=False)
    style_2_naver_clicked = Column(Boolean, default=False)
    style_3_naver_clicked = Column(Boolean, default=False)

    # v20: í”¼ë“œë°± ì œì¶œ ì‹œê°
    feedback_at = Column(DateTime, nullable=True)


# ========== Pydantic ëª¨ë¸ ==========
class FeedbackRequest(BaseModel):
    """í”¼ë“œë°± ì œì¶œ ìš”ì²­"""
    analysis_id: int = Field(..., description="ë¶„ì„ ê²°ê³¼ ID")
    style_index: int = Field(..., ge=1, le=3, description="ìŠ¤íƒ€ì¼ ì¸ë±ìŠ¤ (1, 2, 3)")
    feedback: FeedbackType = Field(..., description="ì¢‹ì•„ìš” ë˜ëŠ” ì‹«ì–´ìš”")
    naver_clicked: bool = Field(default=False, description="ë„¤ì´ë²„ ì´ë¯¸ì§€ ê²€ìƒ‰ í´ë¦­ ì—¬ë¶€")


class FeedbackResponse(BaseModel):
    """í”¼ë“œë°± ì œì¶œ ì‘ë‹µ"""
    success: bool
    message: str
    analysis_id: int
    style_index: int


# ========== FastAPI ì•± ì´ˆê¸°í™” ==========
app = FastAPI(
    title="HairMe API",
    description="AI ê¸°ë°˜ í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ ì„œë¹„ìŠ¤ (v20.1.6: ìˆ˜ì§ ë¹„ìœ¨ ë°ì´í„° ìˆ˜ì§‘)",
    version="20.1.6"
)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ========== ë¼ìš°í„° ë“±ë¡ ==========
app.include_router(admin_router, prefix="/api", tags=["admin"])


# ========== ì•± ì‹œì‘ ì´ë²¤íŠ¸ ==========
@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ML ëª¨ë¸ ë¡œë“œ"""
    global mediapipe_analyzer, hybrid_service, feedback_collector, retrain_queue

    logger.info("ğŸš€ ì„œë²„ ì‹œì‘ ì¤‘...")

    # MediaPipe ì–¼êµ´ ë¶„ì„ê¸° ì´ˆê¸°í™”
    try:
        mediapipe_analyzer = MediaPipeFaceAnalyzer()
        logger.info("âœ… MediaPipe ì–¼êµ´ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        log_structured("mediapipe_initialized", {
            "status": "success",
            "landmarks": 478
        })
    except Exception as e:
        logger.error(f"âŒ MediaPipe ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        mediapipe_analyzer = None
        log_structured("mediapipe_initialized", {
            "status": "failed",
            "error": str(e)
        })

    # ML ëª¨ë¸ ë¡œë“œ ì‹œë„
    ml_loaded = load_ml_model()

    if ml_loaded:
        logger.info("âœ… ML ëª¨ë“œ: í™œì„±í™”")
        log_structured("ml_model_loaded", {
            "status": "success",
            "model_path": "models/final_model.pth"
        })
    else:
        logger.warning("âš ï¸ ML ëª¨ë“œ: ë¹„í™œì„±í™” (ê¸°ë³¸ ì ìˆ˜ ì‚¬ìš©)")
        log_structured("ml_model_loaded", {
            "status": "failed",
            "fallback": "default_score"
        })

    # Sentence Transformer ë¡œë“œ ì‹œë„
    st_loaded = load_sentence_transformer()

    if st_loaded:
        logger.info("âœ… ìŠ¤íƒ€ì¼ ì„ë² ë”©: í™œì„±í™”")
        log_structured("sentence_transformer_loaded", {
            "status": "success",
            "model": "paraphrase-multilingual-MiniLM-L12-v2",
            "embedding_dim": 384
        })
    else:
        logger.warning("âš ï¸ ìŠ¤íƒ€ì¼ ì„ë² ë”©: ë¹„í™œì„±í™” (ì„ë² ë”© ì—†ì´ ì§„í–‰)")
        log_structured("sentence_transformer_loaded", {
            "status": "failed",
            "fallback": "no_embedding"
        })

    # í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (Gemini + ML)
    try:
        gemini_api_key = os.getenv("GEMINI_API_KEY")
        if gemini_api_key:
            hybrid_service = get_hybrid_service(gemini_api_key)
            logger.info("âœ… í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ (Gemini + ML)")
            log_structured("hybrid_service_initialized", {
                "status": "success",
                "gemini_model": "gemini-1.5-flash-latest",
                "ml_model": "hairstyle_recommender.pt"
            })
        else:
            logger.warning("âš ï¸ GEMINI_API_KEY ì—†ìŒ - í•˜ì´ë¸Œë¦¬ë“œ ì„œë¹„ìŠ¤ ë¹„í™œì„±í™”")
            hybrid_service = None
    except Exception as e:
        logger.error(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        hybrid_service = None
        log_structured("hybrid_service_initialized", {
            "status": "failed",
            "error": str(e)
        })

    # í”¼ë“œë°± ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
    try:
        feedback_collector = get_feedback_collector()
        logger.info("âœ… í”¼ë“œë°± ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        log_structured("feedback_collector_initialized", {
            "status": "success"
        })
    except Exception as e:
        logger.error(f"âŒ í”¼ë“œë°± ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        feedback_collector = None
        log_structured("feedback_collector_initialized", {
            "status": "failed",
            "error": str(e)
        })

    # ì¬í•™ìŠµ í ì´ˆê¸°í™”
    try:
        retrain_queue = get_retrain_queue()
        logger.info("âœ… ì¬í•™ìŠµ í ì´ˆê¸°í™” ì™„ë£Œ")
        log_structured("retrain_queue_initialized", {
            "status": "success"
        })
    except Exception as e:
        logger.error(f"âŒ ì¬í•™ìŠµ í ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        retrain_queue = None
        log_structured("retrain_queue_initialized", {
            "status": "failed",
            "error": str(e)
        })


# ========== ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ==========
SessionLocal = None
DATABASE_URL = os.getenv("DATABASE_URL")
DB_PASSWORD = os.getenv("DB_PASSWORD")


def migrate_database_schema():
    """
    v20 ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ (ìë™ ì‹¤í–‰)
    - í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ì¶”ê°€
    - ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ
    """
    if not SessionLocal:
        return

    try:
        from sqlalchemy import text
        db = SessionLocal()

        logger.info("ğŸ”„ DB ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")

        # í˜„ì¬ í…Œì´ë¸” êµ¬ì¡° í™•ì¸
        result = db.execute(text("DESCRIBE analysis_history"))
        existing_columns = {row[0] for row in result}

        required_columns = [
            "recommended_styles",
            "style_1_feedback",
            "style_2_feedback",
            "style_3_feedback",
            "style_1_naver_clicked",
            "style_2_naver_clicked",
            "style_3_naver_clicked",
            "feedback_at",
            # v20.1.6: ìˆ˜ì§ ë¹„ìœ¨ ë°ì´í„°
            "opencv_upper_face_ratio",
            "opencv_middle_face_ratio",
            "opencv_lower_face_ratio"
        ]

        missing_columns = [col for col in required_columns if col not in existing_columns]

        if not missing_columns:
            logger.info("âœ… ìŠ¤í‚¤ë§ˆê°€ ì´ë¯¸ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤ (v20.1.6)")
            db.close()
            return

        logger.info(f"ğŸ”§ ëˆ„ë½ëœ ì»¬ëŸ¼ ë°œê²¬: {missing_columns}")

        # ë§ˆì´ê·¸ë ˆì´ì…˜ SQL ì‹¤í–‰
        migration_sqls = []

        if "recommended_styles" in missing_columns:
            migration_sqls.append(
                "ALTER TABLE analysis_history ADD COLUMN recommended_styles JSON COMMENT 'ì¶”ì²œëœ 3ê°œ í—¤ì–´ìŠ¤íƒ€ì¼'"
            )

        if "style_1_feedback" in missing_columns:
            migration_sqls.append(
                "ALTER TABLE analysis_history ADD COLUMN style_1_feedback ENUM('like', 'dislike') DEFAULT NULL"
            )

        if "style_2_feedback" in missing_columns:
            migration_sqls.append(
                "ALTER TABLE analysis_history ADD COLUMN style_2_feedback ENUM('like', 'dislike') DEFAULT NULL"
            )

        if "style_3_feedback" in missing_columns:
            migration_sqls.append(
                "ALTER TABLE analysis_history ADD COLUMN style_3_feedback ENUM('like', 'dislike') DEFAULT NULL"
            )

        if "style_1_naver_clicked" in missing_columns:
            migration_sqls.append(
                "ALTER TABLE analysis_history ADD COLUMN style_1_naver_clicked BOOLEAN DEFAULT FALSE"
            )

        if "style_2_naver_clicked" in missing_columns:
            migration_sqls.append(
                "ALTER TABLE analysis_history ADD COLUMN style_2_naver_clicked BOOLEAN DEFAULT FALSE"
            )

        if "style_3_naver_clicked" in missing_columns:
            migration_sqls.append(
                "ALTER TABLE analysis_history ADD COLUMN style_3_naver_clicked BOOLEAN DEFAULT FALSE"
            )

        if "feedback_at" in missing_columns:
            migration_sqls.append(
                "ALTER TABLE analysis_history ADD COLUMN feedback_at DATETIME DEFAULT NULL"
            )

        # v20.1.6: ìˆ˜ì§ ë¹„ìœ¨ ì»¬ëŸ¼ ì¶”ê°€
        if "opencv_upper_face_ratio" in missing_columns:
            migration_sqls.append(
                "ALTER TABLE analysis_history ADD COLUMN opencv_upper_face_ratio FLOAT DEFAULT NULL COMMENT 'ìƒì•ˆë¶€ ë†’ì´ ë¹„ìœ¨'"
            )

        if "opencv_middle_face_ratio" in missing_columns:
            migration_sqls.append(
                "ALTER TABLE analysis_history ADD COLUMN opencv_middle_face_ratio FLOAT DEFAULT NULL COMMENT 'ì¤‘ì•ˆë¶€ ë†’ì´ ë¹„ìœ¨'"
            )

        if "opencv_lower_face_ratio" in missing_columns:
            migration_sqls.append(
                "ALTER TABLE analysis_history ADD COLUMN opencv_lower_face_ratio FLOAT DEFAULT NULL COMMENT 'í•˜ì•ˆë¶€ ë†’ì´ ë¹„ìœ¨'"
            )

        # íŠ¸ëœì­ì…˜ìœ¼ë¡œ ì‹¤í–‰
        for sql in migration_sqls:
            logger.info(f"ì‹¤í–‰: {sql[:80]}...")
            db.execute(text(sql))

        db.commit()
        logger.info("âœ… ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")

        log_structured("schema_migration", {
            "status": "success",
            "added_columns": missing_columns
        })

        db.close()

    except Exception as e:
        logger.error(f"âŒ ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {str(e)}")
        logger.error("ì„œë²„ëŠ” ê³„ì† ì‹¤í–‰ë˜ì§€ë§Œ, v20 ê¸°ëŠ¥ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        if 'db' in locals():
            db.rollback()
            db.close()


if DATABASE_URL and DB_PASSWORD:
    try:
        sync_db_url = DATABASE_URL.replace("asyncmy", "pymysql").replace("://admin@", f"://admin:{DB_PASSWORD}@")
        engine = create_engine(
            sync_db_url,
            pool_pre_ping=True,
            pool_recycle=3600,
            echo=False
        )
        SessionLocal = sessionmaker(bind=engine)
        Base.metadata.create_all(bind=engine)
        logger.info("âœ… MySQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")

        # ğŸ†• ìë™ ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
        migrate_database_schema()

        log_structured("database_connected", {
            "database": "hairme-data",
            "tables": ["analysis_history"]
        })
    except Exception as e:
        logger.error(f"âŒ MySQL ì—°ê²° ì‹¤íŒ¨: {str(e)}")
        SessionLocal = None
else:
    logger.warning("âš ï¸ DATABASE_URL ë˜ëŠ” DB_PASSWORDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ========== Redis ìºì‹œ ==========
redis_client = None
REDIS_URL = os.getenv("REDIS_URL")
CACHE_TTL = 86400

if REDIS_URL:
    try:
        redis_client = redis.from_url(REDIS_URL, decode_responses=True)
        redis_client.ping()
        logger.info(f"âœ… Redis ì—°ê²° ì„±ê³µ: {REDIS_URL}")
    except Exception as e:
        logger.error(f"âŒ Redis ì—°ê²° ì‹¤íŒ¨: {str(e)}")
        redis_client = None
else:
    logger.warning("âš ï¸ REDIS_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def get_cached_result(image_hash: str) -> Optional[dict]:
    """Redisì—ì„œ ìºì‹œëœ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
    if not redis_client:
        return None
    try:
        cached = redis_client.get(f"analysis:{image_hash}")
        if cached:
            log_structured("cache_hit", {"image_hash": image_hash[:16]})
            return json.loads(cached)
        return None
    except Exception as e:
        logger.error(f"Redis ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None


def save_to_cache(image_hash: str, result: dict):
    """Redisì— ë¶„ì„ ê²°ê³¼ ì €ì¥"""
    if not redis_client:
        return
    try:
        redis_client.setex(
            f"analysis:{image_hash}",
            CACHE_TTL,
            json.dumps(result, ensure_ascii=False)
        )
    except Exception as e:
        logger.error(f"Redis ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")


# ========== Gemini API ì´ˆê¸°í™” ==========
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    logger.error("GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
else:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        logger.info("âœ… Gemini API ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.error(f"Gemini API ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

MODEL_NAME = "gemini-flash-latest"

# ========== Haar Cascade ì œê±°ë¨ (MediaPipeë¡œ ëŒ€ì²´) ==========
# MediaPipeê°€ ì‹¤íŒ¨í•˜ë©´ Geminië¡œ ì§ì ‘ ë°±ì—…

# ========== Gemini ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ==========
ANALYSIS_PROMPT = """ë¶„ì„í•˜ê³  JSONìœ¼ë¡œ ì‘ë‹µ:

ì–¼êµ´í˜•: ê³„ë€í˜•/ë‘¥ê·¼í˜•/ê°ì§„í˜•/ê¸´í˜• ì¤‘ 1ê°œ
í¼ìŠ¤ë„ì»¬ëŸ¬: ë´„ì›œ/ê°€ì„ì›œ/ì—¬ë¦„ì¿¨/ê²¨ìš¸ì¿¨ ì¤‘ 1ê°œ
í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ 3ê°œ (ê° ì´ë¦„ 15ì, ì´ìœ  30ì ì´ë‚´)

JSON í˜•ì‹:
{
  "analysis": {
    "face_shape": "ê³„ë€í˜•",
    "personal_color": "ë´„ì›œ",
    "features": "ì´ëª©êµ¬ë¹„ íŠ¹ì§•"
  },
  "recommendations": [
    {"style_name": "ìŠ¤íƒ€ì¼ëª…", "reason": "ì¶”ì²œ ì´ìœ "}
  ]
}"""


# ========== í—¬í¼ í•¨ìˆ˜ë“¤ ==========
def verify_face_with_gemini(image_data: bytes) -> dict:
    """OpenCV ì‹¤íŒ¨ ì‹œ Geminië¡œ ë¹ ë¥¸ ì–¼êµ´ ê²€ì¦"""
    try:
        image = Image.open(io.BytesIO(image_data))
        image.thumbnail((256, 256))

        model = genai.GenerativeModel(MODEL_NAME)
        prompt = """ì´ë¯¸ì§€ì— ì‚¬ëŒ ì–¼êµ´ì´ ìˆë‚˜ìš”?

JSONìœ¼ë¡œë§Œ ë‹µë³€:
{"has_face": true/false, "face_count": ìˆ«ì}"""

        response = model.generate_content([prompt, image])
        result = json.loads(response.text.strip())

        return {
            "has_face": result.get("has_face", False),
            "face_count": result.get("face_count", 0),
            "method": "gemini"
        }

    except Exception as e:
        logger.error(f"Gemini ì–¼êµ´ ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
        return {
            "has_face": False,
            "face_count": 0,
            "method": "gemini",
            "error": str(e)
        }


def detect_face(image_data: bytes) -> dict:
    """ì–¼êµ´ ê°ì§€ (MediaPipe ìš°ì„ , ì‹¤íŒ¨ ì‹œ Gemini)"""
    # 1ì°¨ ì‹œë„: MediaPipe (ê°€ì¥ ì •í™•í•¨ - 90%+)
    if mediapipe_analyzer is not None:
        try:
            mp_features = mediapipe_analyzer.analyze(image_data)

            if mp_features:
                log_structured("face_detection", {
                    "method": "mediapipe",
                    "face_count": 1,
                    "success": True,
                    "face_shape": mp_features.face_shape,
                    "skin_tone": mp_features.skin_tone,
                    "confidence": mp_features.confidence
                })
                return {
                    "has_face": True,
                    "face_count": 1,
                    "method": "mediapipe",
                    "features": mp_features  # MediaPipe ë¶„ì„ ê²°ê³¼ í¬í•¨
                }

        except Exception as e:
            logger.warning(f"MediaPipe ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨: {str(e)}")

    # 2ì°¨ ì‹œë„: Gemini (ìµœì¢… ë°±ì—…)
    logger.info("MediaPipe ì‹¤íŒ¨, Geminië¡œ ì–¼êµ´ ê²€ì¦ ì‹œì‘...")
    gemini_result = verify_face_with_gemini(image_data)

    log_structured("face_detection", {
        "method": "gemini",
        "face_count": gemini_result.get("face_count", 0),
        "success": gemini_result.get("has_face", False)
    })

    return gemini_result


def analyze_with_gemini(image_data: bytes, mp_features: Optional[MediaPipeFaceFeatures] = None) -> dict:
    """Gemini Vision APIë¡œ ì–¼êµ´ ë¶„ì„ (MediaPipe íŒíŠ¸ ì œê³µ)"""
    try:
        image = Image.open(io.BytesIO(image_data))

        # MediaPipe ê²°ê³¼ê°€ ìˆìœ¼ë©´ íŒíŠ¸ ì œê³µ
        if mp_features:
            prompt = f"""ë‹¤ìŒ ì–¼êµ´ ì‚¬ì§„ì„ ë¶„ì„í•˜ê³  JSONìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.

ğŸ” **ì°¸ê³ ìš© ì¸¡ì • ë°ì´í„°** (MediaPipe AI ë¶„ì„ - ì‹ ë¢°ë„ {mp_features.confidence:.0%}):
- ì–¼êµ´í˜•: {mp_features.face_shape}
- í”¼ë¶€í†¤: {mp_features.skin_tone}
- ì–¼êµ´ ë¹„ìœ¨(ë†’ì´/ë„ˆë¹„): {mp_features.face_ratio:.2f}
- ì´ë§ˆ ë„ˆë¹„: {mp_features.forehead_width:.0f}px
- ê´‘ëŒ€ ë„ˆë¹„: {mp_features.cheekbone_width:.0f}px
- í„± ë„ˆë¹„: {mp_features.jaw_width:.0f}px
- ITA ê°’: {mp_features.ITA_value:.1f}Â°

ìœ„ ìˆ˜ì¹˜ëŠ” ì°¸ê³ ë§Œ í•˜ê³ , ë‹¹ì‹ ì˜ ì‹œê°ì  íŒë‹¨ì„ ìš°ì„ í•˜ì„¸ìš”.

**ë¶„ì„ í•­ëª©:**
1. ì–¼êµ´í˜•: ê³„ë€í˜•/ë‘¥ê·¼í˜•/ê°ì§„í˜•/ê¸´í˜•/í•˜íŠ¸í˜• ì¤‘ 1ê°œ
2. í¼ìŠ¤ë„ì»¬ëŸ¬: ë´„ì›œ/ê°€ì„ì›œ/ì—¬ë¦„ì¿¨/ê²¨ìš¸ì¿¨ ì¤‘ 1ê°œ
3. í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ 3ê°œ (ê° ì´ë¦„ 15ì, ì´ìœ  30ì ì´ë‚´)

**JSON í˜•ì‹:**
{{
  "analysis": {{
    "face_shape": "ê³„ë€í˜•",
    "personal_color": "ë´„ì›œ",
    "features": "ì´ëª©êµ¬ë¹„ íŠ¹ì§• ì„¤ëª…"
  }},
  "recommendations": [
    {{"style_name": "ìŠ¤íƒ€ì¼ëª…", "reason": "ì¶”ì²œ ì´ìœ "}}
  ]
}}"""
            logger.info(f"âœ… MediaPipe íŒíŠ¸ ì ìš©: {mp_features.face_shape} / {mp_features.skin_tone}")

        else:
            # MediaPipe ì—†ì„ ë•Œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
            prompt = ANALYSIS_PROMPT
            logger.warning("âš ï¸ MediaPipe íŠ¹ì§• ì—†ìŒ, ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")

        model = genai.GenerativeModel(MODEL_NAME)
        response = model.generate_content([prompt, image])

        raw_text = response.text.strip()

        if raw_text.startswith("```json"):
            raw_text = raw_text[7:]
        if raw_text.startswith("```"):
            raw_text = raw_text[3:]
        if raw_text.endswith("```"):
            raw_text = raw_text[:-3]

        result = json.loads(raw_text.strip())

        logger.info(f"âœ… Gemini ë¶„ì„ ì„±ê³µ: {result.get('analysis', {}).get('face_shape')}")
        return result

    except json.JSONDecodeError as e:
        logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}\nì‘ë‹µ ë‚´ìš©: {response.text[:200]}")
        raise HTTPException(
            status_code=500,
            detail=f"AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {str(e)}"
        )
    except Exception as e:
        logger.error(f"Gemini ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


def save_to_database(
        image_hash: str,
        analysis_result: dict,
        processing_time: float,
        detection_method: str,
        mp_features: Optional[MediaPipeFaceFeatures] = None
) -> Optional[int]:
    """ë¶„ì„ ê²°ê³¼ë¥¼ MySQLì— ì €ì¥í•˜ê³  ID ë°˜í™˜"""
    if not SessionLocal:
        logger.warning("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ì—†ì–´ ì €ì¥ì„ ìƒëµí•©ë‹ˆë‹¤.")
        return None

    try:
        db = SessionLocal()

        gemini_shape = analysis_result.get("analysis", {}).get("face_shape")

        # MediaPipe ì¼ì¹˜ë„ ê³„ì‚°
        mediapipe_agreement = None
        if mp_features:
            mediapipe_agreement = (
                    mp_features.face_shape in gemini_shape or
                    gemini_shape in mp_features.face_shape
            )

        recommendations = analysis_result.get("recommendations", [])

        history = AnalysisHistory(
            image_hash=image_hash,
            face_shape=gemini_shape,
            personal_color=analysis_result.get("analysis", {}).get("personal_color"),
            recommendations=recommendations,
            recommended_styles=recommendations,
            processing_time=processing_time,
            detection_method=detection_method,
            # OpenCV ë°ì´í„°ëŠ” ë”ì´ìƒ ìˆ˜ì§‘í•˜ì§€ ì•ŠìŒ (MediaPipeë¡œ ëŒ€ì²´)
            opencv_face_ratio=None,
            opencv_forehead_ratio=None,
            opencv_cheekbone_ratio=None,
            opencv_jaw_ratio=None,
            opencv_prediction=None,
            opencv_confidence=None,
            opencv_gemini_agreement=mediapipe_agreement,  # MediaPipe ì¼ì¹˜ë„ë¡œ ëŒ€ì²´
            opencv_upper_face_ratio=None,
            opencv_middle_face_ratio=None,
            opencv_lower_face_ratio=None
        )

        db.add(history)
        db.commit()
        db.refresh(history)

        logger.info(f"âœ… DB ì €ì¥ ì„±ê³µ (ID: {history.id})")
        log_structured("database_saved", {
            "record_id": history.id,
            "mediapipe_enabled": mp_features is not None,
            "mediapipe_agreement": mediapipe_agreement,
            "recommendations_count": len(recommendations)
        })

        db.close()
        return history.id

    except Exception as e:
        logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return None  # âœ… ì—ëŸ¬ ì‹œ None ë°˜í™˜


# ========== API ì—”ë“œí¬ì¸íŠ¸ ==========
@app.get("/")
async def root():
    """Root ì—”ë“œí¬ì¸íŠ¸"""
    mediapipe_status = "enabled" if mediapipe_analyzer is not None else "disabled"
    return {
        "message": "í—¤ì–´ìŠ¤íƒ€ì¼ ë¶„ì„ API - v20.2.0 (MediaPipe ì „í™˜ ì™„ë£Œ)",
        "version": "20.2.0",
        "model": MODEL_NAME,
        "status": "running",
        "features": {
            "mediapipe_analysis": mediapipe_status,
            "gemini_analysis": "enabled" if GEMINI_API_KEY else "disabled",
            "redis_cache": "enabled" if redis_client else "disabled",
            "database": "enabled" if SessionLocal else "disabled",
            "feedback_system": "enabled",
            "ml_prediction": "enabled" if ml_model else "disabled",
            "style_embedding": "enabled" if sentence_transformer else "disabled"
        }
    }


@app.get("/api/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    mediapipe_status = "enabled" if mediapipe_analyzer is not None else "disabled"

    return {
        "status": "healthy",
        "version": "20.2.0",
        "model": MODEL_NAME,
        "mediapipe_analysis": mediapipe_status,
        "gemini_api": "configured" if GEMINI_API_KEY else "not_configured",
        "redis": "connected" if redis_client else "disconnected",
        "database": "connected" if SessionLocal else "disconnected",
        "feedback_system": "enabled",
        "ml_model": "enabled" if ml_model else "disabled",
        "style_embedding": "enabled" if sentence_transformer else "disabled"
    }


@app.post("/api/analyze")
async def analyze_face(file: UploadFile = File(...)):
    """ì–¼êµ´ ë¶„ì„ ë° í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ (v20.1: ML í†µí•©)"""
    start_time = time.time()
    image_hash = None

    try:
        if not GEMINI_API_KEY:
            raise HTTPException(
                status_code=500,
                detail="Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )

        if not file.filename:
            raise HTTPException(status_code=400, detail="íŒŒì¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤")

        file_ext = file.filename.lower().split('.')[-1]
        if file_ext not in ['jpg', 'jpeg', 'png', 'webp']:
            raise HTTPException(
                status_code=400,
                detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. (jpg, jpeg, png, webpë§Œ ê°€ëŠ¥)"
            )

        logger.info(f"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹œì‘: {file.filename}")

        image_data = await file.read()
        image_hash = calculate_image_hash(image_data)

        log_structured("analysis_start", {
            "filename": file.filename,
            "file_size_kb": round(len(image_data) / 1024, 2),
            "image_hash": image_hash[:16]
        })

        # ìºì‹œ í™•ì¸
        cached_result = get_cached_result(image_hash)
        if cached_result:
            total_time = round(time.time() - start_time, 2)
            return {
                "success": True,
                "data": cached_result,
                "processing_time": total_time,
                "cached": True,
                "model_used": MODEL_NAME
            }

        # ì–¼êµ´ ê°ì§€
        face_detection_start = time.time()
        face_result = detect_face(image_data)
        face_detection_time = round((time.time() - face_detection_start) * 1000, 2)

        if not face_result["has_face"]:
            log_structured("analysis_error", {
                "error_type": "no_face_detected",
                "image_hash": image_hash[:16]
            })
            return JSONResponse(
                status_code=400,
                content={
                    "success": False,
                    "error": "no_face_detected",
                    "message": "ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\në°ì€ ê³³ì—ì„œ ì •ë©´ ì‚¬ì§„ì„ ì´¬ì˜í•´ì£¼ì„¸ìš”."
                }
            )

        if face_result["face_count"] > 1:
            return JSONResponse(
                status_code=400,
                content={
                    "success": False,
                    "error": "multiple_faces",
                    "message": f"{face_result['face_count']}ëª…ì˜ ì–¼êµ´ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\ní•œ ëª…ë§Œ ë‚˜ì˜¨ ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
                }
            )

        # MediaPipe features ì¶”ì¶œ (detect_faceì—ì„œ ì´ë¯¸ ë¶„ì„ë¨)
        mp_features = face_result.get("features", None)

        # Gemini ë¶„ì„ (MediaPipe íŒíŠ¸ ì œê³µ)
        gemini_start = time.time()
        analysis_result = analyze_with_gemini(image_data, mp_features)
        gemini_time = round((time.time() - gemini_start) * 1000, 2)

        # âœ… ML ì ìˆ˜ ì¶”ê°€
        face_shape = analysis_result.get("analysis", {}).get("face_shape")
        skin_tone = analysis_result.get("analysis", {}).get("personal_color")

        for idx, recommendation in enumerate(analysis_result.get("recommendations", []), 1):
            style_name = recommendation.get("style_name", "")

            # ML ì˜ˆì¸¡ ì ìˆ˜ ê³„ì‚°
            ml_score = predict_ml_score(face_shape, skin_tone, style_name)

            # ê²°ê³¼ì— ì¶”ê°€
            recommendation['ml_confidence'] = ml_score
            recommendation['confidence_level'] = get_confidence_level(ml_score)

            # ìŠ¤íƒ€ì¼ ì„ë² ë”© ìƒì„± (Sentence Transformer)
            if sentence_transformer is not None:
                try:
                    embedding = sentence_transformer.encode(style_name)
                    recommendation['style_embedding'] = embedding.tolist()
                    logger.info(f"âœ… ì„ë² ë”© ìƒì„± ì„±ê³µ: {style_name} â†’ {len(embedding)}ì°¨ì›")
                except Exception as e:
                    logger.error(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ ({style_name}): {str(e)}")
                    recommendation['style_embedding'] = None
            else:
                recommendation['style_embedding'] = None

            # ë„¤ì´ë²„ ê²€ìƒ‰ URL
            encoded_query = urllib.parse.quote(f"{style_name} í—¤ì–´ìŠ¤íƒ€ì¼")
            recommendation[
                "image_search_url"] = f"https://search.naver.com/search.naver?where=image&query={encoded_query}"

        # ìºì‹±
        save_to_cache(image_hash, analysis_result)

        # DB ì €ì¥
        total_time = round(time.time() - start_time, 2)
        analysis_id = save_to_database(
            image_hash=image_hash,
            analysis_result=analysis_result,
            processing_time=total_time,
            detection_method=face_result.get("method", "mediapipe"),
            mp_features=mp_features
        )

        log_structured("analysis_complete", {
            "image_hash": image_hash[:16],
            "processing_time": total_time,
            "face_detection_time_ms": face_detection_time,
            "gemini_analysis_time_ms": gemini_time,
            "mediapipe_enabled": mp_features is not None,
            "ml_enabled": ml_model is not None,
            "embedding_enabled": sentence_transformer is not None,
            "face_shape": face_shape,
            "personal_color": skin_tone,
            "analysis_id": analysis_id
        })

        return {
            "success": True,
            "data": analysis_result,
            "analysis_id": analysis_id,
            "processing_time": total_time,
            "performance": {
                "face_detection_ms": face_detection_time,
                "gemini_analysis_ms": gemini_time,
                "detection_method": face_result.get("method", "mediapipe"),
                "mediapipe_analysis": "enabled" if mp_features else "failed",
                "ml_prediction": "enabled" if ml_model else "disabled",
                "style_embedding": "enabled" if sentence_transformer else "disabled"
            },
            "cached": False,
            "model_used": MODEL_NAME
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

        log_structured("analysis_error", {
            "error_type": "internal_error",
            "error_message": str(e),
            "image_hash": image_hash[:16] if image_hash else "unknown"
        })

        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": "internal_error",
                "message": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }
        )


@app.post("/api/feedback", response_model=FeedbackResponse)
async def submit_feedback(request: FeedbackRequest):
    """ì‚¬ìš©ì í”¼ë“œë°± ì œì¶œ ì—”ë“œí¬ì¸íŠ¸"""
    if not SessionLocal:
        raise HTTPException(
            status_code=500,
            detail="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤"
        )

    try:
        db = SessionLocal()

        record = db.query(AnalysisHistory).filter(
            AnalysisHistory.id == request.analysis_id
        ).first()

        if not record:
            db.close()
            raise HTTPException(
                status_code=404,
                detail=f"ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ID: {request.analysis_id})"
            )

        feedback_column = f"style_{request.style_index}_feedback"
        clicked_column = f"style_{request.style_index}_naver_clicked"

        # ëª…ì‹œì  ë¬¸ìì—´ ë³€í™˜ (Enum â†’ str)
        setattr(record, feedback_column, request.feedback.value)
        setattr(record, clicked_column, request.naver_clicked)
        record.feedback_at = datetime.utcnow()

        db.commit()

        logger.info(
            f"âœ… í”¼ë“œë°± ì €ì¥ ì„±ê³µ: analysis_id={request.analysis_id}, style={request.style_index}, feedback={request.feedback}")

        log_structured("feedback_submitted", {
            "analysis_id": request.analysis_id,
            "style_index": request.style_index,
            "feedback": request.feedback,
            "naver_clicked": request.naver_clicked
        })

        db.close()

        return FeedbackResponse(
            success=True,
            message="í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤",
            analysis_id=request.analysis_id,
            style_index=request.style_index
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ í”¼ë“œë°± ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"í”¼ë“œë°± ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )


@app.get("/api/stats/feedback")
async def get_feedback_stats():
    """
    í”¼ë“œë°± í†µê³„ ì¡°íšŒ API

    Returns:
        - total_analysis: ì „ì²´ ë¶„ì„ ê¸°ë¡ ìˆ˜
        - total_feedback: í”¼ë“œë°±ì´ ìˆëŠ” ê¸°ë¡ ìˆ˜
        - recent_feedbacks: ìµœê·¼ 5ê°œ í”¼ë“œë°± ë°ì´í„°
    """
    if not SessionLocal:
        raise HTTPException(
            status_code=500,
            detail="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤"
        )

    try:
        db = SessionLocal()

        # ì „ì²´ í†µê³„
        total = db.query(AnalysisHistory).count()
        feedback_count = db.query(AnalysisHistory).filter(
            AnalysisHistory.feedback_at.isnot(None)
        ).count()

        # ìµœê·¼ 5ê°œ í”¼ë“œë°±
        recent = db.query(AnalysisHistory).filter(
            AnalysisHistory.feedback_at.isnot(None)
        ).order_by(AnalysisHistory.id.desc()).limit(5).all()

        recent_data = []
        for r in recent:
            recent_data.append({
                "id": r.id,
                "face_shape": r.face_shape,
                "personal_color": r.personal_color,
                "style_1_feedback": r.style_1_feedback,
                "style_2_feedback": r.style_2_feedback,
                "style_3_feedback": r.style_3_feedback,
                "style_1_naver_clicked": r.style_1_naver_clicked,
                "style_2_naver_clicked": r.style_2_naver_clicked,
                "style_3_naver_clicked": r.style_3_naver_clicked,
                "feedback_at": r.feedback_at.isoformat() if r.feedback_at else None,
                "created_at": r.created_at.isoformat() if r.created_at else None
            })

        # ì¢‹ì•„ìš”/ì‹«ì–´ìš” í†µê³„
        like_counts = {
            "style_1": 0,
            "style_2": 0,
            "style_3": 0
        }
        dislike_counts = {
            "style_1": 0,
            "style_2": 0,
            "style_3": 0
        }

        all_feedback = db.query(AnalysisHistory).filter(
            AnalysisHistory.feedback_at.isnot(None)
        ).all()

        for record in all_feedback:
            if record.style_1_feedback == "like":
                like_counts["style_1"] += 1
            elif record.style_1_feedback == "dislike":
                dislike_counts["style_1"] += 1

            if record.style_2_feedback == "like":
                like_counts["style_2"] += 1
            elif record.style_2_feedback == "dislike":
                dislike_counts["style_2"] += 1

            if record.style_3_feedback == "like":
                like_counts["style_3"] += 1
            elif record.style_3_feedback == "dislike":
                dislike_counts["style_3"] += 1

        db.close()

        logger.info(f"ğŸ“Š í†µê³„ ì¡°íšŒ: ì „ì²´ {total}ê°œ, í”¼ë“œë°± {feedback_count}ê°œ")

        return {
            "success": True,
            "total_analysis": total,
            "total_feedback": feedback_count,
            "like_counts": like_counts,
            "dislike_counts": dislike_counts,
            "recent_feedbacks": recent_data
        }

    except Exception as e:
        logger.error(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )


# ========== í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì—”ë“œí¬ì¸íŠ¸ (Gemini + ML) ==========
@app.post("/api/v2/analyze-hybrid")
async def analyze_face_hybrid(file: UploadFile = File(...)):
    """
    í•˜ì´ë¸Œë¦¬ë“œ ì–¼êµ´ ë¶„ì„ ë° í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ (Gemini + ML)

    í”Œë¡œìš°:
    1. MediaPipeë¡œ ì–¼êµ´í˜• + í”¼ë¶€í†¤ ë¶„ì„
    2. Gemini APIë¡œ 4ê°œ ì¶”ì²œ
    3. ML ëª¨ë¸ë¡œ Top-3 ì¶”ì²œ
    4. ì¤‘ë³µ ì œê±° í›„ ìµœëŒ€ 7ê°œ ë°˜í™˜
    """
    start_time = time.time()

    try:
        # íŒŒì¼ ê²€ì¦
        if not file.filename:
            raise HTTPException(status_code=400, detail="íŒŒì¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤")

        file_ext = file.filename.lower().split('.')[-1]
        if file_ext not in ['jpg', 'jpeg', 'png', 'webp']:
            raise HTTPException(
                status_code=400,
                detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤."
            )

        logger.info(f"ğŸ¨ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‹œì‘: {file.filename}")

        # ì´ë¯¸ì§€ ì½ê¸°
        image_data = await file.read()
        image_hash = calculate_image_hash(image_data)

        # 1. MediaPipeë¡œ ì–¼êµ´ ë¶„ì„
        if not mediapipe_analyzer:
            raise HTTPException(
                status_code=500,
                detail="MediaPipe ë¶„ì„ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )

        mp_features = mediapipe_analyzer.analyze(image_data)

        if not mp_features:
            return JSONResponse(
                status_code=400,
                content={
                    "success": False,
                    "error": "no_face_detected",
                    "message": "ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\\në°ì€ ê³³ì—ì„œ ì •ë©´ ì‚¬ì§„ì„ ì´¬ì˜í•´ì£¼ì„¸ìš”."
                }
            )

        face_shape = mp_features.face_shape
        skin_tone = mp_features.skin_tone

        logger.info(f"âœ… MediaPipe ë¶„ì„: {face_shape} + {skin_tone}")

        # 2. í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ
        if not hybrid_service:
            raise HTTPException(
                status_code=500,
                detail="í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )

        recommendation_result = hybrid_service.recommend(
            image_data, face_shape, skin_tone
        )

        # 3. ë„¤ì´ë²„ ê²€ìƒ‰ URL ì¶”ê°€
        import urllib.parse
        for rec in recommendation_result.get("recommendations", []):
            style_name = rec.get("style_name", "")
            encoded_query = urllib.parse.quote(f"{style_name} í—¤ì–´ìŠ¤íƒ€ì¼")
            rec["image_search_url"] = f"https://search.naver.com/search.naver?where=image&query={encoded_query}"

        # 4. DBì— ë¶„ì„ ê²°ê³¼ ì €ì¥
        total_time = round(time.time() - start_time, 2)
        analysis_id = None

        if SessionLocal:
            try:
                db = SessionLocal()

                # AnalysisHistory ë ˆì½”ë“œ ìƒì„±
                new_record = AnalysisHistory(
                    user_id="anonymous",
                    image_hash=image_hash,
                    face_shape=face_shape,
                    personal_color=skin_tone,
                    recommendations=recommendation_result,
                    processing_time=total_time,
                    detection_method="hybrid",
                    recommended_styles=recommendation_result.get("recommendations", [])
                )

                db.add(new_record)
                db.commit()
                db.refresh(new_record)

                analysis_id = new_record.id

                logger.info(f"âœ… ë¶„ì„ ê²°ê³¼ DB ì €ì¥ ì™„ë£Œ: analysis_id={analysis_id}")

                db.close()
            except Exception as e:
                logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {str(e)}")
                # DB ì €ì¥ ì‹¤íŒ¨í•´ë„ ë¶„ì„ ê²°ê³¼ëŠ” ë°˜í™˜

        logger.info(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì™„ë£Œ ({total_time}ì´ˆ)")

        return {
            "success": True,
            "analysis_id": analysis_id,
            "data": recommendation_result,
            "processing_time": total_time,
            "method": "hybrid",
            "mediapipe_features": {
                "face_shape": face_shape,
                "skin_tone": skin_tone,
                "confidence": mp_features.confidence
            },
            "model_used": "gemini-1.5-flash-latest + hairstyle_recommender.pt"
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@app.post("/api/v2/feedback")
async def collect_feedback(
    face_shape: str,
    skin_tone: str,
    hairstyle_id: int,
    user_reaction: str,
    ml_prediction: float,
    user_id: str = "anonymous"
):
    """
    ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ ì—”ë“œí¬ì¸íŠ¸ (v2)

    Args:
        face_shape: ì–¼êµ´í˜• ("ê³„ë€í˜•", "ë‘¥ê·¼í˜•", "ê¸´í˜•", "ê°ì§„í˜•")
        skin_tone: í”¼ë¶€í†¤ ("ê°€ì„ì›œ", "ê²¨ìš¸ì¿¨", "ë´„ì›œ", "ì—¬ë¦„ì¿¨")
        hairstyle_id: í—¤ì–´ìŠ¤íƒ€ì¼ ID (0-based index)
        user_reaction: "ğŸ‘" (ì¢‹ì•„ìš”) or "ğŸ‘" (ì‹«ì–´ìš”)
        ml_prediction: ML ëª¨ë¸ ì˜ˆì¸¡ ì ìˆ˜
        user_id: ì‚¬ìš©ì ID (ê¸°ë³¸ê°’: "anonymous")

    Returns:
        {"total_feedbacks": int, "retrain_triggered": bool, "retrain_job_id": str}

    Ground Truth Rules:
        ğŸ‘ -> 90.0 (user LIKED this combination)
        ğŸ‘ -> 10.0 (user DISLIKED this combination)
    """
    if not feedback_collector:
        raise HTTPException(
            status_code=500,
            detail="í”¼ë“œë°± ìˆ˜ì§‘ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        )

    try:
        # ì…ë ¥ ê²€ì¦
        if user_reaction not in ["ğŸ‘", "ğŸ‘"]:
            raise HTTPException(
                status_code=400,
                detail="user_reactionì€ 'ğŸ‘' ë˜ëŠ” 'ğŸ‘'ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            )

        # í”¼ë“œë°± ì €ì¥
        result = feedback_collector.save_feedback(
            face_shape=face_shape,
            skin_tone=skin_tone,
            hairstyle_id=hairstyle_id,
            user_reaction=user_reaction,
            ml_prediction=ml_prediction,
            user_id=user_id
        )

        retrain_job_id = None

        # ì¬í•™ìŠµ íŠ¸ë¦¬ê±° í™•ì¸
        if result['retrain_triggered'] and retrain_queue:
            # ì¬í•™ìŠµ ì‘ì—…ì„ íì— ì¶”ê°€
            job = retrain_queue.add_job(result['total_feedbacks'])
            retrain_job_id = job['job_id']

            logger.info(
                f"ğŸ”„ ì¬í•™ìŠµ ì‘ì—… ìƒì„±: {retrain_job_id} "
                f"(í”¼ë“œë°± {result['total_feedbacks']}ê°œ)"
            )

            log_structured("retrain_job_created", {
                "job_id": retrain_job_id,
                "feedback_count": result['total_feedbacks']
            })

        logger.info(
            f"âœ… í”¼ë“œë°± ìˆ˜ì§‘ ì™„ë£Œ: {face_shape} + {skin_tone} + ID#{hairstyle_id} "
            f"-> {user_reaction} | Total: {result['total_feedbacks']}"
        )

        log_structured("feedback_collected", {
            "face_shape": face_shape,
            "skin_tone": skin_tone,
            "hairstyle_id": hairstyle_id,
            "user_reaction": user_reaction,
            "ml_prediction": ml_prediction,
            "total_feedbacks": result['total_feedbacks'],
            "retrain_triggered": result['retrain_triggered'],
            "retrain_job_id": retrain_job_id
        })

        return {
            "success": True,
            "total_feedbacks": result['total_feedbacks'],
            "retrain_triggered": result['retrain_triggered'],
            "retrain_job_id": retrain_job_id,
            "message": "í”¼ë“œë°±ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ í”¼ë“œë°± ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"í”¼ë“œë°± ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)