import os
import time
import json
import logging
from typing import Optional
from datetime import datetime
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from enum import Enum
import google.generativeai as genai
from PIL import Image
import io
import cv2
import numpy as np
import hashlib
import redis
import urllib.parse
import torch
import torch.nn as nn
import pickle

# ========== SQLAlchemy ì¶”ê°€ ==========
from sqlalchemy import Column, Integer, String, Float, DateTime, JSON, Boolean, create_engine, Enum as SQLEnum
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

# ========== OpenCV ì–¼êµ´ ë¶„ì„ ëª¨ë“ˆ ì„í¬íŠ¸ ==========
from models.face_analyzer import extract_face_features, create_enhanced_prompt, FaceFeatures

Base = declarative_base()

# ========== ë¡œê¹… ì„¤ì • ==========
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ========== ML ëª¨ë¸ ì •ì˜ ==========
class HairstyleRecommender(nn.Module):
    """í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ ML ëª¨ë¸"""

    def __init__(self, n_faces=5, n_skins=3, n_styles=6,
                 emb_dim=16, hidden_dim=64):
        super().__init__()

        self.face_emb = nn.Embedding(n_faces, emb_dim)
        self.skin_emb = nn.Embedding(n_skins, emb_dim)
        self.style_emb = nn.Embedding(n_styles, emb_dim)

        self.shared_layers = nn.Sequential(
            nn.Linear(emb_dim * 3, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3)
        )

        self.score_head = nn.Sequential(
            nn.Linear(hidden_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )

        self.feedback_head = nn.Sequential(
            nn.Linear(hidden_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 2)
        )

    def forward(self, face, skin, style):
        face_emb = self.face_emb(face)
        skin_emb = self.skin_emb(skin)
        style_emb = self.style_emb(style)

        x = torch.cat([face_emb, skin_emb, style_emb], dim=1)
        shared = self.shared_layers(x)

        score_pred = self.score_head(shared).squeeze(-1)
        feedback_logits = self.feedback_head(shared)

        return score_pred, feedback_logits


# ========== ì „ì—­ ë³€ìˆ˜ (ëª¨ë¸ & ì¸ì½”ë”) ==========
ml_model = None
face_encoder = None
skin_encoder = None
style_encoder = None


# ========== CloudWatch Logs êµ¬ì¡°í™” ë¡œê¹… ==========
def log_structured(event_type: str, data: dict):
    """CloudWatch Logs Insightsë¡œ ë¶„ì„ ê°€ëŠ¥í•œ JSON ë¡œê·¸ ìƒì„±"""
    log_entry = {
        "timestamp": datetime.utcnow().isoformat() + "Z",
        "event_type": event_type,
        **data
    }
    logger.info(json.dumps(log_entry, ensure_ascii=False))


def calculate_image_hash(image_data: bytes) -> str:
    """ì´ë¯¸ì§€ì˜ SHA256 í•´ì‹œ ìƒì„± (ìºì‹± í‚¤ë¡œ ì‚¬ìš©)"""
    return hashlib.sha256(image_data).hexdigest()


# ========== ëª¨ë¸ ë¡œë” ==========
def load_ml_model():
    """ML ëª¨ë¸ ë° ì¸ì½”ë” ë¡œë“œ"""
    global ml_model, face_encoder, skin_encoder, style_encoder

    try:
        model_path = 'models/final_model.pth'
        encoder_path = 'models/encoders.pkl'

        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(model_path):
            logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
            return False

        if not os.path.exists(encoder_path):
            logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ ì—†ìŒ: {encoder_path}")
            return False

        # ëª¨ë¸ ë¡œë“œ
        ml_model = HairstyleRecommender()
        ml_model.load_state_dict(torch.load(
            model_path,
            map_location=torch.device('cpu')
        ))
        ml_model.eval()

        # ì¸ì½”ë” ë¡œë“œ
        with open(encoder_path, 'rb') as f:
            encoders = pickle.load(f)
            face_encoder = encoders['face']
            skin_encoder = encoders['skin']
            style_encoder = encoders['style']

        logger.info("âœ… ML ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        logger.info(f"  - ì–¼êµ´í˜•: {len(face_encoder.classes_)}ê°œ")
        logger.info(f"  - í”¼ë¶€í†¤: {len(skin_encoder.classes_)}ê°œ")
        logger.info(f"  - ìŠ¤íƒ€ì¼: {len(style_encoder.classes_)}ê°œ")

        return True

    except Exception as e:
        logger.error(f"âŒ ML ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        ml_model = None
        return False


# ========== ì˜ˆì¸¡ í•¨ìˆ˜ ==========
def predict_ml_score(face_shape: str, skin_tone: str, hairstyle: str) -> float:
    """
    ML ëª¨ë¸ë¡œ ì ìˆ˜ ì˜ˆì¸¡

    Args:
        face_shape: ì–¼êµ´í˜• (ì˜ˆ: "ê³„ë€í˜•")
        skin_tone: í”¼ë¶€í†¤ (ì˜ˆ: "ë´„ì›œ")
        hairstyle: í—¤ì–´ìŠ¤íƒ€ì¼ (ì˜ˆ: "ì‹œìŠ¤ë£¨ë±… ë‹¨ë°œ")

    Returns:
        ì˜ˆì¸¡ ì ìˆ˜ (0.0 ~ 1.0)
    """
    if ml_model is None:
        return 0.85  # ëª¨ë¸ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’

    try:
        # ========== Gemini ì¶œë ¥ â†’ ML ì…ë ¥ ë§¤í•‘ ==========
        skin_tone_mapping = {
            "ë´„ì›œ": "ì›œí†¤",
            "ê°€ì„ì›œ": "ì›œí†¤",
            "ì—¬ë¦„ì¿¨": "ì¿¨í†¤",
            "ê²¨ìš¸ì¿¨": "ì¿¨í†¤"
        }

        mapped_skin = skin_tone_mapping.get(skin_tone, "ì¤‘ê°„í†¤")

        # ========== ì¸ì½”ë”© ==========
        try:
            face_encoded = face_encoder.transform([face_shape])[0]
        except ValueError:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì–¼êµ´í˜•: {face_shape}, ê¸°ë³¸ê°’ ì‚¬ìš©")
            face_encoded = 1  # ê³„ë€í˜•

        try:
            skin_encoded = skin_encoder.transform([mapped_skin])[0]
        except ValueError:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” í”¼ë¶€í†¤: {mapped_skin}, ê¸°ë³¸ê°’ ì‚¬ìš©")
            skin_encoded = 1  # ì¤‘ê°„í†¤

        try:
            style_encoded = style_encoder.transform([hairstyle])[0]
        except ValueError:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ìŠ¤íƒ€ì¼: {hairstyle}, ê¸°ë³¸ê°’ ì‚¬ìš©")
            style_encoded = 2  # ì‹œìŠ¤ë£¨ë±… ë‹¨ë°œ

        # ========== Tensor ë³€í™˜ ==========
        face_tensor = torch.tensor([face_encoded], dtype=torch.long)
        skin_tensor = torch.tensor([skin_encoded], dtype=torch.long)
        style_tensor = torch.tensor([style_encoded], dtype=torch.long)

        # ========== ì˜ˆì¸¡ ==========
        with torch.no_grad():
            score_pred, _ = ml_model(face_tensor, skin_tensor, style_tensor)
            score = score_pred.item()

        logger.info(f"ML ì˜ˆì¸¡: {face_shape} + {mapped_skin} + {hairstyle} â†’ {score:.3f}")
        return round(score, 3)

    except Exception as e:
        logger.error(f"ML ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
        return 0.85


def get_confidence_level(score: float) -> str:
    """ì ìˆ˜ë¥¼ ì‹ ë¢°ë„ ë ˆë²¨ë¡œ ë³€í™˜"""
    if score >= 0.90:
        return "ë§¤ìš° ë†’ìŒ"
    elif score >= 0.85:
        return "ë†’ìŒ"
    elif score >= 0.75:
        return "ë³´í†µ"
    else:
        return "ë‚®ìŒ"


# ========== í”¼ë“œë°± Enum ==========
class FeedbackType(str, Enum):
    LIKE = "like"
    DISLIKE = "dislike"


# ========== ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ ==========
class AnalysisHistory(Base):
    """ë¶„ì„ ê¸°ë¡ í…Œì´ë¸” - v20.1 (ML í†µí•©)"""
    __tablename__ = "analysis_history"

    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(String(100), default="anonymous")
    image_hash = Column(String(64), index=True)
    face_shape = Column(String(50))
    personal_color = Column(String(50))
    recommendations = Column(JSON)
    processing_time = Column(Float)
    detection_method = Column(String(50))
    created_at = Column(DateTime, default=datetime.utcnow, index=True)

    # OpenCV ì¸¡ì • ë°ì´í„°
    opencv_face_ratio = Column(Float)
    opencv_forehead_ratio = Column(Float)
    opencv_cheekbone_ratio = Column(Float)
    opencv_jaw_ratio = Column(Float)
    opencv_prediction = Column(String(50))
    opencv_confidence = Column(Float)
    opencv_gemini_agreement = Column(Boolean)

    # v20: ì¶”ì²œ ìŠ¤íƒ€ì¼ ì €ì¥
    recommended_styles = Column(JSON)

    # v20: í”¼ë“œë°± ì»¬ëŸ¼
    style_1_feedback = Column(SQLEnum(FeedbackType), nullable=True)
    style_2_feedback = Column(SQLEnum(FeedbackType), nullable=True)
    style_3_feedback = Column(SQLEnum(FeedbackType), nullable=True)

    # v20: ë„¤ì´ë²„ í´ë¦­ ì—¬ë¶€
    style_1_naver_clicked = Column(Boolean, default=False)
    style_2_naver_clicked = Column(Boolean, default=False)
    style_3_naver_clicked = Column(Boolean, default=False)

    # v20: í”¼ë“œë°± ì œì¶œ ì‹œê°
    feedback_at = Column(DateTime, nullable=True)


# ========== Pydantic ëª¨ë¸ ==========
class FeedbackRequest(BaseModel):
    """í”¼ë“œë°± ì œì¶œ ìš”ì²­"""
    analysis_id: int = Field(..., description="ë¶„ì„ ê²°ê³¼ ID")
    style_index: int = Field(..., ge=1, le=3, description="ìŠ¤íƒ€ì¼ ì¸ë±ìŠ¤ (1, 2, 3)")
    feedback: FeedbackType = Field(..., description="ì¢‹ì•„ìš” ë˜ëŠ” ì‹«ì–´ìš”")
    naver_clicked: bool = Field(default=False, description="ë„¤ì´ë²„ ì´ë¯¸ì§€ ê²€ìƒ‰ í´ë¦­ ì—¬ë¶€")


class FeedbackResponse(BaseModel):
    """í”¼ë“œë°± ì œì¶œ ì‘ë‹µ"""
    success: bool
    message: str
    analysis_id: int
    style_index: int


# ========== FastAPI ì•± ì´ˆê¸°í™” ==========
app = FastAPI(
    title="HairMe API",
    description="AI ê¸°ë°˜ í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ ì„œë¹„ìŠ¤ (v20.1: ML í†µí•©)",
    version="20.1.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ========== ì•± ì‹œì‘ ì´ë²¤íŠ¸ ==========
@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ML ëª¨ë¸ ë¡œë“œ"""
    logger.info("ğŸš€ ì„œë²„ ì‹œì‘ ì¤‘...")

    # ML ëª¨ë¸ ë¡œë“œ ì‹œë„
    ml_loaded = load_ml_model()

    if ml_loaded:
        logger.info("âœ… ML ëª¨ë“œ: í™œì„±í™”")
        log_structured("ml_model_loaded", {
            "status": "success",
            "model_path": "models/final_model.pth"
        })
    else:
        logger.warning("âš ï¸ ML ëª¨ë“œ: ë¹„í™œì„±í™” (ê¸°ë³¸ ì ìˆ˜ ì‚¬ìš©)")
        log_structured("ml_model_loaded", {
            "status": "failed",
            "fallback": "default_score"
        })


# ========== ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ==========
SessionLocal = None
DATABASE_URL = os.getenv("DATABASE_URL")
DB_PASSWORD = os.getenv("DB_PASSWORD")

if DATABASE_URL and DB_PASSWORD:
    try:
        sync_db_url = DATABASE_URL.replace("asyncmy", "pymysql").replace("://admin@", f"://admin:{DB_PASSWORD}@")
        engine = create_engine(
            sync_db_url,
            pool_pre_ping=True,
            pool_recycle=3600,
            echo=False
        )
        SessionLocal = sessionmaker(bind=engine)
        Base.metadata.create_all(bind=engine)
        logger.info("âœ… MySQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
        log_structured("database_connected", {
            "database": "hairme-data",
            "tables": ["analysis_history"]
        })
    except Exception as e:
        logger.error(f"âŒ MySQL ì—°ê²° ì‹¤íŒ¨: {str(e)}")
        SessionLocal = None
else:
    logger.warning("âš ï¸ DATABASE_URL ë˜ëŠ” DB_PASSWORDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ========== Redis ìºì‹œ ==========
redis_client = None
REDIS_URL = os.getenv("REDIS_URL")
CACHE_TTL = 86400

if REDIS_URL:
    try:
        redis_client = redis.from_url(REDIS_URL, decode_responses=True)
        redis_client.ping()
        logger.info(f"âœ… Redis ì—°ê²° ì„±ê³µ: {REDIS_URL}")
    except Exception as e:
        logger.error(f"âŒ Redis ì—°ê²° ì‹¤íŒ¨: {str(e)}")
        redis_client = None
else:
    logger.warning("âš ï¸ REDIS_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def get_cached_result(image_hash: str) -> Optional[dict]:
    """Redisì—ì„œ ìºì‹œëœ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
    if not redis_client:
        return None
    try:
        cached = redis_client.get(f"analysis:{image_hash}")
        if cached:
            log_structured("cache_hit", {"image_hash": image_hash[:16]})
            return json.loads(cached)
        return None
    except Exception as e:
        logger.error(f"Redis ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None


def save_to_cache(image_hash: str, result: dict):
    """Redisì— ë¶„ì„ ê²°ê³¼ ì €ì¥"""
    if not redis_client:
        return
    try:
        redis_client.setex(
            f"analysis:{image_hash}",
            CACHE_TTL,
            json.dumps(result, ensure_ascii=False)
        )
    except Exception as e:
        logger.error(f"Redis ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")


# ========== Gemini API ì´ˆê¸°í™” ==========
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    logger.error("GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
else:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        logger.info("âœ… Gemini API ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.error(f"Gemini API ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

MODEL_NAME = "gemini-flash-latest"

# ========== OpenCV ì–¼êµ´ ê°ì§€ê¸° ==========
face_cascade = None
try:
    cascade_paths = [
        cv2.data.haarcascades + 'haarcascade_frontalface_default.xml',
        '/usr/local/lib/python3.11/site-packages/cv2/data/haarcascade_frontalface_default.xml',
        '/usr/share/opencv4/haarcascades/haarcascade_frontalface_default.xml'
    ]

    for path in cascade_paths:
        if os.path.exists(path):
            face_cascade = cv2.CascadeClassifier(path)
            if not face_cascade.empty():
                logger.info(f"âœ… OpenCV ì–¼êµ´ ê°ì§€ê¸° ì´ˆê¸°í™” ì™„ë£Œ: {path}")
                break

    if face_cascade is None or face_cascade.empty():
        logger.error("âŒ OpenCV ì–¼êµ´ ê°ì§€ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨")
        face_cascade = None

except Exception as e:
    logger.error(f"OpenCV ì–¼êµ´ ê°ì§€ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    face_cascade = None

# ========== Gemini ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ==========
ANALYSIS_PROMPT = """ë¶„ì„í•˜ê³  JSONìœ¼ë¡œ ì‘ë‹µ:

ì–¼êµ´í˜•: ê³„ë€í˜•/ë‘¥ê·¼í˜•/ê°ì§„í˜•/ê¸´í˜• ì¤‘ 1ê°œ
í¼ìŠ¤ë„ì»¬ëŸ¬: ë´„ì›œ/ê°€ì„ì›œ/ì—¬ë¦„ì¿¨/ê²¨ìš¸ì¿¨ ì¤‘ 1ê°œ
í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ 3ê°œ (ê° ì´ë¦„ 15ì, ì´ìœ  30ì ì´ë‚´)

JSON í˜•ì‹:
{
  "analysis": {
    "face_shape": "ê³„ë€í˜•",
    "personal_color": "ë´„ì›œ",
    "features": "ì´ëª©êµ¬ë¹„ íŠ¹ì§•"
  },
  "recommendations": [
    {"style_name": "ìŠ¤íƒ€ì¼ëª…", "reason": "ì¶”ì²œ ì´ìœ "}
  ]
}"""


# ========== í—¬í¼ í•¨ìˆ˜ë“¤ ==========
def verify_face_with_gemini(image_data: bytes) -> dict:
    """OpenCV ì‹¤íŒ¨ ì‹œ Geminië¡œ ë¹ ë¥¸ ì–¼êµ´ ê²€ì¦"""
    try:
        image = Image.open(io.BytesIO(image_data))
        image.thumbnail((256, 256))

        model = genai.GenerativeModel(MODEL_NAME)
        prompt = """ì´ë¯¸ì§€ì— ì‚¬ëŒ ì–¼êµ´ì´ ìˆë‚˜ìš”?

JSONìœ¼ë¡œë§Œ ë‹µë³€:
{"has_face": true/false, "face_count": ìˆ«ì}"""

        response = model.generate_content([prompt, image])
        result = json.loads(response.text.strip())

        return {
            "has_face": result.get("has_face", False),
            "face_count": result.get("face_count", 0),
            "method": "gemini"
        }

    except Exception as e:
        logger.error(f"Gemini ì–¼êµ´ ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
        return {
            "has_face": False,
            "face_count": 0,
            "method": "gemini",
            "error": str(e)
        }


def detect_face(image_data: bytes) -> dict:
    """ì–¼êµ´ ê°ì§€ (OpenCV ìš°ì„ , ì‹¤íŒ¨ ì‹œ Gemini)"""
    if face_cascade is not None and not face_cascade.empty():
        try:
            nparr = np.frombuffer(image_data, np.uint8)
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

            if img is not None:
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                faces = face_cascade.detectMultiScale(
                    gray,
                    scaleFactor=1.1,
                    minNeighbors=5,
                    minSize=(100, 100)
                )

                if len(faces) > 0:
                    log_structured("face_detection", {
                        "method": "opencv",
                        "face_count": len(faces),
                        "success": True
                    })
                    return {
                        "has_face": True,
                        "face_count": len(faces),
                        "method": "opencv"
                    }

        except Exception as e:
            logger.warning(f"OpenCV ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨: {str(e)}")

    logger.info("OpenCV ì‹¤íŒ¨, Geminië¡œ ì–¼êµ´ ê²€ì¦ ì‹œì‘...")
    gemini_result = verify_face_with_gemini(image_data)

    log_structured("face_detection", {
        "method": "gemini",
        "face_count": gemini_result.get("face_count", 0),
        "success": gemini_result.get("has_face", False)
    })

    return gemini_result


def analyze_with_gemini(image_data: bytes) -> dict:
    """Gemini Vision APIë¡œ ì–¼êµ´ ë¶„ì„"""
    try:
        image = Image.open(io.BytesIO(image_data))

        opencv_features = extract_face_features(image_data)

        if opencv_features:
            prompt = create_enhanced_prompt(opencv_features)
            logger.info(f"âœ… OpenCV íŒíŠ¸ ì ìš©: {opencv_features.face_shape_hint}")
        else:
            prompt = ANALYSIS_PROMPT
            logger.warning("âš ï¸ OpenCV íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨, ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")

        model = genai.GenerativeModel(MODEL_NAME)
        response = model.generate_content([prompt, image])

        raw_text = response.text.strip()

        if raw_text.startswith("```json"):
            raw_text = raw_text[7:]
        if raw_text.startswith("```"):
            raw_text = raw_text[3:]
        if raw_text.endswith("```"):
            raw_text = raw_text[:-3]

        result = json.loads(raw_text.strip())

        logger.info(f"âœ… Gemini ë¶„ì„ ì„±ê³µ: {result.get('analysis', {}).get('face_shape')}")
        return result

    except json.JSONDecodeError as e:
        logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}\nì‘ë‹µ ë‚´ìš©: {response.text[:200]}")
        raise HTTPException(
            status_code=500,
            detail=f"AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {str(e)}"
        )
    except Exception as e:
        logger.error(f"Gemini ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


def save_to_database(
        image_hash: str,
        analysis_result: dict,
        processing_time: float,
        detection_method: str,
        opencv_features: Optional[FaceFeatures] = None
) -> Optional[int]:  # âœ… ë°˜í™˜ íƒ€ì… ì¶”ê°€
    """ë¶„ì„ ê²°ê³¼ë¥¼ MySQLì— ì €ì¥í•˜ê³  ID ë°˜í™˜"""
    if not SessionLocal:
        logger.warning("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ì—†ì–´ ì €ì¥ì„ ìƒëµí•©ë‹ˆë‹¤.")
        return None  # âœ… None ë°˜í™˜

    try:
        db = SessionLocal()

        gemini_shape = analysis_result.get("analysis", {}).get("face_shape")

        opencv_agreement = None
        if opencv_features:
            opencv_agreement = (
                    opencv_features.face_shape_hint in gemini_shape or
                    gemini_shape in opencv_features.face_shape_hint
            )

        recommendations = analysis_result.get("recommendations", [])

        history = AnalysisHistory(
            image_hash=image_hash,
            face_shape=gemini_shape,
            personal_color=analysis_result.get("analysis", {}).get("personal_color"),
            recommendations=recommendations,
            recommended_styles=recommendations,
            processing_time=processing_time,
            detection_method=detection_method,
            opencv_face_ratio=opencv_features.face_ratio if opencv_features else None,
            opencv_forehead_ratio=opencv_features.forehead_ratio if opencv_features else None,
            opencv_cheekbone_ratio=opencv_features.cheekbone_ratio if opencv_features else None,
            opencv_jaw_ratio=opencv_features.jaw_ratio if opencv_features else None,
            opencv_prediction=opencv_features.face_shape_hint if opencv_features else None,
            opencv_confidence=opencv_features.confidence if opencv_features else None,
            opencv_gemini_agreement=opencv_agreement
        )

        db.add(history)
        db.commit()
        db.refresh(history)

        logger.info(f"âœ… DB ì €ì¥ ì„±ê³µ (ID: {history.id})")
        log_structured("database_saved", {
            "record_id": history.id,
            "opencv_enabled": opencv_features is not None,
            "agreement": opencv_agreement,
            "recommendations_count": len(recommendations)
        })

        db.close()
        return history.id  # âœ… ID ë°˜í™˜ ì¶”ê°€!

    except Exception as e:
        logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return None  # âœ… ì—ëŸ¬ ì‹œ None ë°˜í™˜

# ========== API ì—”ë“œí¬ì¸íŠ¸ ==========
@app.get("/")
async def root():
    """Root ì—”ë“œí¬ì¸íŠ¸"""
    face_detection_status = "enabled" if (face_cascade is not None and not face_cascade.empty()) else "disabled"
    return {
        "message": "í—¤ì–´ìŠ¤íƒ€ì¼ ë¶„ì„ API - v20.1 (ML í†µí•©)",
        "version": "20.1.0",
        "model": MODEL_NAME,
        "status": "running",
        "features": {
            "face_detection": face_detection_status,
            "opencv_analysis": "enabled",
            "gemini_analysis": "enabled" if GEMINI_API_KEY else "disabled",
            "redis_cache": "enabled" if redis_client else "disabled",
            "database": "enabled" if SessionLocal else "disabled",
            "feedback_system": "enabled",
            "ml_prediction": "enabled" if ml_model else "disabled"
        }
    }


@app.get("/api/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    face_detection_status = "enabled" if (face_cascade is not None and not face_cascade.empty()) else "disabled"

    return {
        "status": "healthy",
        "version": "20.1.0",
        "model": MODEL_NAME,
        "face_detection": face_detection_status,
        "opencv_analysis": "enabled",
        "gemini_api": "configured" if GEMINI_API_KEY else "not_configured",
        "redis": "connected" if redis_client else "disconnected",
        "database": "connected" if SessionLocal else "disconnected",
        "feedback_system": "enabled",
        "ml_model": "enabled" if ml_model else "disabled"
    }


@app.post("/api/analyze")
async def analyze_face(file: UploadFile = File(...)):
    """ì–¼êµ´ ë¶„ì„ ë° í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ (v20.1: ML í†µí•©)"""
    start_time = time.time()
    image_hash = None

    try:
        if not GEMINI_API_KEY:
            raise HTTPException(
                status_code=500,
                detail="Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )

        if not file.filename:
            raise HTTPException(status_code=400, detail="íŒŒì¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤")

        file_ext = file.filename.lower().split('.')[-1]
        if file_ext not in ['jpg', 'jpeg', 'png', 'webp']:
            raise HTTPException(
                status_code=400,
                detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. (jpg, jpeg, png, webpë§Œ ê°€ëŠ¥)"
            )

        logger.info(f"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹œì‘: {file.filename}")

        image_data = await file.read()
        image_hash = calculate_image_hash(image_data)

        log_structured("analysis_start", {
            "filename": file.filename,
            "file_size_kb": round(len(image_data) / 1024, 2),
            "image_hash": image_hash[:16]
        })

        # ìºì‹œ í™•ì¸
        cached_result = get_cached_result(image_hash)
        if cached_result:
            total_time = round(time.time() - start_time, 2)
            return {
                "success": True,
                "data": cached_result,
                "processing_time": total_time,
                "cached": True,
                "model_used": MODEL_NAME
            }

        # ì–¼êµ´ ê°ì§€
        face_detection_start = time.time()
        face_result = detect_face(image_data)
        face_detection_time = round((time.time() - face_detection_start) * 1000, 2)

        if not face_result["has_face"]:
            log_structured("analysis_error", {
                "error_type": "no_face_detected",
                "image_hash": image_hash[:16]
            })
            return JSONResponse(
                status_code=400,
                content={
                    "success": False,
                    "error": "no_face_detected",
                    "message": "ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\në°ì€ ê³³ì—ì„œ ì •ë©´ ì‚¬ì§„ì„ ì´¬ì˜í•´ì£¼ì„¸ìš”."
                }
            )

        if face_result["face_count"] > 1:
            return JSONResponse(
                status_code=400,
                content={
                    "success": False,
                    "error": "multiple_faces",
                    "message": f"{face_result['face_count']}ëª…ì˜ ì–¼êµ´ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\ní•œ ëª…ë§Œ ë‚˜ì˜¨ ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
                }
            )

        # Gemini ë¶„ì„
        gemini_start = time.time()
        analysis_result = analyze_with_gemini(image_data)
        gemini_time = round((time.time() - gemini_start) * 1000, 2)

        opencv_features = extract_face_features(image_data)

        # âœ… ML ì ìˆ˜ ì¶”ê°€
        face_shape = analysis_result.get("analysis", {}).get("face_shape")
        skin_tone = analysis_result.get("analysis", {}).get("personal_color")

        for idx, recommendation in enumerate(analysis_result.get("recommendations", []), 1):
            style_name = recommendation.get("style_name", "")

            # ML ì˜ˆì¸¡ ì ìˆ˜ ê³„ì‚°
            ml_score = predict_ml_score(face_shape, skin_tone, style_name)

            # ê²°ê³¼ì— ì¶”ê°€
            recommendation['ml_confidence'] = ml_score
            recommendation['confidence_level'] = get_confidence_level(ml_score)

            # ë„¤ì´ë²„ ê²€ìƒ‰ URL
            encoded_query = urllib.parse.quote(f"{style_name} í—¤ì–´ìŠ¤íƒ€ì¼")
            recommendation[
                "image_search_url"] = f"https://search.naver.com/search.naver?where=image&query={encoded_query}"

        # ìºì‹±
        save_to_cache(image_hash, analysis_result)

        # DB ì €ì¥
        total_time = round(time.time() - start_time, 2)
        analysis_id = save_to_database(  # âœ… ì´ ë¶€ë¶„ ì¶”ê°€!
            image_hash=image_hash,
            analysis_result=analysis_result,
            processing_time=total_time,
            detection_method=face_result.get("method", "opencv"),
            opencv_features=opencv_features
        )

        log_structured("analysis_complete", {
            "image_hash": image_hash[:16],
            "processing_time": total_time,
            "face_detection_time_ms": face_detection_time,
            "gemini_analysis_time_ms": gemini_time,
            "opencv_enabled": opencv_features is not None,
            "ml_enabled": ml_model is not None,
            "face_shape": face_shape,
            "personal_color": skin_tone,
            "analysis_id": analysis_id
        })

        return {
            "success": True,
            "data": analysis_result,
            "analysis_id": analysis_id,
            "processing_time": total_time,
            "performance": {
                "face_detection_ms": face_detection_time,
                "gemini_analysis_ms": gemini_time,
                "detection_method": face_result.get("method", "opencv"),
                "opencv_analysis": "enabled" if opencv_features else "failed",
                "ml_prediction": "enabled" if ml_model else "disabled"
            },
            "cached": False,
            "model_used": MODEL_NAME
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

        log_structured("analysis_error", {
            "error_type": "internal_error",
            "error_message": str(e),
            "image_hash": image_hash[:16] if image_hash else "unknown"
        })

        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": "internal_error",
                "message": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }
        )


@app.post("/api/feedback", response_model=FeedbackResponse)
async def submit_feedback(request: FeedbackRequest):
    """ì‚¬ìš©ì í”¼ë“œë°± ì œì¶œ ì—”ë“œí¬ì¸íŠ¸"""
    if not SessionLocal:
        raise HTTPException(
            status_code=500,
            detail="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤"
        )

    try:
        db = SessionLocal()

        record = db.query(AnalysisHistory).filter(
            AnalysisHistory.id == request.analysis_id
        ).first()

        if not record:
            db.close()
            raise HTTPException(
                status_code=404,
                detail=f"ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ID: {request.analysis_id})"
            )

        feedback_column = f"style_{request.style_index}_feedback"
        clicked_column = f"style_{request.style_index}_naver_clicked"

        setattr(record, feedback_column, request.feedback)
        setattr(record, clicked_column, request.naver_clicked)
        record.feedback_at = datetime.utcnow()

        db.commit()

        logger.info(
            f"âœ… í”¼ë“œë°± ì €ì¥ ì„±ê³µ: analysis_id={request.analysis_id}, style={request.style_index}, feedback={request.feedback}")

        log_structured("feedback_submitted", {
            "analysis_id": request.analysis_id,
            "style_index": request.style_index,
            "feedback": request.feedback,
            "naver_clicked": request.naver_clicked
        })

        db.close()

        return FeedbackResponse(
            success=True,
            message="í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤",
            analysis_id=request.analysis_id,
            style_index=request.style_index
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ í”¼ë“œë°± ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"í”¼ë“œë°± ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)