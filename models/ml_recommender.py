"""
ML ê¸°ë°˜ ë…ë¦½í˜• í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œê¸°

MediaPipe ë¶„ì„ ê²°ê³¼ (ì–¼êµ´í˜• + í”¼ë¶€í†¤)ë¡œ í•™ìŠµëœ ML ëª¨ë¸ì„ ì‚¬ìš©í•´
ëª¨ë“  í—¤ì–´ìŠ¤íƒ€ì¼ì˜ ì¶”ì²œ ì ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ê³  Top-Kë¥¼ ë°˜í™˜

Author: HairMe ML Team
Date: 2025-11-08
Version: 1.2.0 (Normalized Label Support - v5)

v1.2.0 ë³€ê²½ì‚¬í•­:
- ë¼ë²¨ ì •ê·œí™” ëª¨ë¸(v5) ì§€ì› ì¶”ê°€
- ëª¨ë¸ ì¶œë ¥ ì—­ë³€í™˜ ë¡œì§ (0~1 â†’ 10~95)
- Sigmoid ì¶œë ¥ì¸µ ì§€ì›
"""

import numpy as np
import torch
import torch.nn as nn
from pathlib import Path
from typing import List, Dict, Tuple, TYPE_CHECKING
import logging
import sys
from difflib import SequenceMatcher

# TYPE_CHECKINGì„ ì‚¬ìš©í•˜ì—¬ ëŸ°íƒ€ì„ì—ëŠ” importí•˜ì§€ ì•ŠìŒ
if TYPE_CHECKING:
    from sentence_transformers import SentenceTransformer

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from utils.style_preprocessor import normalize_style_name

logger = logging.getLogger(__name__)

# ========== ë¼ë²¨ ì •ê·œí™” ìƒìˆ˜ (v5 ëª¨ë¸ìš©) ==========
LABEL_MIN = 10.0   # ì›ë³¸ ì ìˆ˜ ìµœì†Œê°’
LABEL_MAX = 95.0   # ì›ë³¸ ì ìˆ˜ ìµœëŒ€ê°’
LABEL_RANGE = LABEL_MAX - LABEL_MIN  # 85


# ========== í•™ìŠµ ë°ì´í„° íŠ¹ì§• í†µê³„ (ì…ë ¥ ìŠ¤ì¼€ì¼ë§ìš©) ==========
# ai_face_1000.npzì—ì„œ ì¶”ì¶œí•œ í†µê³„ (5910 ìƒ˜í”Œ)
FACE_FEATURE_STATS = {
    0: {"min": 0.99, "max": 1.51, "mean": 1.20, "std": 0.06},   # face_ratio
    1: {"min": 301.10, "max": 495.30, "mean": 458.13, "std": 14.31},  # forehead_width (pixel)
    2: {"min": 421.40, "max": 641.00, "mean": 561.34, "std": 19.73},  # cheekbone_width (pixel)
    3: {"min": 333.90, "max": 524.10, "mean": 447.70, "std": 19.82},  # jaw_width (pixel)
    4: {"min": 0.71, "max": 0.89, "mean": 0.82, "std": 0.02},   # forehead_ratio
    5: {"min": 0.73, "max": 0.86, "mean": 0.80, "std": 0.02},   # jaw_ratio
}

SKIN_FEATURE_STATS = {
    0: {"min": 50.53, "max": 89.26, "mean": 79.91, "std": 3.90},  # ITA_value
    1: {"min": 5.96, "max": 142.39, "mean": 12.09, "std": 10.97},  # hue_value
}


def denormalize_score(normalized: float) -> float:
    """0~1 ì ìˆ˜ë¥¼ ì›ë³¸ ìŠ¤ì¼€ì¼ë¡œ ì—­ë³€í™˜ (10~95)"""
    return normalized * LABEL_RANGE + LABEL_MIN


def scale_input_features(
    face_features: np.ndarray,
    skin_features: np.ndarray
) -> tuple:
    """
    ì¶”ë¡  ì…ë ¥ì„ í•™ìŠµ ë°ì´í„° ë¶„í¬ì— ë§ê²Œ ìŠ¤ì¼€ì¼ë§

    ë¬¸ì œ:
    - í•™ìŠµ ë°ì´í„°: ì–¼êµ´ ë„ˆë¹„ 300-600 í”½ì…€ (ê³ í•´ìƒë„ ì´ë¯¸ì§€)
    - ì‹¤ì œ ì¶”ë¡ : ì–¼êµ´ ë„ˆë¹„ 70-150 í”½ì…€ (ë‹¤ì–‘í•œ í•´ìƒë„)
    - ì´ ìŠ¤ì¼€ì¼ ë¶ˆì¼ì¹˜ë¡œ ì¸í•´ OOD(Out-of-Distribution) ì˜ˆì¸¡ ë°œìƒ

    í•´ê²°ì±…:
    - í”½ì…€ ê¸°ë°˜ íŠ¹ì§•(forehead, cheekbone, jaw width)ì„ í•™ìŠµ ë°ì´í„° í‰ê·  ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
    - ë¹„ìœ¨ ê¸°ë°˜ íŠ¹ì§•(face_ratio, forehead_ratio, jaw_ratio)ì€ ìŠ¤ì¼€ì¼ ë¶ˆë³€ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ìœ ì§€

    Args:
        face_features: [face_ratio, forehead_width, cheekbone_width, jaw_width, forehead_ratio, jaw_ratio]
        skin_features: [ITA_value, hue_value]

    Returns:
        (scaled_face_features, scaled_skin_features)
    """
    face_scaled = face_features.copy()
    skin_scaled = skin_features.copy()

    # ì–¼êµ´ íŠ¹ì§• ìŠ¤ì¼€ì¼ë§
    # - ì¸ë±ìŠ¤ 0, 4, 5: ë¹„ìœ¨ íŠ¹ì§• (ìŠ¤ì¼€ì¼ ë¶ˆë³€) - ìŠ¤ì¼€ì¼ë§ í•„ìš” ì—†ìŒ
    # - ì¸ë±ìŠ¤ 1, 2, 3: í”½ì…€ ë„ˆë¹„ íŠ¹ì§• (ìŠ¤ì¼€ì¼ ì˜ì¡´) - ìŠ¤ì¼€ì¼ë§ í•„ìš”

    # ì…ë ¥ ì´ë¯¸ì§€ì˜ ìŠ¤ì¼€ì¼ ì¶”ì • (cheekbone_width ê¸°ì¤€)
    input_cheekbone = face_features[2]
    train_cheekbone_mean = FACE_FEATURE_STATS[2]["mean"]  # 561.34

    # ìŠ¤ì¼€ì¼ íŒ©í„° ê³„ì‚° (ì…ë ¥ì„ í•™ìŠµ ë°ì´í„° ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜)
    if input_cheekbone > 0:
        scale_factor = train_cheekbone_mean / input_cheekbone
    else:
        scale_factor = 1.0

    # í”½ì…€ ê¸°ë°˜ íŠ¹ì§•ë§Œ ìŠ¤ì¼€ì¼ë§ (ì¸ë±ìŠ¤ 1, 2, 3)
    face_scaled[1] = face_features[1] * scale_factor  # forehead_width
    face_scaled[2] = face_features[2] * scale_factor  # cheekbone_width
    face_scaled[3] = face_features[3] * scale_factor  # jaw_width

    # ìŠ¤ì¼€ì¼ë§ëœ ê°’ì´ í•™ìŠµ ë°ì´í„° ë²”ìœ„ ë‚´ì— ìˆë„ë¡ í´ë¦¬í•‘
    for idx in [1, 2, 3]:
        min_val = FACE_FEATURE_STATS[idx]["min"]
        max_val = FACE_FEATURE_STATS[idx]["max"]
        face_scaled[idx] = np.clip(face_scaled[idx], min_val, max_val)

    # ë¹„ìœ¨ íŠ¹ì§•ë„ í•™ìŠµ ë°ì´í„° ë²”ìœ„ ë‚´ì— ìˆë„ë¡ í´ë¦¬í•‘
    for idx in [0, 4, 5]:
        min_val = FACE_FEATURE_STATS[idx]["min"]
        max_val = FACE_FEATURE_STATS[idx]["max"]
        face_scaled[idx] = np.clip(face_scaled[idx], min_val, max_val)

    # í”¼ë¶€ íŠ¹ì§• í´ë¦¬í•‘ (ì´ë¯¸ ìŠ¤ì¼€ì¼ ë¶ˆë³€)
    for idx in [0, 1]:
        min_val = SKIN_FEATURE_STATS[idx]["min"]
        max_val = SKIN_FEATURE_STATS[idx]["max"]
        skin_scaled[idx] = np.clip(skin_scaled[idx], min_val, max_val)

    return face_scaled, skin_scaled


class AttentionLayer(nn.Module):
    """
    Multi-head self-attention layer for multi-token inputs

    Note: ì´ ë ˆì´ì–´ëŠ” ì—¬ëŸ¬ í† í° ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ í•™ìŠµí•©ë‹ˆë‹¤.
    ë‹¨ì¼ í† í°ì— ì ìš©í•˜ë©´ identity ì—°ì‚°ì´ ë˜ë¯€ë¡œ, ìµœì†Œ 2ê°œ ì´ìƒì˜ í† í°ì´ í•„ìš”í•©ë‹ˆë‹¤.
    """

    def __init__(self, embed_dim: int, num_heads: int = 8, dropout: float = 0.1):
        super().__init__()
        self.attention = nn.MultiheadAttention(
            embed_dim=embed_dim,
            num_heads=num_heads,
            dropout=dropout,
            batch_first=True
        )
        self.norm = nn.LayerNorm(embed_dim)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Self-attention across multiple tokens
        attn_out, _ = self.attention(x, x, x)
        # Residual connection + layer norm
        x = self.norm(x + self.dropout(attn_out))
        return x


class MultiTokenAttentionLayer(nn.Module):
    """
    3-Token Cross-Attention Layer

    face_proj, skin_proj, style_embë¥¼ 3ê°œì˜ ê°œë³„ í† í°ìœ¼ë¡œ êµ¬ì„±í•˜ì—¬
    í† í° ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ í•™ìŠµí•©ë‹ˆë‹¤.

    êµ¬ì¡°:
    - Token 1: face_proj (projected to token_dim)
    - Token 2: skin_proj (projected to token_dim)
    - Token 3: style_emb (projected to token_dim)
    - Self-attentionìœ¼ë¡œ 3ê°œ í† í° ê°„ ê´€ê³„ í•™ìŠµ
    - 3ê°œ í† í°ì„ concatí•˜ì—¬ ì¶œë ¥
    """

    def __init__(
        self,
        face_dim: int = 64,
        skin_dim: int = 32,
        style_dim: int = 384,
        token_dim: int = 128,  # í†µì¼ëœ í† í° ì°¨ì›
        num_heads: int = 4,
        dropout: float = 0.1
    ):
        super().__init__()
        self.token_dim = token_dim

        # ê° ì…ë ¥ì„ ë™ì¼í•œ token_dimìœ¼ë¡œ projection
        self.face_to_token = nn.Linear(face_dim, token_dim)
        self.skin_to_token = nn.Linear(skin_dim, token_dim)
        self.style_to_token = nn.Linear(style_dim, token_dim)

        # Multi-head self-attention (3 tokens)
        self.attention = nn.MultiheadAttention(
            embed_dim=token_dim,
            num_heads=num_heads,
            dropout=dropout,
            batch_first=True
        )
        self.norm1 = nn.LayerNorm(token_dim)

        # Feed-forward network
        self.ffn = nn.Sequential(
            nn.Linear(token_dim, token_dim * 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(token_dim * 2, token_dim)
        )
        self.norm2 = nn.LayerNorm(token_dim)
        self.dropout = nn.Dropout(dropout)

    def forward(
        self,
        face_proj: torch.Tensor,  # (batch, 64)
        skin_proj: torch.Tensor,  # (batch, 32)
        style_emb: torch.Tensor   # (batch, 384)
    ) -> torch.Tensor:
        """
        Returns:
            (batch, token_dim * 3) - 3ê°œ í† í°ì˜ concat ê²°ê³¼
        """
        batch_size = face_proj.size(0)

        # ê° íŠ¹ì§•ì„ token_dimìœ¼ë¡œ projection
        face_token = self.face_to_token(face_proj)   # (batch, token_dim)
        skin_token = self.skin_to_token(skin_proj)   # (batch, token_dim)
        style_token = self.style_to_token(style_emb) # (batch, token_dim)

        # 3ê°œ í† í°ìœ¼ë¡œ ì‹œí€€ìŠ¤ êµ¬ì„±: (batch, 3, token_dim)
        tokens = torch.stack([face_token, skin_token, style_token], dim=1)

        # Self-attention across 3 tokens
        attn_out, _ = self.attention(tokens, tokens, tokens)
        tokens = self.norm1(tokens + self.dropout(attn_out))

        # Feed-forward network
        ffn_out = self.ffn(tokens)
        tokens = self.norm2(tokens + self.dropout(ffn_out))

        # 3ê°œ í† í°ì„ flattení•˜ì—¬ ë°˜í™˜: (batch, token_dim * 3)
        output = tokens.reshape(batch_size, -1)

        return output


class RecommendationModel(nn.Module):
    """
    ì—°ì†í˜• ë³€ìˆ˜ ê¸°ë°˜ ì¶”ì²œ ëª¨ë¸ v4

    ì…ë ¥:
    - face_features: [batch, 6] - MediaPipe ì–¼êµ´ ì¸¡ì •ê°’
    - skin_features: [batch, 2] - MediaPipe í”¼ë¶€ ì¸¡ì •ê°’
    - style_emb: [batch, 384] - í—¤ì–´ìŠ¤íƒ€ì¼ ì„ë² ë”©

    Note:
    - use_attention=TrueëŠ” ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
    - ë‹¨ì¼ í† í° attentionì€ ì‹¤ì§ˆì ìœ¼ë¡œ LayerNorm+Dropoutê³¼ ë™ì¼ (identityì— ê°€ê¹Œì›€)
    - ìƒˆë¡œìš´ í•™ìŠµ ì‹œì—ëŠ” RecommendationModelV6 ì‚¬ìš© ê¶Œì¥
    """

    def __init__(
        self,
        face_feat_dim: int = 6,
        skin_feat_dim: int = 2,
        style_embed_dim: int = 384,
        use_attention: bool = True,  # ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ í˜¸í™˜ì„± ìœ ì§€
        dropout_rate: float = 0.3
    ):
        super().__init__()

        self.face_feat_dim = face_feat_dim
        self.skin_feat_dim = skin_feat_dim
        self.style_embed_dim = style_embed_dim

        # Input projection layers
        self.face_projection = nn.Sequential(
            nn.Linear(face_feat_dim, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(dropout_rate * 0.5)
        )

        self.skin_projection = nn.Sequential(
            nn.Linear(skin_feat_dim, 32),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.Dropout(dropout_rate * 0.5)
        )

        # Total dimension after projection
        self.total_dim = 64 + 32 + style_embed_dim  # 96 + 384 = 480

        # Attention layer (ë‹¨ì¼ í† í° - ì‹¤ì§ˆì ìœ¼ë¡œ LayerNorm+Dropout)
        # WARNING: ì´ êµ¬ì¡°ëŠ” ì˜ë¯¸ ì—†ëŠ” attention ì ìš©ì„
        # ìƒˆë¡œìš´ ëª¨ë¸ì—ì„œëŠ” MultiTokenAttentionLayer ì‚¬ìš© ê¶Œì¥
        self.use_attention = use_attention
        if use_attention:
            self.attention = AttentionLayer(
                embed_dim=self.total_dim,
                num_heads=8,
                dropout=0.1
            )

        # Feature fusion network
        self.fc1 = nn.Linear(self.total_dim, 256)
        self.bn1 = nn.BatchNorm1d(256)
        self.dropout1 = nn.Dropout(dropout_rate)

        self.fc2 = nn.Linear(256, 128)
        self.bn2 = nn.BatchNorm1d(128)
        self.dropout2 = nn.Dropout(dropout_rate * 0.7)

        # Residual connection
        self.residual_proj = nn.Linear(self.total_dim, 128)

        self.fc3 = nn.Linear(128, 64)
        self.bn3 = nn.BatchNorm1d(64)
        self.dropout3 = nn.Dropout(dropout_rate * 0.5)

        self.fc4 = nn.Linear(64, 32)
        self.fc_out = nn.Linear(32, 1)

    def forward(
        self,
        face_features: torch.Tensor,
        skin_features: torch.Tensor,
        style_emb: torch.Tensor
    ) -> torch.Tensor:
        """Forward pass"""
        # Project features
        face_proj = self.face_projection(face_features)
        skin_proj = self.skin_projection(skin_features)

        # Concatenate all features
        x = torch.cat([face_proj, skin_proj, style_emb], dim=1)

        # Apply attention if enabled (ë‹¨ì¼ í† í°ì´ë¯€ë¡œ ì‹¤ì§ˆì ìœ¼ë¡œ LayerNorm)
        if self.use_attention:
            x_att = x.unsqueeze(1)
            x_att = self.attention(x_att)
            x = x_att.squeeze(1)

        # Store for residual
        residual = self.residual_proj(x)

        # Main network
        x = self.fc1(x)
        x = self.bn1(x)
        x = torch.relu(x)
        x = self.dropout1(x)

        x = self.fc2(x)
        x = self.bn2(x)
        x = torch.relu(x)
        x = self.dropout2(x)

        # Add residual connection
        x = x + residual

        x = self.fc3(x)
        x = self.bn3(x)
        x = torch.relu(x)
        x = self.dropout3(x)

        x = self.fc4(x)
        x = torch.relu(x)

        x = self.fc_out(x)

        # ìŠ¤ì¼€ì¼ë§ ì ìš© (í•™ìŠµ ì‹œ 30~90ì  ë²”ìœ„)
        # í´ë¨í•‘ ì œê±° - ì›ë³¸ ì ìˆ˜ë¥¼ ìœ ì§€í•˜ì—¬ Top-K ë‚´ì—ì„œ Min-Max ì •ê·œí™” ê°€ëŠ¥í•˜ê²Œ í•¨
        x = (x - 29.0) * 7.5 + 60.0
        # ì°¸ê³ : í´ë¨í•‘ì€ recommend_top_kì—ì„œ Min-Max ì •ê·œí™” í›„ ì ìš©

        return x.squeeze(-1)


class NormalizedRecommendationModel(nn.Module):
    """
    ì •ê·œí™”ëœ ë¼ë²¨ ê¸°ë°˜ ì¶”ì²œ ëª¨ë¸ v5

    í•µì‹¬ íŠ¹ì§•:
    - ì¶œë ¥ì¸µì— Sigmoid í™œì„±í™” í•¨ìˆ˜ ì‚¬ìš© (0~1 ì¶œë ¥ ë³´ì¥)
    - ì¶”ë¡  ì‹œ ì—­ë³€í™˜ í•„ìš” (0~1 â†’ 10~95)

    ì…ë ¥:
    - face_features: [batch, 6] - MediaPipe ì–¼êµ´ ì¸¡ì •ê°’
    - skin_features: [batch, 2] - MediaPipe í”¼ë¶€ ì¸¡ì •ê°’
    - style_emb: [batch, 384] - í—¤ì–´ìŠ¤íƒ€ì¼ ì„ë² ë”©

    Note:
    - use_attention=TrueëŠ” ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
    - ë‹¨ì¼ í† í° attentionì€ ì‹¤ì§ˆì ìœ¼ë¡œ LayerNorm+Dropoutê³¼ ë™ì¼ (identityì— ê°€ê¹Œì›€)
    - ìƒˆë¡œìš´ í•™ìŠµ ì‹œì—ëŠ” RecommendationModelV6 ì‚¬ìš© ê¶Œì¥
    """

    def __init__(
        self,
        face_feat_dim: int = 6,
        skin_feat_dim: int = 2,
        style_embed_dim: int = 384,
        use_attention: bool = True,  # ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ í˜¸í™˜ì„± ìœ ì§€
        dropout_rate: float = 0.3
    ):
        super().__init__()

        self.face_feat_dim = face_feat_dim
        self.skin_feat_dim = skin_feat_dim
        self.style_embed_dim = style_embed_dim

        # Input projection layers
        self.face_projection = nn.Sequential(
            nn.Linear(face_feat_dim, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(dropout_rate * 0.5)
        )

        self.skin_projection = nn.Sequential(
            nn.Linear(skin_feat_dim, 32),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.Dropout(dropout_rate * 0.5)
        )

        self.total_dim = 64 + 32 + style_embed_dim  # 480

        # Attention layer (ë‹¨ì¼ í† í° - ì‹¤ì§ˆì ìœ¼ë¡œ LayerNorm+Dropout)
        # WARNING: ì´ êµ¬ì¡°ëŠ” ì˜ë¯¸ ì—†ëŠ” attention ì ìš©ì„
        # ìƒˆë¡œìš´ ëª¨ë¸ì—ì„œëŠ” MultiTokenAttentionLayer ì‚¬ìš© ê¶Œì¥
        self.use_attention = use_attention
        if use_attention:
            self.attention = AttentionLayer(
                embed_dim=self.total_dim,
                num_heads=8,
                dropout=0.1
            )

        self.fc1 = nn.Linear(self.total_dim, 256)
        self.bn1 = nn.BatchNorm1d(256)
        self.dropout1 = nn.Dropout(dropout_rate)

        self.fc2 = nn.Linear(256, 128)
        self.bn2 = nn.BatchNorm1d(128)
        self.dropout2 = nn.Dropout(dropout_rate * 0.7)

        self.residual_proj = nn.Linear(self.total_dim, 128)

        self.fc3 = nn.Linear(128, 64)
        self.bn3 = nn.BatchNorm1d(64)
        self.dropout3 = nn.Dropout(dropout_rate * 0.5)

        self.fc4 = nn.Linear(64, 32)
        self.fc_out = nn.Linear(32, 1)

        # Sigmoid í™œì„±í™” í•¨ìˆ˜ - ì¶œë ¥ì„ 0~1ë¡œ ì œí•œ
        self.sigmoid = nn.Sigmoid()

    def forward(
        self,
        face_features: torch.Tensor,
        skin_features: torch.Tensor,
        style_emb: torch.Tensor
    ) -> torch.Tensor:
        """Forward pass - ì¶œë ¥ ë²”ìœ„: 0~1 (Sigmoid)"""
        face_proj = self.face_projection(face_features)
        skin_proj = self.skin_projection(skin_features)

        x = torch.cat([face_proj, skin_proj, style_emb], dim=1)

        # Apply attention if enabled (ë‹¨ì¼ í† í°ì´ë¯€ë¡œ ì‹¤ì§ˆì ìœ¼ë¡œ LayerNorm)
        if self.use_attention:
            x_att = x.unsqueeze(1)
            x_att = self.attention(x_att)
            x = x_att.squeeze(1)

        residual = self.residual_proj(x)

        x = self.fc1(x)
        x = self.bn1(x)
        x = torch.relu(x)
        x = self.dropout1(x)

        x = self.fc2(x)
        x = self.bn2(x)
        x = torch.relu(x)
        x = self.dropout2(x)

        x = x + residual

        x = self.fc3(x)
        x = self.bn3(x)
        x = torch.relu(x)
        x = self.dropout3(x)

        x = self.fc4(x)
        x = torch.relu(x)

        x = self.fc_out(x)

        # Sigmoidë¡œ 0~1 ì¶œë ¥ ë³´ì¥
        x = self.sigmoid(x)

        return x.squeeze(-1)


class RecommendationModelV6(nn.Module):
    """
    Multi-Token Attention ê¸°ë°˜ ì¶”ì²œ ëª¨ë¸ v6

    v4/v5ì˜ ë¬¸ì œì  í•´ê²°:
    - ê¸°ì¡´: ë‹¨ì¼ í† í°(480ì°¨ì›)ì— self-attention â†’ ì‚¬ì‹¤ìƒ identity
    - ê°œì„ : 3ê°œ í† í°(face, skin, style) ê°„ cross-attention â†’ ì˜ë¯¸ ìˆëŠ” ìƒí˜¸ì‘ìš© í•™ìŠµ

    êµ¬ì¡°:
    1. Input Projection: face(6â†’64), skin(2â†’32)
    2. Multi-Token Attention: 3ê°œ í† í°ì„ 128ì°¨ì›ìœ¼ë¡œ í†µì¼ í›„ attention
    3. Feature Fusion: attention ì¶œë ¥(384) â†’ MLP â†’ score

    ì…ë ¥:
    - face_features: [batch, 6] - MediaPipe ì–¼êµ´ ì¸¡ì •ê°’
    - skin_features: [batch, 2] - MediaPipe í”¼ë¶€ ì¸¡ì •ê°’
    - style_emb: [batch, 384] - í—¤ì–´ìŠ¤íƒ€ì¼ ì„ë² ë”©

    ì¶œë ¥:
    - normalized score: 0~1 (Sigmoid)
    """

    def __init__(
        self,
        face_feat_dim: int = 6,
        skin_feat_dim: int = 2,
        style_embed_dim: int = 384,
        token_dim: int = 128,
        num_heads: int = 4,
        dropout_rate: float = 0.3
    ):
        super().__init__()

        self.face_feat_dim = face_feat_dim
        self.skin_feat_dim = skin_feat_dim
        self.style_embed_dim = style_embed_dim

        # Input projection layers (attention ì´ì „)
        self.face_projection = nn.Sequential(
            nn.Linear(face_feat_dim, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(dropout_rate * 0.5)
        )

        self.skin_projection = nn.Sequential(
            nn.Linear(skin_feat_dim, 32),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.Dropout(dropout_rate * 0.5)
        )

        # Multi-Token Attention Layer (3ê°œ í† í° ê°„ ìƒí˜¸ì‘ìš©)
        self.multi_token_attention = MultiTokenAttentionLayer(
            face_dim=64,
            skin_dim=32,
            style_dim=style_embed_dim,
            token_dim=token_dim,
            num_heads=num_heads,
            dropout=dropout_rate * 0.3
        )

        # Attention ì¶œë ¥ ì°¨ì›: token_dim * 3 = 384
        attention_out_dim = token_dim * 3

        # Feature fusion network
        self.fc1 = nn.Linear(attention_out_dim, 256)
        self.bn1 = nn.BatchNorm1d(256)
        self.dropout1 = nn.Dropout(dropout_rate)

        self.fc2 = nn.Linear(256, 128)
        self.bn2 = nn.BatchNorm1d(128)
        self.dropout2 = nn.Dropout(dropout_rate * 0.7)

        # Residual connection
        self.residual_proj = nn.Linear(attention_out_dim, 128)

        self.fc3 = nn.Linear(128, 64)
        self.bn3 = nn.BatchNorm1d(64)
        self.dropout3 = nn.Dropout(dropout_rate * 0.5)

        self.fc4 = nn.Linear(64, 32)
        self.fc_out = nn.Linear(32, 1)

        # Sigmoid í™œì„±í™” í•¨ìˆ˜ - ì¶œë ¥ì„ 0~1ë¡œ ì œí•œ
        self.sigmoid = nn.Sigmoid()

    def forward(
        self,
        face_features: torch.Tensor,
        skin_features: torch.Tensor,
        style_emb: torch.Tensor
    ) -> torch.Tensor:
        """Forward pass - ì¶œë ¥ ë²”ìœ„: 0~1 (Sigmoid)"""
        # 1. Input projection
        face_proj = self.face_projection(face_features)  # (batch, 64)
        skin_proj = self.skin_projection(skin_features)  # (batch, 32)

        # 2. Multi-Token Attention (3ê°œ í† í° ê°„ ìƒí˜¸ì‘ìš©)
        x = self.multi_token_attention(face_proj, skin_proj, style_emb)  # (batch, 384)

        # Store for residual
        residual = self.residual_proj(x)

        # 3. Feature fusion MLP
        x = self.fc1(x)
        x = self.bn1(x)
        x = torch.relu(x)
        x = self.dropout1(x)

        x = self.fc2(x)
        x = self.bn2(x)
        x = torch.relu(x)
        x = self.dropout2(x)

        # Add residual connection
        x = x + residual

        x = self.fc3(x)
        x = self.bn3(x)
        x = torch.relu(x)
        x = self.dropout3(x)

        x = self.fc4(x)
        x = torch.relu(x)

        x = self.fc_out(x)

        # Sigmoidë¡œ 0~1 ì¶œë ¥ ë³´ì¥
        x = self.sigmoid(x)

        return x.squeeze(-1)


class MLHairstyleRecommender:
    """ML ê¸°ë°˜ í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œê¸°"""

    # MediaPipeì™€ í˜¸í™˜ë˜ëŠ” ì¹´í…Œê³ ë¦¬
    FACE_SHAPES = ["ê°ì§„í˜•", "ë‘¥ê·¼í˜•", "ê¸´í˜•", "ê³„ë€í˜•"]
    SKIN_TONES = ["ê²¨ìš¸ì¿¨", "ê°€ì„ì›œ", "ë´„ì›œ", "ì—¬ë¦„ì¿¨"]

    def __init__(
        self,
        model_path: str = "models/hairstyle_recommender_v6_multitoken.pt",
        embeddings_path: str = "data_source/style_embeddings.npz",
        gender_metadata_path: str = "data_source/hairstyle_gender.json"
    ):
        """
        ì´ˆê¸°í™”

        Args:
            model_path: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ (ê¸°ë³¸: v6 Multi-Token Attention)
            embeddings_path: í—¤ì–´ìŠ¤íƒ€ì¼ ì„ë² ë”© ê²½ë¡œ
            gender_metadata_path: í—¤ì–´ìŠ¤íƒ€ì¼ ì„±ë³„ ë©”íƒ€ë°ì´í„° ê²½ë¡œ
        """
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        # 1. ëª¨ë¸ ë¡œë“œ
        logger.info(f"ğŸ“‚ ML ëª¨ë¸ ë¡œë”©: {model_path}")

        # ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ìœ¼ë¡œ ì €ì¥ëœ ê²½ìš° ì²˜ë¦¬
        try:
            checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)

            # ëª¨ë¸ ë²„ì „ ë° ì„¤ì • í™•ì¸
            if isinstance(checkpoint, dict) and 'config' in checkpoint:
                config = checkpoint['config']
                self.is_normalized_model = config.get('normalized', False)
                self.model_version = config.get('version', 'v5' if self.is_normalized_model else 'v4')
                self.attention_type = config.get('attention_type', 'single_token')
                logger.info(f"  - ëª¨ë¸ ë²„ì „: {self.model_version}")
                logger.info(f"  - ì •ê·œí™” ëª¨ë¸: {self.is_normalized_model}")
                logger.info(f"  - Attention íƒ€ì…: {self.attention_type}")
            else:
                self.is_normalized_model = False
                self.model_version = 'v4'
                self.attention_type = 'single_token'

            # ëª¨ë¸ í´ë˜ìŠ¤ ì„ íƒ
            if self.model_version == 'v6' or self.attention_type == 'multi_token':
                # V6: Multi-Token Attention
                token_dim = config.get('token_dim', 128)
                num_heads = config.get('num_heads', 4)
                self.model = RecommendationModelV6(
                    token_dim=token_dim,
                    num_heads=num_heads
                )
                logger.info(f"  - ì‚¬ìš© ëª¨ë¸: RecommendationModelV6 (Multi-Token Attention)")
            elif self.is_normalized_model:
                # V5: Normalized + Single-Token Attention
                self.model = NormalizedRecommendationModel()
                logger.info("  - ì‚¬ìš© ëª¨ë¸: NormalizedRecommendationModel (v5 - Sigmoid ì¶œë ¥)")
            else:
                # V4: Legacy
                self.model = RecommendationModel()
                logger.info("  - ì‚¬ìš© ëª¨ë¸: RecommendationModel (v4)")

            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                self.model.load_state_dict(checkpoint['model_state_dict'])
                logger.info(f"âœ… ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (epoch: {checkpoint.get('epoch', 'N/A')})")
            else:
                self.model.load_state_dict(checkpoint)
                logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise

        self.model.to(self.device)
        self.model.eval()  # ì¶”ë¡  ëª¨ë“œ
        logger.info(f"âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ (ë””ë°”ì´ìŠ¤: {self.device})")

        # 2. í—¤ì–´ìŠ¤íƒ€ì¼ ì„ë² ë”© ë¡œë“œ
        logger.info(f"ğŸ“‚ ì„ë² ë”© ë¡œë”©: {embeddings_path}")
        try:
            data = np.load(embeddings_path, allow_pickle=False)
            self.styles = data['styles'].tolist()  # í—¤ì–´ìŠ¤íƒ€ì¼ëª… ë¦¬ìŠ¤íŠ¸
            self.embeddings = data['embeddings']  # (N, 384) ì„ë² ë”©
            logger.info(f"âœ… ì„ë² ë”© ë¡œë“œ ì™„ë£Œ: {len(self.styles)}ê°œ ìŠ¤íƒ€ì¼")
        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise

        # ìŠ¤íƒ€ì¼ëª… -> ì¸ë±ìŠ¤ ë§¤í•‘
        self.style_to_idx = {style: idx for idx, style in enumerate(self.styles)}

        # 3. ì„±ë³„ ë©”íƒ€ë°ì´í„° ë¡œë“œ (NEW)
        logger.info(f"ğŸ“‚ ì„±ë³„ ë©”íƒ€ë°ì´í„° ë¡œë”©: {gender_metadata_path}")
        try:
            import json
            import os
            if os.path.exists(gender_metadata_path):
                with open(gender_metadata_path, 'r', encoding='utf-8') as f:
                    self.gender_metadata = json.load(f)
                logger.info(f"âœ… ì„±ë³„ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.gender_metadata)}ê°œ ìŠ¤íƒ€ì¼")
            else:
                logger.warning(f"âš ï¸ ì„±ë³„ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì—†ìŒ - ì„±ë³„ í•„í„°ë§ ë¹„í™œì„±í™”")
                self.gender_metadata = {}
        except Exception as e:
            logger.error(f"âŒ ì„±ë³„ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            self.gender_metadata = {}

        # 4. ì‹¤ì‹œê°„ ì„ë² ë”©ìš© SentenceTransformer ë¡œë“œ (Lambdaì—ì„œëŠ” ìŠ¤í‚µ)
        import os
        is_lambda = os.environ.get('AWS_LAMBDA_FUNCTION_NAME') is not None

        if not is_lambda:
            logger.info("ğŸ”„ ì‹¤ì‹œê°„ ì„ë² ë”© ëª¨ë¸ ë¡œë”© (paraphrase-multilingual-MiniLM-L12-v2)...")
            try:
                from sentence_transformers import SentenceTransformer
                self.sentence_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
                logger.info("âœ… ì‹¤ì‹œê°„ ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ ì‹¤ì‹œê°„ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                self.sentence_model = None
        else:
            logger.info("ğŸ”§ Lambda í™˜ê²½ - ì‹¤ì‹œê°„ ì„ë² ë”© ëª¨ë¸ ìŠ¤í‚µ")
            self.sentence_model = None

    def _encode_face_shape(self, face_shape: str) -> np.ndarray:
        """ì–¼êµ´í˜•ì„ one-hot ì¸ì½”ë”© (6ì°¨ì› - ëª¨ë¸ê³¼ ì¼ì¹˜)"""
        vec = np.zeros(6, dtype=np.float32)

        # í•˜íŠ¸í˜•ì€ ê³„ë€í˜•ìœ¼ë¡œ ë§¤í•‘
        if face_shape == "í•˜íŠ¸í˜•":
            face_shape = "ê³„ë€í˜•"
            logger.debug("í•˜íŠ¸í˜•ì„ ê³„ë€í˜•ìœ¼ë¡œ ë§¤í•‘")

        # ê¸°ë³¸ 4ê°€ì§€ ì–¼êµ´í˜•ì— ëŒ€í•œ one-hot ì¸ì½”ë”©
        if face_shape in self.FACE_SHAPES:
            idx = self.FACE_SHAPES.index(face_shape)
            vec[idx] = 1.0
        else:
            logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ì–¼êµ´í˜•: {face_shape}, ê³„ë€í˜•ìœ¼ë¡œ ê¸°ë³¸ê°’ ì‚¬ìš©")
            vec[3] = 1.0  # ê³„ë€í˜•

        # ì¶”ê°€ íŠ¹ì§• ì°¨ì› (ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©ë¨)
        vec[4] = 0.5  # ì¤‘ê°„ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
        vec[5] = 0.5  # ì¤‘ê°„ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”

        return vec

    def _encode_skin_tone(self, skin_tone: str) -> np.ndarray:
        """í”¼ë¶€í†¤ì„ one-hot ì¸ì½”ë”© (2ì°¨ì› - ëª¨ë¸ê³¼ ì¼ì¹˜)"""
        vec = np.zeros(2, dtype=np.float32)

        # ë´„/ê°€ì„ -> ì›œí†¤(0), ì—¬ë¦„/ê²¨ìš¸ -> ì¿¨í†¤(1)
        if skin_tone in ["ë´„ì›œ", "ê°€ì„ì›œ"]:
            vec[0] = 1.0  # ì›œí†¤
        elif skin_tone in ["ì—¬ë¦„ì¿¨", "ê²¨ìš¸ì¿¨"]:
            vec[1] = 1.0  # ì¿¨í†¤
        else:
            logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” í”¼ë¶€í†¤: {skin_tone}, ì›œí†¤ìœ¼ë¡œ ê¸°ë³¸ê°’ ì‚¬ìš©")
            vec[0] = 1.0  # ì›œí†¤

        return vec

    # ìŠ¤íƒ€ì¼ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ (ê°™ì€ ì¹´í…Œê³ ë¦¬ëŠ” ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ë¡œ ê°„ì£¼)
    # ì£¼ì˜: ë” êµ¬ì²´ì ì¸ í‚¤ì›Œë“œê°€ ë¨¼ì € ì™€ì•¼ í•¨
    STYLE_CATEGORY_KEYWORDS = [
        ["ì‰¼í‘œë¨¸ë¦¬", "ì‰¼í‘œ ë¨¸ë¦¬", "comma"],  # ì‰¼í‘œë¨¸ë¦¬ ê³„ì—´ (ë¨¼ì € ì²´í¬)
        ["íˆí”¼ë¨¸ë¦¬", "íˆí”¼", "hippie"],  # íˆí”¼ ê³„ì—´
        ["ê°€ë¥´ë§ˆ", "ì„¼í„°", "ì‚¬ì´ë“œ"],  # ê°€ë¥´ë§ˆ ê³„ì—´
        ["ì‹œìŠ¤ë£¨", "í’€ë±…"],  # ì‹œìŠ¤ë£¨/í’€ë±… ê³„ì—´
        ["ë ˆì´ì–´ë“œ", "ë ˆì´ì–´"],  # ë ˆì´ì–´ë“œ ê³„ì—´
        ["ìˆì»·", "ìˆí—¤ì–´", "ì§§ì€", "short"],  # ìˆì»· ê³„ì—´
        ["ë¡± ìŠ¤íƒ€ì¼", "ë¡±í—¤ì–´", "ê¸´ë¨¸ë¦¬", "ì¥ë°œ", "long"],  # ë¡± ê³„ì—´
        ["íˆ¬ë¸”ëŸ­", "íˆ¬ë¸”ë¡", "ì–¸ë”ì»·"],  # íˆ¬ë¸”ëŸ­ ê³„ì—´
        ["ëŒ„ë””", "í¬ë§ˆë“œ", "ìŠ¬ë¦­ë°±"],  # ëŒ„ë”” ê³„ì—´
        ["ë³´ë¸Œ", "ë‹¨ë°œ", "bob"],  # ë³´ë¸Œ/ë‹¨ë°œ ê³„ì—´
        ["ë¨¸ì‰¬ë£¸", "ë²„ì„¯"],  # ë¨¸ì‰¬ë£¸ ê³„ì—´
        ["íŒ", "ì›¨ì´ë¸Œ", "ì»¬", "perm"],  # íŒ ê³„ì—´
        ["ì‹¬í”Œ", "ìì—°", "ë‚´ì¶”ëŸ´"],  # ì‹¬í”Œ/ìì—° ê³„ì—´
    ]

    def _get_style_category(self, style_name: str) -> int:
        """ìŠ¤íƒ€ì¼ëª…ì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ (0-based index, -1ì´ë©´ ì¹´í…Œê³ ë¦¬ ì—†ìŒ)"""
        style_lower = style_name.lower()
        for idx, keywords in enumerate(self.STYLE_CATEGORY_KEYWORDS):
            for keyword in keywords:
                if keyword in style_lower:
                    return idx
        return -1

    def _is_similar_style(self, style_a: str, style_b: str, threshold: float = 0.65) -> bool:
        """
        ë‘ ìŠ¤íƒ€ì¼ëª…ì˜ ìœ ì‚¬ë„ ê³„ì‚° (ë¬¸ìì—´ ìœ ì‚¬ë„ + ì¹´í…Œê³ ë¦¬ ê¸°ë°˜)

        Args:
            style_a: ì²« ë²ˆì§¸ ìŠ¤íƒ€ì¼ëª…
            style_b: ë‘ ë²ˆì§¸ ìŠ¤íƒ€ì¼ëª…
            threshold: ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸ 0.65 = 65%)

        Returns:
            threshold ì´ìƒì´ë©´ True (ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼)

        ë¡œì§:
            1. ë¬¸ìì—´ ìœ ì‚¬ë„ê°€ threshold ì´ìƒì´ë©´ ìœ ì‚¬í•¨
            2. ê°™ì€ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ë©´ ìœ ì‚¬í•¨ (ì˜ˆ: "ì„¼í„° ê°€ë¥´ë§ˆ" vs "ê°€ë¥´ë§ˆ ìŠ¤íƒ€ì¼")
        """
        # 1. ë¬¸ìì—´ ìœ ì‚¬ë„ ì²´í¬
        ratio = SequenceMatcher(None, style_a, style_b).ratio()
        if ratio >= threshold:
            return True

        # 2. ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ì²´í¬ (ê°™ì€ ì¹´í…Œê³ ë¦¬ë©´ ìœ ì‚¬í•¨)
        cat_a = self._get_style_category(style_a)
        cat_b = self._get_style_category(style_b)

        if cat_a >= 0 and cat_a == cat_b:
            logger.debug(f"[DIVERSITY] ê°™ì€ ì¹´í…Œê³ ë¦¬: '{style_a}' vs '{style_b}' (category={cat_a})")
            return True

        return False

    def _get_style_embedding(self, style_name: str) -> np.ndarray:
        """
        ìŠ¤íƒ€ì¼ ì„ë² ë”© ê°€ì ¸ì˜¤ê¸° (DB ì¡°íšŒ ë˜ëŠ” ì‹¤ì‹œê°„ ìƒì„±)

        Args:
            style_name: í—¤ì–´ìŠ¤íƒ€ì¼ëª… (ì •ê·œí™”ëœ ì´ë¦„ ê¶Œì¥)

        Returns:
            ì„ë² ë”© ë²¡í„° (384,) ë˜ëŠ” None
        """
        # 1. DB ì¡°íšŒ (Fast Path)
        if style_name in self.style_to_idx:
            idx = self.style_to_idx[style_name]
            return self.embeddings[idx]

        # 2. ì‹¤ì‹œê°„ ìƒì„± (Slow Path)
        if self.sentence_model:
            logger.info(f"ğŸ†• ìƒˆë¡œìš´ ìŠ¤íƒ€ì¼ ë°œê²¬: '{style_name}' -> ì‹¤ì‹œê°„ ì„ë² ë”© ìƒì„±")
            try:
                embedding = self.sentence_model.encode(style_name)
                return embedding
            except Exception as e:
                logger.error(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ ({style_name}): {str(e)}")
                return None

        return None

    def predict_score(
        self,
        face_shape: str,
        skin_tone: str,
        hairstyle: str
    ) -> float:
        """
        íŠ¹ì • í—¤ì–´ìŠ¤íƒ€ì¼ì˜ ì¶”ì²œ ì ìˆ˜ ì˜ˆì¸¡ (ë„ì–´ì“°ê¸° ì •ê·œí™” ì ìš©)

        Args:
            face_shape: ì–¼êµ´í˜•
            skin_tone: í”¼ë¶€í†¤
            hairstyle: í—¤ì–´ìŠ¤íƒ€ì¼ëª…

        Returns:
            ì¶”ì²œ ì ìˆ˜ (0-100)
        """
        # ë„ì–´ì“°ê¸° ì •ê·œí™” ì ìš©
        normalized_style = normalize_style_name(hairstyle)

        # ì„ë² ë”© ê°€ì ¸ì˜¤ê¸° (DB or ì‹¤ì‹œê°„)
        style_embedding = self._get_style_embedding(normalized_style)

        if style_embedding is None:
            # ì›ë³¸ ì´ë¦„ìœ¼ë¡œë„ ì‹œë„
            style_embedding = self._get_style_embedding(hairstyle)
            
            if style_embedding is None:
                logger.warning(f"ì„ë² ë”© ìƒì„± ë¶ˆê°€: '{hairstyle}'")
                return 0.0

        # ê°œë³„ íŠ¹ì§• ë²¡í„° ìƒì„±
        face_vec = self._encode_face_shape(face_shape)  # (4,)
        tone_vec = self._encode_skin_tone(skin_tone)    # (4,)

        # ëª¨ë¸ ì¶”ë¡  - 3ê°œì˜ ê°œë³„ í…ì„œë¡œ ì „ë‹¬
        with torch.no_grad():
            face_tensor = torch.FloatTensor(face_vec).unsqueeze(0).to(self.device)
            skin_tensor = torch.FloatTensor(tone_vec).unsqueeze(0).to(self.device)
            style_tensor = torch.FloatTensor(style_embedding).unsqueeze(0).to(self.device)

            score_tensor = self.model(face_tensor, skin_tensor, style_tensor)
            score = score_tensor.cpu().item()

        # ì •ê·œí™” ëª¨ë¸(v5)ì¸ ê²½ìš° ì—­ë³€í™˜ ì ìš© (0~1 â†’ 10~95)
        if self.is_normalized_model:
            score = denormalize_score(score)

        # 10-95 ë²”ìœ„ë¡œ í´ë¦¬í•‘ (ì •ê·œí™” ëª¨ë¸) ë˜ëŠ” 0-100 (ê¸°ì¡´ ëª¨ë¸)
        if self.is_normalized_model:
            score = max(LABEL_MIN, min(LABEL_MAX, score))
        else:
            score = max(0.0, min(100.0, score))

        return round(score, 2)

    def recommend_top_k(
        self,
        face_shape: str = None,
        skin_tone: str = None,
        k: int = 3,
        face_features: List[float] = None,
        skin_features: List[float] = None,
        gender: str = None
    ) -> List[Dict[str, any]]:
        """
        Top-K í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ (ì„±ë³„ í•„í„°ë§ ì ìš©)

        Args:
            face_shape: ì–¼êµ´í˜• (ì˜ˆ: "ê³„ë€í˜•") - DEPRECATED, í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
            skin_tone: í”¼ë¶€í†¤ (ì˜ˆ: "ë´„ì›œ") - DEPRECATED, í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
            k: ì¶”ì²œ ê°œìˆ˜
            face_features: MediaPipe ì–¼êµ´ ì¸¡ì •ê°’ [face_ratio, forehead_width, cheekbone_width, jaw_width, forehead_ratio, jaw_ratio] (6ì°¨ì›)
            skin_features: MediaPipe í”¼ë¶€ ì¸¡ì •ê°’ [ITA_value, hue_value] (2ì°¨ì›)
            gender: ì„±ë³„ ("male", "female", "neutral") - MediaPipeë¡œ ì¶”ë¡ ëœ ê°’

        Returns:
            ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ [{"hairstyle": "...", "score": 85.3}, ...]
        """
        # ì‹¤ì œ ì¸¡ì •ê°’ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ë¼ë²¨ ê¸°ë°˜ ì¸ì½”ë”© (í•˜ìœ„ í˜¸í™˜ì„±)
        if face_features is not None and skin_features is not None:
            logger.info(f"[ML DEBUG] ML ì¶”ì²œ ì‹œì‘ (ì‹¤ì œ ì¸¡ì •ê°’ ì‚¬ìš©) - Top-{k}")
            logger.info(f"[ML DEBUG] Face features (ì›ë³¸): {face_features}")
            logger.info(f"[ML DEBUG] Skin features (ì›ë³¸): {skin_features}")

            # NumPy ë°°ì—´ë¡œ ë³€í™˜
            face_vec = np.array(face_features, dtype=np.float32)
            tone_vec = np.array(skin_features, dtype=np.float32)

            # ì°¨ì› ê²€ì¦
            if face_vec.shape[0] != 6:
                raise ValueError(f"face_featuresëŠ” 6ì°¨ì›ì´ì–´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {face_vec.shape[0]}")
            if tone_vec.shape[0] != 2:
                raise ValueError(f"skin_featuresëŠ” 2ì°¨ì›ì´ì–´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {tone_vec.shape[0]}")

            # ì…ë ¥ ìŠ¤ì¼€ì¼ë§ ì ìš© (í•™ìŠµ ë°ì´í„° ë¶„í¬ì— ë§ê²Œ ë³€í™˜)
            face_vec, tone_vec = scale_input_features(face_vec, tone_vec)
            logger.info(f"[ML DEBUG] Face features (ìŠ¤ì¼€ì¼ë§ í›„): {face_vec.tolist()}")
            logger.info(f"[ML DEBUG] Skin features (ìŠ¤ì¼€ì¼ë§ í›„): {tone_vec.tolist()}")
        else:
            # í•˜ìœ„ í˜¸í™˜ì„±: ë¼ë²¨ ê¸°ë°˜ ì¸ì½”ë”©
            logger.warning(f"[ML DEPRECATED] ë¼ë²¨ ê¸°ë°˜ ì¸ì½”ë”© ì‚¬ìš©: {face_shape} + {skin_tone}")
            logger.warning("[ML DEPRECATED] ì‹¤ì œ ì¸¡ì •ê°’(face_features, skin_features)ì„ ì „ë‹¬í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")

            if face_shape is None or skin_tone is None:
                raise ValueError("face_featuresì™€ skin_featuresê°€ ì—†ìœ¼ë©´ face_shapeê³¼ skin_toneì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")

            face_vec = self._encode_face_shape(face_shape)  # (6,)
            tone_vec = self._encode_skin_tone(skin_tone)    # (2,)

        logger.info(f"[ML DEBUG] Face vector: {face_vec.tolist()}")
        logger.info(f"[ML DEBUG] Skin vector: {tone_vec.tolist()}")

        # ëª¨ë“  í—¤ì–´ìŠ¤íƒ€ì¼ì— ëŒ€í•´ ì ìˆ˜ ì˜ˆì¸¡
        all_scores = []

        # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ìµœì í™”
        batch_size = 64
        num_styles = len(self.styles)

        for i in range(0, num_styles, batch_size):
            batch_end = min(i + batch_size, num_styles)
            batch_size_actual = batch_end - i
            batch_embeddings = self.embeddings[i:batch_end]

            # ë°°ì¹˜ ì¶”ë¡  - 3ê°œì˜ ê°œë³„ í…ì„œë¡œ ì „ë‹¬
            with torch.no_grad():
                # ì–¼êµ´í˜•ê³¼ í”¼ë¶€í†¤ì€ ë°°ì¹˜ í¬ê¸°ë§Œí¼ ë³µì œ
                face_batch = np.tile(face_vec, (batch_size_actual, 1))
                skin_batch = np.tile(tone_vec, (batch_size_actual, 1))

                face_tensor = torch.FloatTensor(face_batch).to(self.device)
                skin_tensor = torch.FloatTensor(skin_batch).to(self.device)
                style_tensor = torch.FloatTensor(batch_embeddings).to(self.device)

                # ì²« ë²ˆì§¸ ë°°ì¹˜ì—ì„œë§Œ ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
                if i == 0:
                    logger.info(f"[ML DEBUG] First batch embedding shape: {batch_embeddings.shape}")
                    logger.info(f"[ML DEBUG] First style embedding std: {batch_embeddings.std():.6f}")
                    logger.info(f"[ML DEBUG] First 3 styles: {self.styles[i:i+3]}")

                scores_tensor = self.model(face_tensor, skin_tensor, style_tensor)
                scores = scores_tensor.cpu().numpy().flatten()

                # ì •ê·œí™” ëª¨ë¸(v5)ì¸ ê²½ìš° ì—­ë³€í™˜ ì ìš© (0~1 â†’ 10~95)
                if self.is_normalized_model:
                    scores = scores * LABEL_RANGE + LABEL_MIN

                # ì²« ë²ˆì§¸ ë°°ì¹˜ì—ì„œë§Œ ì ìˆ˜ ë””ë²„ê·¸
                if i == 0:
                    logger.info(f"[ML DEBUG] First batch scores: {scores[:5].tolist()}")
                    logger.info(f"[ML DEBUG] Scores std: {scores.std():.6f}")
                    if self.is_normalized_model:
                        logger.info(f"[ML DEBUG] ì •ê·œí™” ëª¨ë¸ - ì—­ë³€í™˜ ì ìš©ë¨ (0~1 â†’ {LABEL_MIN}~{LABEL_MAX})")

            # ê²°ê³¼ ì €ì¥
            for j, score in enumerate(scores):
                style_idx = i + j
                all_scores.append({
                    "hairstyle_id": style_idx,  # DB ID ì¶”ê°€
                    "hairstyle": self.styles[style_idx],
                    "score": float(score),  # ì—­ë³€í™˜ëœ ì ìˆ˜ (10~95 ë²”ìœ„)
                    "original_score": float(score)  # í”¼ë“œë°±ìš© ì›ë³¸ ì ìˆ˜ ë³´ì¡´
                })

        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        all_scores.sort(key=lambda x: x['score'], reverse=True)

        # ì„±ë³„ í•„í„°ë§ (NEW)
        if gender and self.gender_metadata:
            logger.info(f"[GENDER] ì„±ë³„ í•„í„°ë§ ì‹œì‘ (gender={gender}, metadata_count={len(self.gender_metadata)})")
            filtered_scores = []
            debug_count = 0
            for item in all_scores:
                style_name = item['hairstyle']
                style_gender = self.gender_metadata.get(style_name, "unisex")

                # ì²˜ìŒ 5ê°œ ìŠ¤íƒ€ì¼ì€ ë””ë²„ê¹…ìš© ë¡œê¹…
                if debug_count < 5:
                    logger.debug(f"[GENDER DEBUG] {style_name}: {style_gender} (score={item['score']:.2f})")
                    debug_count += 1

                # ì„±ë³„ ë§¤ì¹­ ë¡œì§:
                # - neutral (ì• ë§¤í•œ ê²½ìš°): ëª¨ë“  ìŠ¤íƒ€ì¼ ì¶”ì²œ
                # - male: male + unisex ì¶”ì²œ
                # - female: female + unisex ì¶”ì²œ
                if gender == "neutral":
                    filtered_scores.append(item)
                elif gender == "male" and style_gender in ["male", "unisex"]:
                    filtered_scores.append(item)
                elif gender == "female" and style_gender in ["female", "unisex"]:
                    filtered_scores.append(item)

            logger.info(
                f"[GENDER] í•„í„°ë§ ì™„ë£Œ: {len(all_scores)}ê°œ â†’ {len(filtered_scores)}ê°œ "
                f"(ì œì™¸: {len(all_scores) - len(filtered_scores)}ê°œ)"
            )
            all_scores = filtered_scores
        else:
            if not gender:
                logger.warning("[GENDER] ì„±ë³„ í•„í„°ë§ ë¹„í™œì„±í™” - gender íŒŒë¼ë¯¸í„°ê°€ ë¹„ì–´ìˆìŒ!")
            elif not self.gender_metadata:
                logger.warning("[GENDER] ì„±ë³„ í•„í„°ë§ ë¹„í™œì„±í™” - metadataê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ!")
            else:
                logger.info("[GENDER] ì„±ë³„ í•„í„°ë§ ë¹„í™œì„±í™”")

        # ìœ ì‚¬ë„ ê¸°ë°˜ ë‹¤ì–‘ì„± í•„í„°ë§ (65% ì´ìƒ ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ ì œì™¸)
        top_k_recommendations = []
        similarity_threshold = 0.65
        max_candidates = min(100, len(all_scores))  # ìƒìœ„ 100ê°œê¹Œì§€ íƒìƒ‰

        logger.info(f"[DIVERSITY] ë‹¤ì–‘ì„± í•„í„°ë§ ì‹œì‘ (threshold={similarity_threshold})")

        for candidate in all_scores[:max_candidates]:
            if len(top_k_recommendations) >= k:
                break

            candidate_style = candidate['hairstyle']

            # ì´ë¯¸ ì„ íƒëœ ìŠ¤íƒ€ì¼ê³¼ ìœ ì‚¬ë„ ì²´í¬
            is_duplicate = False
            for selected in top_k_recommendations:
                selected_style = selected['hairstyle']
                if self._is_similar_style(candidate_style, selected_style, similarity_threshold):
                    logger.debug(
                        f"[DIVERSITY] ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ ì œì™¸: '{candidate_style}' "
                        f"(ìœ ì‚¬: '{selected_style}')"
                    )
                    is_duplicate = True
                    break

            if not is_duplicate:
                top_k_recommendations.append(candidate)
                logger.info(
                    f"[DIVERSITY] ì„ íƒ ({len(top_k_recommendations)}/{k}): "
                    f"'{candidate_style}' (ì ìˆ˜: {candidate['score']:.2f})"
                )

        # kê°œë¥¼ ì±„ìš°ì§€ ëª»í•œ ê²½ìš° ê²½ê³ 
        if len(top_k_recommendations) < k:
            logger.warning(
                f"[DIVERSITY] ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ {k}ê°œë¥¼ ì°¾ì§€ ëª»í•¨ "
                f"(ì‹¤ì œ: {len(top_k_recommendations)}ê°œ). "
                f"thresholdë¥¼ ë‚®ì¶”ê±°ë‚˜ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”."
            )

        # ì ìˆ˜ ìŠ¤ì¼€ì¼ë§ ì²˜ë¦¬
        # - v5 ì •ê·œí™” ëª¨ë¸: ì´ë¯¸ 10~95 ë²”ìœ„ì´ë¯€ë¡œ ì›ë³¸ ì ìˆ˜ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        # - v4 ê¸°ì¡´ ëª¨ë¸: Min-Max ì •ê·œí™”ë¡œ 75~95 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§
        if self.is_normalized_model:
            # v5 ì •ê·œí™” ëª¨ë¸: ì›ë³¸ ì ìˆ˜ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì´ë¯¸ 10~95 ë²”ìœ„)
            logger.info(f"[SCORE] v5 ì •ê·œí™” ëª¨ë¸ - ì›ë³¸ ì ìˆ˜ ì‚¬ìš©")
            for rec in top_k_recommendations:
                rec['score'] = round(rec['original_score'], 2)
        elif len(top_k_recommendations) >= 2:
            # v4 ê¸°ì¡´ ëª¨ë¸: Min-Max ì •ê·œí™”ë¥¼ ì‚¬ìš©í•œ ì ìˆ˜ ìŠ¤ì¼€ì¼ë§
            # Top-K ë‚´ì—ì„œ ì ìˆ˜ë¥¼ 75~95ì  ë²”ìœ„ë¡œ ì •ê·œí™”
            raw_scores = [rec['original_score'] for rec in top_k_recommendations]
            min_raw = min(raw_scores)
            max_raw = max(raw_scores)

            if max_raw > min_raw:
                target_min, target_max = 75.0, 95.0

                logger.info(f"[SCORE NORM] Raw scores: {raw_scores}")
                logger.info(f"[SCORE NORM] Raw range: {min_raw:.2f} ~ {max_raw:.2f}")

                for rec in top_k_recommendations:
                    raw = rec['original_score']
                    normalized = (raw - min_raw) / (max_raw - min_raw) * (target_max - target_min) + target_min
                    rec['score'] = round(normalized, 2)

                logger.info(f"[SCORE NORM] Normalized scores: {[r['score'] for r in top_k_recommendations]}")
            else:
                for i, rec in enumerate(top_k_recommendations):
                    rec['score'] = round(95.0 - i * 3, 2)
                logger.info(f"[SCORE NORM] Same scores - using fallback: {[r['score'] for r in top_k_recommendations]}")
        elif len(top_k_recommendations) == 1:
            top_k_recommendations[0]['score'] = 90.0
            logger.info("[SCORE NORM] Single recommendation - set to 90.0")

        # ë””ë²„ê·¸: Top-K ì ìˆ˜ ë¶„í¬
        if top_k_recommendations:
            scores_list = [r['score'] for r in top_k_recommendations]
            logger.info(f"[ML DEBUG] Top-{k} final scores: {scores_list}")
            logger.info(f"[ML DEBUG] Score range: {min(scores_list):.2f} ~ {max(scores_list):.2f}")

        logger.info(
            f"[ML RESULT] ML ì¶”ì²œ ì™„ë£Œ: {[r['hairstyle'] for r in top_k_recommendations]}"
        )

        return top_k_recommendations

    def batch_predict(
        self,
        face_shape: str,
        skin_tone: str,
        hairstyles: List[str]
    ) -> Dict[str, float]:
        """
        ì—¬ëŸ¬ í—¤ì–´ìŠ¤íƒ€ì¼ì˜ ì ìˆ˜ë¥¼ í•œ ë²ˆì— ì˜ˆì¸¡ (ë„ì–´ì“°ê¸° ì •ê·œí™” ì ìš©)

        Args:
            face_shape: ì–¼êµ´í˜•
            skin_tone: í”¼ë¶€í†¤
            hairstyles: í—¤ì–´ìŠ¤íƒ€ì¼ ë¦¬ìŠ¤íŠ¸

        Returns:
            {í—¤ì–´ìŠ¤íƒ€ì¼: ì ìˆ˜} ë”•ì…”ë„ˆë¦¬
        """
        results = {}
        
        # 1. ì„ë² ë”© ìˆ˜ì§‘ (DB or ì‹¤ì‹œê°„)
        valid_styles = []
        batch_embeddings = []
        
        for style in hairstyles:
            normalized = normalize_style_name(style)
            embedding = self._get_style_embedding(normalized)
            
            if embedding is None:
                # ì›ë³¸ ì´ë¦„ìœ¼ë¡œë„ ì‹œë„
                embedding = self._get_style_embedding(style)
            
            if embedding is not None:
                valid_styles.append(style)
                batch_embeddings.append(embedding)
            else:
                logger.warning(f"ì„ë² ë”© ìƒì„± ë¶ˆê°€ë¡œ ê±´ë„ˆëœ€: {style}")

        if not valid_styles:
            logger.warning("ìœ íš¨í•œ í—¤ì–´ìŠ¤íƒ€ì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return results

        # 2. ì–¼êµ´í˜•ê³¼ í”¼ë¶€í†¤ íŠ¹ì§• ë²¡í„° ìƒì„±
        face_vec = self._encode_face_shape(face_shape)  # (4,)
        tone_vec = self._encode_skin_tone(skin_tone)    # (4,)

        batch_embeddings = np.array(batch_embeddings, dtype=np.float32)

        # 3. ë°°ì¹˜ ì¶”ë¡  - 3ê°œì˜ ê°œë³„ í…ì„œë¡œ ì „ë‹¬
        with torch.no_grad():
            batch_size = len(valid_styles)
            face_batch = np.tile(face_vec, (batch_size, 1))
            skin_batch = np.tile(tone_vec, (batch_size, 1))

            face_tensor = torch.FloatTensor(face_batch).to(self.device)
            skin_tensor = torch.FloatTensor(skin_batch).to(self.device)
            style_tensor = torch.FloatTensor(batch_embeddings).to(self.device)

            scores_tensor = self.model(face_tensor, skin_tensor, style_tensor)
            scores = scores_tensor.cpu().numpy().flatten()

        # ì •ê·œí™” ëª¨ë¸(v5)ì¸ ê²½ìš° ì—­ë³€í™˜ ì ìš© (0~1 â†’ 10~95)
        if self.is_normalized_model:
            scores = scores * LABEL_RANGE + LABEL_MIN

        # 4. ê²°ê³¼ ì €ì¥
        for style, score in zip(valid_styles, scores):
            if self.is_normalized_model:
                score_clipped = max(LABEL_MIN, min(LABEL_MAX, float(score)))
            else:
                score_clipped = max(0.0, min(100.0, float(score)))
            results[style] = round(score_clipped, 2)

        return results


# ========== ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ (ì „ì—­ ì‚¬ìš©) ==========
_recommender_instance = None


def get_ml_recommender() -> MLHairstyleRecommender:
    """
    ML ì¶”ì²œê¸° ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°

    Returns:
        MLHairstyleRecommender ì¸ìŠ¤í„´ìŠ¤
    """
    global _recommender_instance

    if _recommender_instance is None:
        logger.info("ğŸ”§ ML ì¶”ì²œê¸° ì´ˆê¸°í™” ì¤‘...")
        _recommender_instance = MLHairstyleRecommender()
        logger.info("âœ… ML ì¶”ì²œê¸° ì¤€ë¹„ ì™„ë£Œ")

    return _recommender_instance


# ========== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (analyze.py í˜¸í™˜) ==========

# Confidence threshold ìƒìˆ˜
CONFIDENCE_THRESHOLD_VERY_HIGH = 0.90
CONFIDENCE_THRESHOLD_HIGH = 0.85
CONFIDENCE_THRESHOLD_MEDIUM = 0.75


def predict_ml_score(face_shape: str, skin_tone: str, hairstyle: str) -> float:
    """
    ML ëª¨ë¸ë¡œ íŠ¹ì • í—¤ì–´ìŠ¤íƒ€ì¼ì˜ ì¶”ì²œ ì ìˆ˜ ì˜ˆì¸¡

    Args:
        face_shape: ì–¼êµ´í˜• (ì˜ˆ: "ê³„ë€í˜•")
        skin_tone: í”¼ë¶€í†¤ (ì˜ˆ: "ë´„ì›œ")
        hairstyle: í—¤ì–´ìŠ¤íƒ€ì¼ëª… (ì˜ˆ: "ì‹œìŠ¤ë£¨ë±… ë‹¨ë°œ")

    Returns:
        ì¶”ì²œ ì ìˆ˜ (0.0 ~ 100.0)
    """
    try:
        recommender = get_ml_recommender()
        score = recommender.predict_score(face_shape, skin_tone, hairstyle)
        return score
    except Exception as e:
        logger.error(f"ML ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
        return 85.0  # ê¸°ë³¸ê°’


def get_confidence_level(score: float) -> str:
    """
    ì ìˆ˜ë¥¼ ì‹ ë¢°ë„ ë ˆë²¨ ë¬¸ìì—´ë¡œ ë³€í™˜

    Args:
        score: ì‹ ë¢°ë„ ì ìˆ˜ (0.0 ~ 1.0 ë˜ëŠ” 0.0 ~ 100.0)

    Returns:
        ì‹ ë¢°ë„ ë ˆë²¨ ë¬¸ìì—´ ("ë§¤ìš° ë†’ìŒ", "ë†’ìŒ", "ë³´í†µ", "ë‚®ìŒ")
    """
    # 0~100 ë²”ìœ„ ì ìˆ˜ë¥¼ 0~1ë¡œ ì •ê·œí™”
    if score > 1.0:
        score = score / 100.0

    if score >= CONFIDENCE_THRESHOLD_VERY_HIGH:
        return "ë§¤ìš° ë†’ìŒ"
    elif score >= CONFIDENCE_THRESHOLD_HIGH:
        return "ë†’ìŒ"
    elif score >= CONFIDENCE_THRESHOLD_MEDIUM:
        return "ë³´í†µ"
    else:
        return "ë‚®ìŒ"
