"""
ML ê¸°ë°˜ ë…ë¦½í˜• í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œê¸°

MediaPipe ë¶„ì„ ê²°ê³¼ (ì–¼êµ´í˜• + í”¼ë¶€í†¤)ë¡œ í•™ìŠµëœ ML ëª¨ë¸ì„ ì‚¬ìš©í•´
ëª¨ë“  í—¤ì–´ìŠ¤íƒ€ì¼ì˜ ì¶”ì²œ ì ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ê³  Top-Kë¥¼ ë°˜í™˜

Author: HairMe ML Team
Date: 2025-11-08
Version: 1.1.0 (Real-time Embedding Support)
"""

import numpy as np
import torch
import torch.nn as nn
from pathlib import Path
from typing import List, Dict, Tuple, TYPE_CHECKING
import logging
import sys
from difflib import SequenceMatcher

# TYPE_CHECKINGì„ ì‚¬ìš©í•˜ì—¬ ëŸ°íƒ€ì„ì—ëŠ” importí•˜ì§€ ì•ŠìŒ
if TYPE_CHECKING:
    from sentence_transformers import SentenceTransformer

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from utils.style_preprocessor import normalize_style_name

logger = logging.getLogger(__name__)


class AttentionLayer(nn.Module):
    """Multi-head self-attention layer"""

    def __init__(self, embed_dim: int, num_heads: int = 8, dropout: float = 0.1):
        super().__init__()
        self.attention = nn.MultiheadAttention(
            embed_dim=embed_dim,
            num_heads=num_heads,
            dropout=dropout,
            batch_first=True
        )
        self.norm = nn.LayerNorm(embed_dim)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Self-attention
        attn_out, _ = self.attention(x, x, x)
        # Residual connection + layer norm
        x = self.norm(x + self.dropout(attn_out))
        return x


class RecommendationModel(nn.Module):
    """
    ì—°ì†í˜• ë³€ìˆ˜ ê¸°ë°˜ ì¶”ì²œ ëª¨ë¸ v4

    ì…ë ¥:
    - face_features: [batch, 6] - MediaPipe ì–¼êµ´ ì¸¡ì •ê°’
    - skin_features: [batch, 2] - MediaPipe í”¼ë¶€ ì¸¡ì •ê°’
    - style_emb: [batch, 384] - í—¤ì–´ìŠ¤íƒ€ì¼ ì„ë² ë”©
    """

    def __init__(
        self,
        face_feat_dim: int = 6,
        skin_feat_dim: int = 2,
        style_embed_dim: int = 384,
        use_attention: bool = True,
        dropout_rate: float = 0.3
    ):
        super().__init__()

        self.face_feat_dim = face_feat_dim
        self.skin_feat_dim = skin_feat_dim
        self.style_embed_dim = style_embed_dim

        # Input projection layers
        self.face_projection = nn.Sequential(
            nn.Linear(face_feat_dim, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(dropout_rate * 0.5)
        )

        self.skin_projection = nn.Sequential(
            nn.Linear(skin_feat_dim, 32),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.Dropout(dropout_rate * 0.5)
        )

        # Total dimension after projection
        self.total_dim = 64 + 32 + style_embed_dim  # 96 + 384 = 480

        # Attention layer
        self.use_attention = use_attention
        if use_attention:
            self.attention = AttentionLayer(
                embed_dim=self.total_dim,
                num_heads=8,
                dropout=0.1
            )

        # Feature fusion network
        self.fc1 = nn.Linear(self.total_dim, 256)
        self.bn1 = nn.BatchNorm1d(256)
        self.dropout1 = nn.Dropout(dropout_rate)

        self.fc2 = nn.Linear(256, 128)
        self.bn2 = nn.BatchNorm1d(128)
        self.dropout2 = nn.Dropout(dropout_rate * 0.7)

        # Residual connection
        self.residual_proj = nn.Linear(self.total_dim, 128)

        self.fc3 = nn.Linear(128, 64)
        self.bn3 = nn.BatchNorm1d(64)
        self.dropout3 = nn.Dropout(dropout_rate * 0.5)

        self.fc4 = nn.Linear(64, 32)
        self.fc_out = nn.Linear(32, 1)

    def forward(
        self,
        face_features: torch.Tensor,
        skin_features: torch.Tensor,
        style_emb: torch.Tensor
    ) -> torch.Tensor:
        """Forward pass"""
        # Project features
        face_proj = self.face_projection(face_features)
        skin_proj = self.skin_projection(skin_features)

        # Concatenate all features
        x = torch.cat([face_proj, skin_proj, style_emb], dim=1)

        # Apply attention if enabled
        if self.use_attention:
            x_att = x.unsqueeze(1)
            x_att = self.attention(x_att)
            x = x_att.squeeze(1)

        # Store for residual
        residual = self.residual_proj(x)

        # Main network
        x = self.fc1(x)
        x = self.bn1(x)
        x = torch.relu(x)
        x = self.dropout1(x)

        x = self.fc2(x)
        x = self.bn2(x)
        x = torch.relu(x)
        x = self.dropout2(x)

        # Add residual connection
        x = x + residual

        x = self.fc3(x)
        x = self.bn3(x)
        x = torch.relu(x)
        x = self.dropout3(x)

        x = self.fc4(x)
        x = torch.relu(x)

        x = self.fc_out(x)

        # ìŠ¤ì¼€ì¼ë§ ì ìš© (í•™ìŠµ ì‹œ 30~90ì  ë²”ìœ„)
        # í´ë¨í•‘ ì œê±° - ì›ë³¸ ì ìˆ˜ë¥¼ ìœ ì§€í•˜ì—¬ Top-K ë‚´ì—ì„œ Min-Max ì •ê·œí™” ê°€ëŠ¥í•˜ê²Œ í•¨
        x = (x - 29.0) * 7.5 + 60.0
        # ì°¸ê³ : í´ë¨í•‘ì€ recommend_top_kì—ì„œ Min-Max ì •ê·œí™” í›„ ì ìš©

        return x.squeeze(-1)


class MLHairstyleRecommender:
    """ML ê¸°ë°˜ í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œê¸°"""

    # MediaPipeì™€ í˜¸í™˜ë˜ëŠ” ì¹´í…Œê³ ë¦¬
    FACE_SHAPES = ["ê°ì§„í˜•", "ë‘¥ê·¼í˜•", "ê¸´í˜•", "ê³„ë€í˜•"]
    SKIN_TONES = ["ê²¨ìš¸ì¿¨", "ê°€ì„ì›œ", "ë´„ì›œ", "ì—¬ë¦„ì¿¨"]

    def __init__(
        self,
        model_path: str = "models/hairstyle_recommender_v4_no_leakage.pt",
        embeddings_path: str = "data_source/style_embeddings.npz",
        gender_metadata_path: str = "data_source/hairstyle_gender.json"
    ):
        """
        ì´ˆê¸°í™”

        Args:
            model_path: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
            embeddings_path: í—¤ì–´ìŠ¤íƒ€ì¼ ì„ë² ë”© ê²½ë¡œ
            gender_metadata_path: í—¤ì–´ìŠ¤íƒ€ì¼ ì„±ë³„ ë©”íƒ€ë°ì´í„° ê²½ë¡œ
        """
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        # 1. ëª¨ë¸ ë¡œë“œ
        logger.info(f"ğŸ“‚ ML ëª¨ë¸ ë¡œë”©: {model_path}")
        self.model = RecommendationModel()

        # ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ìœ¼ë¡œ ì €ì¥ëœ ê²½ìš° ì²˜ë¦¬
        try:
            checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                # ì²´í¬í¬ì¸íŠ¸ í˜•ì‹
                self.model.load_state_dict(checkpoint['model_state_dict'])
                logger.info(f"âœ… ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (epoch: {checkpoint.get('epoch', 'N/A')})")
            else:
                # ì¼ë°˜ state_dict í˜•ì‹
                self.model.load_state_dict(checkpoint)
                logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise

        self.model.to(self.device)
        self.model.eval()  # ì¶”ë¡  ëª¨ë“œ
        logger.info(f"âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ (ë””ë°”ì´ìŠ¤: {self.device})")

        # 2. í—¤ì–´ìŠ¤íƒ€ì¼ ì„ë² ë”© ë¡œë“œ
        logger.info(f"ğŸ“‚ ì„ë² ë”© ë¡œë”©: {embeddings_path}")
        try:
            data = np.load(embeddings_path, allow_pickle=False)
            self.styles = data['styles'].tolist()  # í—¤ì–´ìŠ¤íƒ€ì¼ëª… ë¦¬ìŠ¤íŠ¸
            self.embeddings = data['embeddings']  # (N, 384) ì„ë² ë”©
            logger.info(f"âœ… ì„ë² ë”© ë¡œë“œ ì™„ë£Œ: {len(self.styles)}ê°œ ìŠ¤íƒ€ì¼")
        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise

        # ìŠ¤íƒ€ì¼ëª… -> ì¸ë±ìŠ¤ ë§¤í•‘
        self.style_to_idx = {style: idx for idx, style in enumerate(self.styles)}

        # 3. ì„±ë³„ ë©”íƒ€ë°ì´í„° ë¡œë“œ (NEW)
        logger.info(f"ğŸ“‚ ì„±ë³„ ë©”íƒ€ë°ì´í„° ë¡œë”©: {gender_metadata_path}")
        try:
            import json
            import os
            if os.path.exists(gender_metadata_path):
                with open(gender_metadata_path, 'r', encoding='utf-8') as f:
                    self.gender_metadata = json.load(f)
                logger.info(f"âœ… ì„±ë³„ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.gender_metadata)}ê°œ ìŠ¤íƒ€ì¼")
            else:
                logger.warning(f"âš ï¸ ì„±ë³„ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì—†ìŒ - ì„±ë³„ í•„í„°ë§ ë¹„í™œì„±í™”")
                self.gender_metadata = {}
        except Exception as e:
            logger.error(f"âŒ ì„±ë³„ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            self.gender_metadata = {}

        # 4. ì‹¤ì‹œê°„ ì„ë² ë”©ìš© SentenceTransformer ë¡œë“œ (Lambdaì—ì„œëŠ” ìŠ¤í‚µ)
        import os
        is_lambda = os.environ.get('AWS_LAMBDA_FUNCTION_NAME') is not None

        if not is_lambda:
            logger.info("ğŸ”„ ì‹¤ì‹œê°„ ì„ë² ë”© ëª¨ë¸ ë¡œë”© (paraphrase-multilingual-MiniLM-L12-v2)...")
            try:
                from sentence_transformers import SentenceTransformer
                self.sentence_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
                logger.info("âœ… ì‹¤ì‹œê°„ ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ ì‹¤ì‹œê°„ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                self.sentence_model = None
        else:
            logger.info("ğŸ”§ Lambda í™˜ê²½ - ì‹¤ì‹œê°„ ì„ë² ë”© ëª¨ë¸ ìŠ¤í‚µ")
            self.sentence_model = None

    def _encode_face_shape(self, face_shape: str) -> np.ndarray:
        """ì–¼êµ´í˜•ì„ one-hot ì¸ì½”ë”© (6ì°¨ì› - ëª¨ë¸ê³¼ ì¼ì¹˜)"""
        vec = np.zeros(6, dtype=np.float32)

        # í•˜íŠ¸í˜•ì€ ê³„ë€í˜•ìœ¼ë¡œ ë§¤í•‘
        if face_shape == "í•˜íŠ¸í˜•":
            face_shape = "ê³„ë€í˜•"
            logger.debug("í•˜íŠ¸í˜•ì„ ê³„ë€í˜•ìœ¼ë¡œ ë§¤í•‘")

        # ê¸°ë³¸ 4ê°€ì§€ ì–¼êµ´í˜•ì— ëŒ€í•œ one-hot ì¸ì½”ë”©
        if face_shape in self.FACE_SHAPES:
            idx = self.FACE_SHAPES.index(face_shape)
            vec[idx] = 1.0
        else:
            logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ì–¼êµ´í˜•: {face_shape}, ê³„ë€í˜•ìœ¼ë¡œ ê¸°ë³¸ê°’ ì‚¬ìš©")
            vec[3] = 1.0  # ê³„ë€í˜•

        # ì¶”ê°€ íŠ¹ì§• ì°¨ì› (ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©ë¨)
        vec[4] = 0.5  # ì¤‘ê°„ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
        vec[5] = 0.5  # ì¤‘ê°„ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”

        return vec

    def _encode_skin_tone(self, skin_tone: str) -> np.ndarray:
        """í”¼ë¶€í†¤ì„ one-hot ì¸ì½”ë”© (2ì°¨ì› - ëª¨ë¸ê³¼ ì¼ì¹˜)"""
        vec = np.zeros(2, dtype=np.float32)

        # ë´„/ê°€ì„ -> ì›œí†¤(0), ì—¬ë¦„/ê²¨ìš¸ -> ì¿¨í†¤(1)
        if skin_tone in ["ë´„ì›œ", "ê°€ì„ì›œ"]:
            vec[0] = 1.0  # ì›œí†¤
        elif skin_tone in ["ì—¬ë¦„ì¿¨", "ê²¨ìš¸ì¿¨"]:
            vec[1] = 1.0  # ì¿¨í†¤
        else:
            logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” í”¼ë¶€í†¤: {skin_tone}, ì›œí†¤ìœ¼ë¡œ ê¸°ë³¸ê°’ ì‚¬ìš©")
            vec[0] = 1.0  # ì›œí†¤

        return vec

    def _is_similar_style(self, style_a: str, style_b: str, threshold: float = 0.65) -> bool:
        """
        ë‘ ìŠ¤íƒ€ì¼ëª…ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0~1)

        Args:
            style_a: ì²« ë²ˆì§¸ ìŠ¤íƒ€ì¼ëª…
            style_b: ë‘ ë²ˆì§¸ ìŠ¤íƒ€ì¼ëª…
            threshold: ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸ 0.65 = 65%)

        Returns:
            threshold ì´ìƒì´ë©´ True (ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼)

        Examples:
            - "ê°€ë¥´ë§ˆ ìŠ¤íƒ€ì¼ (5:5 ë˜ëŠ” 6:4)" vs "ê°€ë¥´ë§ˆ ìŠ¤íƒ€ì¼ (6:4 ë˜ëŠ” 7:3)" â†’ 0.74 â†’ True (ìœ ì‚¬í•¨)
            - "ê°€ë¥´ë§ˆ ìŠ¤íƒ€ì¼" vs "ê°€ì¼ ì»·" â†’ 0.25 â†’ False (ë‹¤ë¦„)
        """
        ratio = SequenceMatcher(None, style_a, style_b).ratio()
        return ratio >= threshold

    def _get_style_embedding(self, style_name: str) -> np.ndarray:
        """
        ìŠ¤íƒ€ì¼ ì„ë² ë”© ê°€ì ¸ì˜¤ê¸° (DB ì¡°íšŒ ë˜ëŠ” ì‹¤ì‹œê°„ ìƒì„±)

        Args:
            style_name: í—¤ì–´ìŠ¤íƒ€ì¼ëª… (ì •ê·œí™”ëœ ì´ë¦„ ê¶Œì¥)

        Returns:
            ì„ë² ë”© ë²¡í„° (384,) ë˜ëŠ” None
        """
        # 1. DB ì¡°íšŒ (Fast Path)
        if style_name in self.style_to_idx:
            idx = self.style_to_idx[style_name]
            return self.embeddings[idx]

        # 2. ì‹¤ì‹œê°„ ìƒì„± (Slow Path)
        if self.sentence_model:
            logger.info(f"ğŸ†• ìƒˆë¡œìš´ ìŠ¤íƒ€ì¼ ë°œê²¬: '{style_name}' -> ì‹¤ì‹œê°„ ì„ë² ë”© ìƒì„±")
            try:
                embedding = self.sentence_model.encode(style_name)
                return embedding
            except Exception as e:
                logger.error(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ ({style_name}): {str(e)}")
                return None

        return None

    def predict_score(
        self,
        face_shape: str,
        skin_tone: str,
        hairstyle: str
    ) -> float:
        """
        íŠ¹ì • í—¤ì–´ìŠ¤íƒ€ì¼ì˜ ì¶”ì²œ ì ìˆ˜ ì˜ˆì¸¡ (ë„ì–´ì“°ê¸° ì •ê·œí™” ì ìš©)

        Args:
            face_shape: ì–¼êµ´í˜•
            skin_tone: í”¼ë¶€í†¤
            hairstyle: í—¤ì–´ìŠ¤íƒ€ì¼ëª…

        Returns:
            ì¶”ì²œ ì ìˆ˜ (0-100)
        """
        # ë„ì–´ì“°ê¸° ì •ê·œí™” ì ìš©
        normalized_style = normalize_style_name(hairstyle)

        # ì„ë² ë”© ê°€ì ¸ì˜¤ê¸° (DB or ì‹¤ì‹œê°„)
        style_embedding = self._get_style_embedding(normalized_style)

        if style_embedding is None:
            # ì›ë³¸ ì´ë¦„ìœ¼ë¡œë„ ì‹œë„
            style_embedding = self._get_style_embedding(hairstyle)
            
            if style_embedding is None:
                logger.warning(f"ì„ë² ë”© ìƒì„± ë¶ˆê°€: '{hairstyle}'")
                return 0.0

        # ê°œë³„ íŠ¹ì§• ë²¡í„° ìƒì„±
        face_vec = self._encode_face_shape(face_shape)  # (4,)
        tone_vec = self._encode_skin_tone(skin_tone)    # (4,)

        # ëª¨ë¸ ì¶”ë¡  - 3ê°œì˜ ê°œë³„ í…ì„œë¡œ ì „ë‹¬
        with torch.no_grad():
            face_tensor = torch.FloatTensor(face_vec).unsqueeze(0).to(self.device)
            skin_tensor = torch.FloatTensor(tone_vec).unsqueeze(0).to(self.device)
            style_tensor = torch.FloatTensor(style_embedding).unsqueeze(0).to(self.device)

            score_tensor = self.model(face_tensor, skin_tensor, style_tensor)
            score = score_tensor.cpu().item()

        # 0-100 ë²”ìœ„ë¡œ í´ë¦¬í•‘
        score = max(0.0, min(100.0, score))

        return round(score, 2)

    def recommend_top_k(
        self,
        face_shape: str = None,
        skin_tone: str = None,
        k: int = 3,
        face_features: List[float] = None,
        skin_features: List[float] = None,
        gender: str = None
    ) -> List[Dict[str, any]]:
        """
        Top-K í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ (ì„±ë³„ í•„í„°ë§ ì ìš©)

        Args:
            face_shape: ì–¼êµ´í˜• (ì˜ˆ: "ê³„ë€í˜•") - DEPRECATED, í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
            skin_tone: í”¼ë¶€í†¤ (ì˜ˆ: "ë´„ì›œ") - DEPRECATED, í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
            k: ì¶”ì²œ ê°œìˆ˜
            face_features: MediaPipe ì–¼êµ´ ì¸¡ì •ê°’ [face_ratio, forehead_width, cheekbone_width, jaw_width, forehead_ratio, jaw_ratio] (6ì°¨ì›)
            skin_features: MediaPipe í”¼ë¶€ ì¸¡ì •ê°’ [ITA_value, hue_value] (2ì°¨ì›)
            gender: ì„±ë³„ ("male", "female", "neutral") - MediaPipeë¡œ ì¶”ë¡ ëœ ê°’

        Returns:
            ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ [{"hairstyle": "...", "score": 85.3}, ...]
        """
        # ì‹¤ì œ ì¸¡ì •ê°’ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ë¼ë²¨ ê¸°ë°˜ ì¸ì½”ë”© (í•˜ìœ„ í˜¸í™˜ì„±)
        if face_features is not None and skin_features is not None:
            logger.info(f"[ML DEBUG] ML ì¶”ì²œ ì‹œì‘ (ì‹¤ì œ ì¸¡ì •ê°’ ì‚¬ìš©) - Top-{k}")
            logger.info(f"[ML DEBUG] Face features: {face_features}")
            logger.info(f"[ML DEBUG] Skin features: {skin_features}")

            # NumPy ë°°ì—´ë¡œ ë³€í™˜
            face_vec = np.array(face_features, dtype=np.float32)
            tone_vec = np.array(skin_features, dtype=np.float32)

            # ì°¨ì› ê²€ì¦
            if face_vec.shape[0] != 6:
                raise ValueError(f"face_featuresëŠ” 6ì°¨ì›ì´ì–´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {face_vec.shape[0]}")
            if tone_vec.shape[0] != 2:
                raise ValueError(f"skin_featuresëŠ” 2ì°¨ì›ì´ì–´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {tone_vec.shape[0]}")
        else:
            # í•˜ìœ„ í˜¸í™˜ì„±: ë¼ë²¨ ê¸°ë°˜ ì¸ì½”ë”©
            logger.warning(f"[ML DEPRECATED] ë¼ë²¨ ê¸°ë°˜ ì¸ì½”ë”© ì‚¬ìš©: {face_shape} + {skin_tone}")
            logger.warning("[ML DEPRECATED] ì‹¤ì œ ì¸¡ì •ê°’(face_features, skin_features)ì„ ì „ë‹¬í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")

            if face_shape is None or skin_tone is None:
                raise ValueError("face_featuresì™€ skin_featuresê°€ ì—†ìœ¼ë©´ face_shapeê³¼ skin_toneì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")

            face_vec = self._encode_face_shape(face_shape)  # (6,)
            tone_vec = self._encode_skin_tone(skin_tone)    # (2,)

        logger.info(f"[ML DEBUG] Face vector: {face_vec.tolist()}")
        logger.info(f"[ML DEBUG] Skin vector: {tone_vec.tolist()}")

        # ëª¨ë“  í—¤ì–´ìŠ¤íƒ€ì¼ì— ëŒ€í•´ ì ìˆ˜ ì˜ˆì¸¡
        all_scores = []

        # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ìµœì í™”
        batch_size = 64
        num_styles = len(self.styles)

        for i in range(0, num_styles, batch_size):
            batch_end = min(i + batch_size, num_styles)
            batch_size_actual = batch_end - i
            batch_embeddings = self.embeddings[i:batch_end]

            # ë°°ì¹˜ ì¶”ë¡  - 3ê°œì˜ ê°œë³„ í…ì„œë¡œ ì „ë‹¬
            with torch.no_grad():
                # ì–¼êµ´í˜•ê³¼ í”¼ë¶€í†¤ì€ ë°°ì¹˜ í¬ê¸°ë§Œí¼ ë³µì œ
                face_batch = np.tile(face_vec, (batch_size_actual, 1))
                skin_batch = np.tile(tone_vec, (batch_size_actual, 1))

                face_tensor = torch.FloatTensor(face_batch).to(self.device)
                skin_tensor = torch.FloatTensor(skin_batch).to(self.device)
                style_tensor = torch.FloatTensor(batch_embeddings).to(self.device)

                # ì²« ë²ˆì§¸ ë°°ì¹˜ì—ì„œë§Œ ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
                if i == 0:
                    logger.info(f"[ML DEBUG] First batch embedding shape: {batch_embeddings.shape}")
                    logger.info(f"[ML DEBUG] First style embedding std: {batch_embeddings.std():.6f}")
                    logger.info(f"[ML DEBUG] First 3 styles: {self.styles[i:i+3]}")

                scores_tensor = self.model(face_tensor, skin_tensor, style_tensor)
                scores = scores_tensor.cpu().numpy().flatten()

                # ì²« ë²ˆì§¸ ë°°ì¹˜ì—ì„œë§Œ ì ìˆ˜ ë””ë²„ê·¸
                if i == 0:
                    logger.info(f"[ML DEBUG] First batch scores: {scores[:5].tolist()}")
                    logger.info(f"[ML DEBUG] Scores std: {scores.std():.6f}")

            # ê²°ê³¼ ì €ì¥ (ì›ë³¸ ì ìˆ˜ ê·¸ëŒ€ë¡œ ì €ì¥)
            for j, score in enumerate(scores):
                style_idx = i + j
                all_scores.append({
                    "hairstyle_id": style_idx,  # âœ… DB ID ì¶”ê°€
                    "hairstyle": self.styles[style_idx],
                    "score": float(score),  # ì›ë³¸ ì ìˆ˜ ê·¸ëŒ€ë¡œ ì €ì¥
                    "original_score": float(score)  # í”¼ë“œë°±ìš© ì›ë³¸ ì ìˆ˜ ë³´ì¡´
                })

        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        all_scores.sort(key=lambda x: x['score'], reverse=True)

        # ì„±ë³„ í•„í„°ë§ (NEW)
        if gender and self.gender_metadata:
            logger.info(f"[GENDER] ì„±ë³„ í•„í„°ë§ ì‹œì‘ (gender={gender})")
            filtered_scores = []
            for item in all_scores:
                style_name = item['hairstyle']
                style_gender = self.gender_metadata.get(style_name, "unisex")

                # ì„±ë³„ ë§¤ì¹­ ë¡œì§:
                # - neutral (ì• ë§¤í•œ ê²½ìš°): ëª¨ë“  ìŠ¤íƒ€ì¼ ì¶”ì²œ
                # - male: male + unisex ì¶”ì²œ
                # - female: female + unisex ì¶”ì²œ
                if gender == "neutral":
                    filtered_scores.append(item)
                elif gender == "male" and style_gender in ["male", "unisex"]:
                    filtered_scores.append(item)
                elif gender == "female" and style_gender in ["female", "unisex"]:
                    filtered_scores.append(item)

            logger.info(
                f"[GENDER] í•„í„°ë§ ì™„ë£Œ: {len(all_scores)}ê°œ â†’ {len(filtered_scores)}ê°œ "
                f"(ì œì™¸: {len(all_scores) - len(filtered_scores)}ê°œ)"
            )
            all_scores = filtered_scores
        else:
            logger.info("[GENDER] ì„±ë³„ í•„í„°ë§ ë¹„í™œì„±í™” (gender ë¯¸ì œê³µ ë˜ëŠ” ë©”íƒ€ë°ì´í„° ì—†ìŒ)")

        # ìœ ì‚¬ë„ ê¸°ë°˜ ë‹¤ì–‘ì„± í•„í„°ë§ (65% ì´ìƒ ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ ì œì™¸)
        top_k_recommendations = []
        similarity_threshold = 0.65
        max_candidates = min(100, len(all_scores))  # ìƒìœ„ 100ê°œê¹Œì§€ íƒìƒ‰

        logger.info(f"[DIVERSITY] ë‹¤ì–‘ì„± í•„í„°ë§ ì‹œì‘ (threshold={similarity_threshold})")

        for candidate in all_scores[:max_candidates]:
            if len(top_k_recommendations) >= k:
                break

            candidate_style = candidate['hairstyle']

            # ì´ë¯¸ ì„ íƒëœ ìŠ¤íƒ€ì¼ê³¼ ìœ ì‚¬ë„ ì²´í¬
            is_duplicate = False
            for selected in top_k_recommendations:
                selected_style = selected['hairstyle']
                if self._is_similar_style(candidate_style, selected_style, similarity_threshold):
                    logger.debug(
                        f"[DIVERSITY] ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ ì œì™¸: '{candidate_style}' "
                        f"(ìœ ì‚¬: '{selected_style}')"
                    )
                    is_duplicate = True
                    break

            if not is_duplicate:
                top_k_recommendations.append(candidate)
                logger.info(
                    f"[DIVERSITY] ì„ íƒ ({len(top_k_recommendations)}/{k}): "
                    f"'{candidate_style}' (ì ìˆ˜: {candidate['score']:.2f})"
                )

        # kê°œë¥¼ ì±„ìš°ì§€ ëª»í•œ ê²½ìš° ê²½ê³ 
        if len(top_k_recommendations) < k:
            logger.warning(
                f"[DIVERSITY] ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ {k}ê°œë¥¼ ì°¾ì§€ ëª»í•¨ "
                f"(ì‹¤ì œ: {len(top_k_recommendations)}ê°œ). "
                f"thresholdë¥¼ ë‚®ì¶”ê±°ë‚˜ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”."
            )

        # Min-Max ì •ê·œí™”ë¥¼ ì‚¬ìš©í•œ ì ìˆ˜ ìŠ¤ì¼€ì¼ë§
        # Top-K ë‚´ì—ì„œ ì ìˆ˜ë¥¼ 75~95ì  ë²”ìœ„ë¡œ ì •ê·œí™”í•˜ì—¬ ì°¨ë³„í™”ëœ ì ìˆ˜ ì œê³µ
        if len(top_k_recommendations) >= 2:
            raw_scores = [rec['original_score'] for rec in top_k_recommendations]
            min_raw = min(raw_scores)
            max_raw = max(raw_scores)

            # ì ìˆ˜ ì°¨ì´ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì •ê·œí™”
            if max_raw > min_raw:
                # ëª©í‘œ ë²”ìœ„: 75 ~ 95ì 
                target_min, target_max = 75.0, 95.0

                logger.info(f"[SCORE NORM] Raw scores: {raw_scores}")
                logger.info(f"[SCORE NORM] Raw range: {min_raw:.2f} ~ {max_raw:.2f}")

                for rec in top_k_recommendations:
                    raw = rec['original_score']
                    # Min-Max ì •ê·œí™”: (raw - min) / (max - min) * (target_max - target_min) + target_min
                    normalized = (raw - min_raw) / (max_raw - min_raw) * (target_max - target_min) + target_min
                    rec['score'] = round(normalized, 2)

                logger.info(f"[SCORE NORM] Normalized scores: {[r['score'] for r in top_k_recommendations]}")
            else:
                # ëª¨ë“  ì ìˆ˜ê°€ ë™ì¼í•œ ê²½ìš° (ë“œë¬¼ì§€ë§Œ) ì¤‘ê°„ê°’ ì‚¬ìš©
                for i, rec in enumerate(top_k_recommendations):
                    rec['score'] = round(95.0 - i * 3, 2)  # 95, 92, 89...
                logger.info(f"[SCORE NORM] Same scores - using fallback: {[r['score'] for r in top_k_recommendations]}")
        elif len(top_k_recommendations) == 1:
            # 1ê°œë§Œ ìˆëŠ” ê²½ìš°
            top_k_recommendations[0]['score'] = 90.0
            logger.info("[SCORE NORM] Single recommendation - set to 90.0")

        # ë””ë²„ê·¸: Top-K ì ìˆ˜ ë¶„í¬
        if top_k_recommendations:
            scores_list = [r['score'] for r in top_k_recommendations]
            logger.info(f"[ML DEBUG] Top-{k} final scores: {scores_list}")
            logger.info(f"[ML DEBUG] Score range: {min(scores_list):.2f} ~ {max(scores_list):.2f}")

        logger.info(
            f"[ML RESULT] ML ì¶”ì²œ ì™„ë£Œ: {[r['hairstyle'] for r in top_k_recommendations]}"
        )

        return top_k_recommendations

    def batch_predict(
        self,
        face_shape: str,
        skin_tone: str,
        hairstyles: List[str]
    ) -> Dict[str, float]:
        """
        ì—¬ëŸ¬ í—¤ì–´ìŠ¤íƒ€ì¼ì˜ ì ìˆ˜ë¥¼ í•œ ë²ˆì— ì˜ˆì¸¡ (ë„ì–´ì“°ê¸° ì •ê·œí™” ì ìš©)

        Args:
            face_shape: ì–¼êµ´í˜•
            skin_tone: í”¼ë¶€í†¤
            hairstyles: í—¤ì–´ìŠ¤íƒ€ì¼ ë¦¬ìŠ¤íŠ¸

        Returns:
            {í—¤ì–´ìŠ¤íƒ€ì¼: ì ìˆ˜} ë”•ì…”ë„ˆë¦¬
        """
        results = {}
        
        # 1. ì„ë² ë”© ìˆ˜ì§‘ (DB or ì‹¤ì‹œê°„)
        valid_styles = []
        batch_embeddings = []
        
        for style in hairstyles:
            normalized = normalize_style_name(style)
            embedding = self._get_style_embedding(normalized)
            
            if embedding is None:
                # ì›ë³¸ ì´ë¦„ìœ¼ë¡œë„ ì‹œë„
                embedding = self._get_style_embedding(style)
            
            if embedding is not None:
                valid_styles.append(style)
                batch_embeddings.append(embedding)
            else:
                logger.warning(f"ì„ë² ë”© ìƒì„± ë¶ˆê°€ë¡œ ê±´ë„ˆëœ€: {style}")

        if not valid_styles:
            logger.warning("ìœ íš¨í•œ í—¤ì–´ìŠ¤íƒ€ì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return results

        # 2. ì–¼êµ´í˜•ê³¼ í”¼ë¶€í†¤ íŠ¹ì§• ë²¡í„° ìƒì„±
        face_vec = self._encode_face_shape(face_shape)  # (4,)
        tone_vec = self._encode_skin_tone(skin_tone)    # (4,)

        batch_embeddings = np.array(batch_embeddings, dtype=np.float32)

        # 3. ë°°ì¹˜ ì¶”ë¡  - 3ê°œì˜ ê°œë³„ í…ì„œë¡œ ì „ë‹¬
        with torch.no_grad():
            batch_size = len(valid_styles)
            face_batch = np.tile(face_vec, (batch_size, 1))
            skin_batch = np.tile(tone_vec, (batch_size, 1))

            face_tensor = torch.FloatTensor(face_batch).to(self.device)
            skin_tensor = torch.FloatTensor(skin_batch).to(self.device)
            style_tensor = torch.FloatTensor(batch_embeddings).to(self.device)

            scores_tensor = self.model(face_tensor, skin_tensor, style_tensor)
            scores = scores_tensor.cpu().numpy().flatten()

        # 4. ê²°ê³¼ ì €ì¥
        for style, score in zip(valid_styles, scores):
            results[style] = round(max(0.0, min(100.0, float(score))), 2)

        return results


# ========== ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ (ì „ì—­ ì‚¬ìš©) ==========
_recommender_instance = None


def get_ml_recommender() -> MLHairstyleRecommender:
    """
    ML ì¶”ì²œê¸° ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°

    Returns:
        MLHairstyleRecommender ì¸ìŠ¤í„´ìŠ¤
    """
    global _recommender_instance

    if _recommender_instance is None:
        logger.info("ğŸ”§ ML ì¶”ì²œê¸° ì´ˆê¸°í™” ì¤‘...")
        _recommender_instance = MLHairstyleRecommender()
        logger.info("âœ… ML ì¶”ì²œê¸° ì¤€ë¹„ ì™„ë£Œ")

    return _recommender_instance
